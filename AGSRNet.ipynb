{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AGSRNet_source.preprocessing import *\n",
    "from AGSRNet_source.model import *\n",
    "from AGSRNet_source.train import *\n",
    "\n",
    "from data_preparation import load_data_tensor\n",
    "\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available... Using cuda!\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "    print(f\"CUDA available... Using {DEVICE}!\")\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "    print(f\"CUDA not available... Using {DEVICE}!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data\n",
    "lr_train, lr_test, hr_train = load_data_tensor('data')\n",
    "lr_train, lr_test, hr_train = lr_train.to(DEVICE), lr_test.to(DEVICE), hr_train.to(DEVICE)\n",
    "# lr_train: training input x_train\n",
    "# hr_train: training target y_train\n",
    "# lr_test: test input x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr_train: <class 'torch.Tensor'>, lr_test: <class 'torch.Tensor'>, hr_train: <class 'torch.Tensor'>\n",
      "lr_train: torch.Size([167, 160, 160]), lr_test: torch.Size([112, 160, 160]), hr_train: torch.Size([167, 268, 268])\n"
     ]
    }
   ],
   "source": [
    "print(f'lr_train: {type(lr_train)}, lr_test: {type(lr_test)}, hr_train: {type(hr_train)}')\n",
    "print(f'lr_train: {lr_train.shape}, lr_test: {lr_test.shape}, hr_train: {hr_train.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mlr_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "lr_train[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# plotting the LR and target HR matrix for 1 sample/participant (index=0)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlr_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcmap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhot\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnearest\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mcolorbar()\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[0;32m/vol/bitbucket/km2120/DGL_Project/DGL24-Group-Project/my_env/lib/python3.10/site-packages/matplotlib/pyplot.py:3358\u001b[0m, in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, data, **kwargs)\u001b[0m\n\u001b[1;32m   3337\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mimshow)\n\u001b[1;32m   3338\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimshow\u001b[39m(\n\u001b[1;32m   3339\u001b[0m     X: ArrayLike \u001b[38;5;241m|\u001b[39m PIL\u001b[38;5;241m.\u001b[39mImage\u001b[38;5;241m.\u001b[39mImage,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3356\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3357\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m AxesImage:\n\u001b[0;32m-> 3358\u001b[0m     __ret \u001b[38;5;241m=\u001b[39m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3359\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3360\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcmap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcmap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3361\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3362\u001b[0m \u001b[43m        \u001b[49m\u001b[43maspect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maspect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3363\u001b[0m \u001b[43m        \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3364\u001b[0m \u001b[43m        \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3365\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvmin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3366\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvmax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvmax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3367\u001b[0m \u001b[43m        \u001b[49m\u001b[43morigin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morigin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3368\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3369\u001b[0m \u001b[43m        \u001b[49m\u001b[43minterpolation_stage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation_stage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3370\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilternorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilternorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3371\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilterrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilterrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3372\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3373\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3374\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3375\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3376\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3377\u001b[0m     sci(__ret)\n\u001b[1;32m   3378\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m __ret\n",
      "File \u001b[0;32m/vol/bitbucket/km2120/DGL_Project/DGL24-Group-Project/my_env/lib/python3.10/site-packages/matplotlib/__init__.py:1465\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1462\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m   1463\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(ax, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1464\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1465\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1467\u001b[0m     bound \u001b[38;5;241m=\u001b[39m new_sig\u001b[38;5;241m.\u001b[39mbind(ax, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1468\u001b[0m     auto_label \u001b[38;5;241m=\u001b[39m (bound\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mget(label_namer)\n\u001b[1;32m   1469\u001b[0m                   \u001b[38;5;129;01mor\u001b[39;00m bound\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(label_namer))\n",
      "File \u001b[0;32m/vol/bitbucket/km2120/DGL_Project/DGL24-Group-Project/my_env/lib/python3.10/site-packages/matplotlib/axes/_axes.py:5759\u001b[0m, in \u001b[0;36mAxes.imshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5756\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m aspect \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5757\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_aspect(aspect)\n\u001b[0;32m-> 5759\u001b[0m \u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5760\u001b[0m im\u001b[38;5;241m.\u001b[39mset_alpha(alpha)\n\u001b[1;32m   5761\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m im\u001b[38;5;241m.\u001b[39mget_clip_path() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5762\u001b[0m     \u001b[38;5;66;03m# image does not already have clipping set, clip to axes patch\u001b[39;00m\n",
      "File \u001b[0;32m/vol/bitbucket/km2120/DGL_Project/DGL24-Group-Project/my_env/lib/python3.10/site-packages/matplotlib/image.py:723\u001b[0m, in \u001b[0;36m_ImageBase.set_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(A, PIL\u001b[38;5;241m.\u001b[39mImage\u001b[38;5;241m.\u001b[39mImage):\n\u001b[1;32m    722\u001b[0m     A \u001b[38;5;241m=\u001b[39m pil_to_array(A)  \u001b[38;5;66;03m# Needed e.g. to apply png palette.\u001b[39;00m\n\u001b[0;32m--> 723\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_normalize_image_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_imcache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    725\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/vol/bitbucket/km2120/DGL_Project/DGL24-Group-Project/my_env/lib/python3.10/site-packages/matplotlib/image.py:686\u001b[0m, in \u001b[0;36m_ImageBase._normalize_image_array\u001b[0;34m(A)\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_normalize_image_array\u001b[39m(A):\n\u001b[1;32m    682\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;124;03m    Check validity of image-like input *A* and normalize it to a format suitable for\u001b[39;00m\n\u001b[1;32m    684\u001b[0m \u001b[38;5;124;03m    Image subclasses.\u001b[39;00m\n\u001b[1;32m    685\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 686\u001b[0m     A \u001b[38;5;241m=\u001b[39m \u001b[43mcbook\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msafe_masked_invalid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    687\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m A\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39muint8 \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mcan_cast(A\u001b[38;5;241m.\u001b[39mdtype, \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msame_kind\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    688\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage data of dtype \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mA\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m cannot be \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    689\u001b[0m                         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconverted to float\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/vol/bitbucket/km2120/DGL_Project/DGL24-Group-Project/my_env/lib/python3.10/site-packages/matplotlib/cbook.py:733\u001b[0m, in \u001b[0;36msafe_masked_invalid\u001b[0;34m(x, copy)\u001b[0m\n\u001b[1;32m    732\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msafe_masked_invalid\u001b[39m(x, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 733\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    734\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39misnative:\n\u001b[1;32m    735\u001b[0m         \u001b[38;5;66;03m# If we have already made a copy, do the byteswap in place, else make a\u001b[39;00m\n\u001b[1;32m    736\u001b[0m         \u001b[38;5;66;03m# copy with the byte order swapped.\u001b[39;00m\n\u001b[1;32m    737\u001b[0m         \u001b[38;5;66;03m# Swap to native order.\u001b[39;00m\n\u001b[1;32m    738\u001b[0m         x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mbyteswap(inplace\u001b[38;5;241m=\u001b[39mcopy)\u001b[38;5;241m.\u001b[39mview(x\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mnewbyteorder(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mN\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[0;32m/vol/bitbucket/km2120/DGL_Project/DGL24-Group-Project/my_env/lib/python3.10/site-packages/torch/_tensor.py:1062\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   1060\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m__array__, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1062\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1064\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting the LR and target HR matrix for 1 sample/participant (index=0)\n",
    "plt.imshow(lr_train[0], cmap='hot', interpolation='nearest')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(hr_train[0], cmap='hot', interpolation='nearest')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unnecessary, but just to be consistent with the AGSR-Net repo\n",
    "\n",
    "# actual data\n",
    "subjects_adj, subjects_ground_truth, test_adj, test_ground_truth = \\\n",
    "    lr_train, hr_train, lr_test, None  # we don't have the test labels, right?\n",
    "\n",
    "\n",
    "# simulated data from the AGSR-Net repo \n",
    "# subjects_adj = np.random.normal(0.5, 1, (190, 160, 160))\n",
    "# test_adj = np.random.normal(0.5, 1, (87, 160, 160))\n",
    "# subjects_ground_truth = np.random.normal(0.5, 1, (190, 268, 268))\n",
    "# test_ground_truth = np.random.normal(0.5, 1, (87, 268, 268))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AGSRNet(\n",
      "  (layer): GSRLayer()\n",
      "  (net): GraphUnet(\n",
      "    (start_gcn): GCN(\n",
      "      (proj): Linear(in_features=160, out_features=320, bias=True)\n",
      "      (drop): Dropout(p=0, inplace=False)\n",
      "    )\n",
      "    (bottom_gcn): GCN(\n",
      "      (proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "      (drop): Dropout(p=0, inplace=False)\n",
      "    )\n",
      "    (end_gcn): GCN(\n",
      "      (proj): Linear(in_features=640, out_features=320, bias=True)\n",
      "      (drop): Dropout(p=0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (gc1): GraphConvolution()\n",
      "  (gc2): GraphConvolution()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# create the model\n",
    "ks = [0.9, 0.7, 0.6, 0.5]\n",
    "\n",
    "# default values from demo.py in the GitHub repo:\n",
    "# https://github.com/basiralab/AGSR-Net/blob/master/demo.py\n",
    "# args = {\n",
    "#     'epochs': 200,\n",
    "#     'lr': 0.0001,\n",
    "#     'lmbda': 0.1,\n",
    "#     'lr_dim': 160,\n",
    "#     'hr_dim': 320,\n",
    "#     'hidden_dim': 320,\n",
    "#     'padding': 26,\n",
    "#     'mean_dense': 0.,\n",
    "#     'std_dense': 0.01,\n",
    "#     'mean_gaussian': 0.,\n",
    "#     'std_gaussian': 0.1\n",
    "# }\n",
    "\n",
    "class ModelArgs:  # instead of using arg parser, so that this works with AGSRNet class\n",
    "    def __init__(self, epochs, lr, splits, lmbda, lr_dim, hr_dim, hidden_dim,\n",
    "                 padding, mean_dense, std_dense, mean_gaussian, std_gaussian):\n",
    "        self.epochs = epochs\n",
    "        self.lr = lr\n",
    "        self.splits = splits\n",
    "        self.lmbda = lmbda\n",
    "        self.lr_dim = lr_dim\n",
    "        self.hr_dim = hr_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.padding = padding\n",
    "        self.mean_dense = mean_dense\n",
    "        self.std_dense = std_dense\n",
    "        self.mean_gaussian = mean_gaussian\n",
    "        self.std_gaussian = std_gaussian\n",
    "\n",
    "# default arguments\n",
    "args = ModelArgs(\n",
    "    epochs=200,\n",
    "    lr=0.0001,\n",
    "    splits=3,\n",
    "    lmbda=0.1,\n",
    "    lr_dim=160,\n",
    "    hr_dim=320,\n",
    "    hidden_dim=320,\n",
    "    padding=26,\n",
    "    mean_dense=0.,\n",
    "    std_dense=0.01,\n",
    "    mean_gaussian=0.,\n",
    "    std_gaussian=0.1\n",
    ")\n",
    "\n",
    "model = AGSRNet(ks, args).to(DEVICE)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "#train(model, subjects_adj.numpy(), subjects_ground_truth.numpy(), args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the model\n",
    "# test(model, test_adj, test_ground_truth, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator(\n",
      "  (dense_1): Dense()\n",
      "  (relu_1): ReLU()\n",
      "  (dense_2): Dense()\n",
      "  (relu_2): ReLU()\n",
      "  (dense_3): Dense()\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/km2120/DGL_Project/DGL24-Group-Project/AGSRNet_source/preprocessing.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  label = torch.tensor(label, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 Loss:  6.4359262204385015 Error:  551.3387801008181 %\n",
      "Epoch:  1 Loss:  4.351259843723194 Error:  10.239800837662843 %\n",
      "Epoch:  2 Loss:  7.728865507486704 Error:  7.91813693269416 %\n",
      "Epoch:  3 Loss:  10.112513950279167 Error:  7.294071143543398 %\n",
      "Epoch:  4 Loss:  11.968688475119102 Error:  7.059930050158286 %\n",
      "Epoch:  5 Loss:  13.544491269566992 Error:  6.954102184589919 %\n",
      "Epoch:  6 Loss:  14.904071876594612 Error:  6.899924851484126 %\n",
      "Epoch:  7 Loss:  16.143748678602613 Error:  6.869314191443427 %\n",
      "Epoch:  8 Loss:  17.23806717159512 Error:  6.849981700112154 %\n",
      "Epoch:  9 Loss:  18.19090462590123 Error:  6.835976548425786 %\n",
      "Epoch:  10 Loss:  19.014932915971087 Error:  6.824353139276977 %\n",
      "Epoch:  11 Loss:  19.73252958864779 Error:  6.8134855143390265 %\n",
      "Epoch:  12 Loss:  20.3643741178083 Error:  6.802491101998466 %\n",
      "Epoch:  13 Loss:  20.92772104074289 Error:  6.790995711947347 %\n",
      "Epoch:  14 Loss:  21.43639526710854 Error:  6.778822258651794 %\n",
      "Epoch:  15 Loss:  21.897610097318083 Error:  6.765972796055647 %\n",
      "Epoch:  16 Loss:  22.31725973696322 Error:  6.752567899388236 %\n",
      "Epoch:  17 Loss:  22.70121124198845 Error:  6.738766054580878 %\n",
      "Epoch:  18 Loss:  23.055479977581953 Error:  6.72462334571121 %\n",
      "Epoch:  19 Loss:  23.384857349567586 Error:  6.710300993946222 %\n",
      "Epoch:  20 Loss:  23.695513940072274 Error:  6.695853130103231 %\n",
      "Epoch:  21 Loss:  23.98866911192198 Error:  6.681372607881958 %\n",
      "Epoch:  22 Loss:  24.26674643507949 Error:  6.666817724167763 %\n",
      "Epoch:  23 Loss:  24.532061963467985 Error:  6.652250953085788 %\n",
      "Epoch:  24 Loss:  24.785825145137203 Error:  6.637696190191819 %\n",
      "Epoch:  25 Loss:  25.030383427937824 Error:  6.623113756110002 %\n",
      "Epoch:  26 Loss:  25.267119330328864 Error:  6.608508916588517 %\n",
      "Epoch:  27 Loss:  25.49650137274115 Error:  6.593861310063182 %\n",
      "Epoch:  28 Loss:  25.719086380692215 Error:  6.57915679721145 %\n",
      "Epoch:  29 Loss:  25.935316670048344 Error:  6.564398170322986 %\n",
      "Epoch:  30 Loss:  26.14446832467844 Error:  6.549629065636042 %\n",
      "Epoch:  31 Loss:  26.349312241012985 Error:  6.534859648830182 %\n",
      "Epoch:  32 Loss:  26.550489391292537 Error:  6.519987249562333 %\n",
      "Epoch:  33 Loss:  26.746893204010284 Error:  6.505225682715038 %\n",
      "Epoch:  34 Loss:  26.939266617233688 Error:  6.490476513365367 %\n",
      "Epoch:  35 Loss:  27.12900615382839 Error:  6.475761331416466 %\n",
      "Epoch:  36 Loss:  27.31617953326251 Error:  6.4611554783475285 %\n",
      "Epoch:  37 Loss:  27.50094697282121 Error:  6.446712031155019 %\n",
      "Epoch:  38 Loss:  27.683901382996154 Error:  6.43231445537494 %\n",
      "Epoch:  39 Loss:  27.86356748976149 Error:  6.418107691648844 %\n",
      "Epoch:  40 Loss:  28.042471602156354 Error:  6.403859912812172 %\n",
      "Epoch:  41 Loss:  28.219440889788103 Error:  6.389623007795832 %\n",
      "Epoch:  42 Loss:  28.393584156895542 Error:  6.375439948326833 %\n",
      "Epoch:  43 Loss:  28.567330729854 Error:  6.361291826039821 %\n",
      "Epoch:  44 Loss:  28.737566612862253 Error:  6.347365479345794 %\n",
      "Epoch:  45 Loss:  28.905463003897452 Error:  6.333723459560591 %\n",
      "Epoch:  46 Loss:  29.072738750560863 Error:  6.320140551070909 %\n",
      "Epoch:  47 Loss:  29.23784998300913 Error:  6.306514657429747 %\n",
      "Epoch:  48 Loss:  29.400802749771255 Error:  6.29267963404591 %\n",
      "Epoch:  49 Loss:  29.561705305769635 Error:  6.278603661570463 %\n",
      "Epoch:  50 Loss:  29.71868439408036 Error:  6.2643592321389425 %\n",
      "Epoch:  51 Loss:  29.873615367992503 Error:  6.249961404650061 %\n",
      "Epoch:  52 Loss:  30.025422018927497 Error:  6.235240513945485 %\n",
      "Epoch:  53 Loss:  30.173057762352197 Error:  6.220211894125552 %\n",
      "Epoch:  54 Loss:  30.31738501196509 Error:  6.204828596464148 %\n",
      "Epoch:  55 Loss:  30.45776769277212 Error:  6.188996290569907 %\n",
      "Epoch:  56 Loss:  30.594527614009273 Error:  6.1728251678449615 %\n",
      "Epoch:  57 Loss:  30.728095888017535 Error:  6.155939655260997 %\n",
      "Epoch:  58 Loss:  30.85791269938151 Error:  6.138552020530443 %\n",
      "Epoch:  59 Loss:  30.985200624208193 Error:  6.120725966117403 %\n",
      "Epoch:  60 Loss:  31.112962757144963 Error:  6.102649807124524 %\n",
      "Epoch:  61 Loss:  31.239844777562595 Error:  6.084107913009755 %\n",
      "Epoch:  62 Loss:  31.365754376660597 Error:  6.065138476388948 %\n",
      "Epoch:  63 Loss:  31.487762141872096 Error:  6.045723652785963 %\n",
      "Epoch:  64 Loss:  31.611404350212027 Error:  6.025895459560661 %\n",
      "Epoch:  65 Loss:  31.734532227387298 Error:  6.005635928060558 %\n",
      "Epoch:  66 Loss:  31.858347592053114 Error:  5.984833839911598 %\n",
      "Epoch:  67 Loss:  31.982679487348676 Error:  5.963641952152725 %\n",
      "Epoch:  68 Loss:  32.11048696706961 Error:  5.941818879397066 %\n",
      "Epoch:  69 Loss:  32.24553462191745 Error:  5.919598965897217 %\n",
      "Epoch:  70 Loss:  32.393404470907676 Error:  5.8978196602683886 %\n",
      "Epoch:  71 Loss:  32.538335198754666 Error:  5.875479030582282 %\n",
      "Epoch:  72 Loss:  32.6776011870788 Error:  5.85265023012956 %\n",
      "Epoch:  73 Loss:  32.81448319581178 Error:  5.829234025231353 %\n",
      "Epoch:  74 Loss:  32.94339769380586 Error:  5.8050856162030415 %\n",
      "Epoch:  75 Loss:  33.07875997526152 Error:  5.779221757977933 %\n",
      "Epoch:  76 Loss:  33.21479137523754 Error:  5.75313223106367 %\n",
      "Epoch:  77 Loss:  33.38273108542502 Error:  5.726498049927187 %\n",
      "Epoch:  78 Loss:  33.54755719502767 Error:  5.69995517196419 %\n",
      "Epoch:  79 Loss:  33.75057517730438 Error:  5.672998900886054 %\n",
      "Epoch:  80 Loss:  33.90464906434755 Error:  5.646120209817414 %\n",
      "Epoch:  81 Loss:  34.27781118788161 Error:  5.616925730630084 %\n",
      "Epoch:  82 Loss:  34.38603198420894 Error:  5.587567023194588 %\n",
      "Epoch:  83 Loss:  34.72726297808123 Error:  5.558072661494349 %\n",
      "Epoch:  84 Loss:  35.32109396307318 Error:  5.526650720485696 %\n",
      "Epoch:  85 Loss:  34.982449763530006 Error:  5.497870604331429 %\n",
      "Epoch:  86 Loss:  36.199229695775486 Error:  5.46580208381554 %\n",
      "Epoch:  87 Loss:  35.530021426913976 Error:  5.435492772911045 %\n",
      "Epoch:  88 Loss:  34.71157086002934 Error:  5.403454876966304 %\n",
      "Epoch:  89 Loss:  34.62700809444393 Error:  5.3708238174786445 %\n",
      "Epoch:  90 Loss:  34.69555705302471 Error:  5.339021812956613 %\n",
      "Epoch:  91 Loss:  34.688224362897444 Error:  5.308113750573751 %\n",
      "Epoch:  92 Loss:  34.12835086788143 Error:  5.276846291648376 %\n",
      "Epoch:  93 Loss:  34.48909336811787 Error:  5.247199501808699 %\n",
      "Epoch:  94 Loss:  34.17313938312702 Error:  5.21694971835828 %\n",
      "Epoch:  95 Loss:  33.72188604200208 Error:  5.186409449523634 %\n",
      "Epoch:  96 Loss:  34.05702326319239 Error:  5.15590330233445 %\n",
      "Epoch:  97 Loss:  32.81071645719511 Error:  5.124113842979208 %\n",
      "Epoch:  98 Loss:  32.89476081916878 Error:  5.095473707124993 %\n",
      "Epoch:  99 Loss:  32.769202893918695 Error:  5.064747774520436 %\n",
      "Epoch:  100 Loss:  32.68804577664212 Error:  5.0348836962167205 %\n",
      "Epoch:  101 Loss:  32.297637733253275 Error:  5.007376931272112 %\n",
      "Epoch:  102 Loss:  31.49967095658586 Error:  4.978139856242918 %\n",
      "Epoch:  103 Loss:  31.186410216597825 Error:  4.9482777345556395 %\n",
      "Epoch:  104 Loss:  30.450869878133137 Error:  4.917346746534915 %\n",
      "Epoch:  105 Loss:  29.524222949603658 Error:  4.8871731469491575 %\n",
      "Epoch:  106 Loss:  28.705702085752744 Error:  4.856101990685806 %\n",
      "Epoch:  107 Loss:  28.112796946688814 Error:  4.824455874460237 %\n",
      "Epoch:  108 Loss:  27.467464094763404 Error:  4.791056354706352 %\n",
      "Epoch:  109 Loss:  26.717552683374905 Error:  4.763365422820185 %\n",
      "Epoch:  110 Loss:  26.08524478018821 Error:  4.728556387462057 %\n",
      "Epoch:  111 Loss:  25.45125096982664 Error:  4.696488111942738 %\n",
      "Epoch:  112 Loss:  24.809726508888037 Error:  4.6643187115724025 %\n",
      "Epoch:  113 Loss:  24.076517354260695 Error:  4.632952755635923 %\n",
      "Epoch:  114 Loss:  23.462662138380445 Error:  4.606742770956443 %\n",
      "Epoch:  115 Loss:  22.78268306319778 Error:  4.577718693595212 %\n",
      "Epoch:  116 Loss:  22.10890156513936 Error:  4.547600357516392 %\n",
      "Epoch:  117 Loss:  21.28786462491697 Error:  4.519617300782654 %\n",
      "Epoch:  118 Loss:  20.647905057614988 Error:  4.491064262886843 %\n",
      "Epoch:  119 Loss:  20.02390262672493 Error:  4.461071066356994 %\n",
      "Epoch:  120 Loss:  19.424340944032412 Error:  4.431533845359677 %\n",
      "Epoch:  121 Loss:  18.74710209305222 Error:  4.401820337584427 %\n",
      "Epoch:  122 Loss:  18.167283573666133 Error:  4.3683144490461085 %\n",
      "Epoch:  123 Loss:  17.805978886716 Error:  4.334200727375778 %\n",
      "Epoch:  124 Loss:  17.438029452487154 Error:  4.302968878533926 %\n",
      "Epoch:  125 Loss:  17.45294058000719 Error:  4.271726009880637 %\n",
      "Epoch:  126 Loss:  17.343571542619586 Error:  4.234390714214191 %\n",
      "Epoch:  127 Loss:  17.03606364104125 Error:  4.199124725015314 %\n",
      "Epoch:  128 Loss:  16.92796382388553 Error:  4.165850406898572 %\n",
      "Epoch:  129 Loss:  17.05730948577056 Error:  4.137869014799058 %\n",
      "Epoch:  130 Loss:  16.93807667225331 Error:  4.113068255419667 %\n",
      "Epoch:  131 Loss:  17.085296012259818 Error:  4.090858039421004 %\n",
      "Epoch:  132 Loss:  16.797376701423715 Error:  4.066658922815107 %\n",
      "Epoch:  133 Loss:  16.572282645079465 Error:  4.038355541457464 %\n",
      "Epoch:  134 Loss:  16.382642333571976 Error:  4.01508735476045 %\n",
      "Epoch:  135 Loss:  16.4535821708473 Error:  3.9972467146612503 %\n",
      "Epoch:  136 Loss:  16.319943350714606 Error:  3.9780411768603967 %\n",
      "Epoch:  137 Loss:  16.447711549363696 Error:  3.9611294043359453 %\n",
      "Epoch:  138 Loss:  16.200805930403977 Error:  3.9375739088198087 %\n",
      "Epoch:  139 Loss:  16.4219872156779 Error:  3.921176865696907 %\n",
      "Epoch:  140 Loss:  16.36023080671156 Error:  3.906543619997867 %\n",
      "Epoch:  141 Loss:  16.400333095241237 Error:  3.8896143033697794 %\n",
      "Epoch:  142 Loss:  16.43975341212642 Error:  3.8751631807368083 %\n",
      "Epoch:  143 Loss:  16.412285821931857 Error:  3.860158985061152 %\n",
      "Epoch:  144 Loss:  16.528646056716507 Error:  3.8461658096796763 %\n",
      "Epoch:  145 Loss:  16.60101537446718 Error:  3.830734660496583 %\n",
      "Epoch:  146 Loss:  16.468894829621185 Error:  3.818199657709212 %\n",
      "Epoch:  147 Loss:  16.452014390412753 Error:  3.8024877374236645 %\n",
      "Epoch:  148 Loss:  16.510627952781885 Error:  3.7900539400341278 %\n",
      "Epoch:  149 Loss:  16.612653534691614 Error:  3.7776274287754354 %\n",
      "Epoch:  150 Loss:  16.651675808537114 Error:  3.7657349177443225 %\n",
      "Epoch:  151 Loss:  16.857375746374732 Error:  3.753154360697613 %\n",
      "Epoch:  152 Loss:  16.883695507908726 Error:  3.7436709160337576 %\n",
      "Epoch:  153 Loss:  16.99639976776398 Error:  3.736672159452159 %\n",
      "Epoch:  154 Loss:  17.29791871491853 Error:  3.7327918047840534 %\n",
      "Epoch:  155 Loss:  17.62352245777577 Error:  3.7391582587817767 %\n",
      "Epoch:  156 Loss:  17.605835029670786 Error:  3.7479775278149425 %\n",
      "Epoch:  157 Loss:  17.68683320981962 Error:  3.7429161000627653 %\n",
      "Epoch:  158 Loss:  17.963284587000942 Error:  3.747279413447187 %\n",
      "Epoch:  159 Loss:  17.809485177736025 Error:  3.7532637298509886 %\n",
      "Epoch:  160 Loss:  17.68474593463245 Error:  3.745947063371942 %\n",
      "Epoch:  161 Loss:  17.555907232267362 Error:  3.7087517547177837 %\n",
      "Epoch:  162 Loss:  17.598527530292134 Error:  3.689801157661923 %\n",
      "Epoch:  163 Loss:  17.75695578257243 Error:  3.6770952043232614 %\n",
      "Epoch:  164 Loss:  17.915316444259506 Error:  3.6627995806771354 %\n",
      "Epoch:  165 Loss:  18.345152055895007 Error:  3.6524283708081593 %\n",
      "Epoch:  166 Loss:  19.026595536652987 Error:  3.64739014557353 %\n",
      "Epoch:  167 Loss:  18.377750568561726 Error:  3.6442537515147313 %\n",
      "Epoch:  168 Loss:  18.152556866138905 Error:  3.6377818382403873 %\n",
      "Epoch:  169 Loss:  18.232307227882178 Error:  3.631639958837548 %\n",
      "Epoch:  170 Loss:  18.137928945524198 Error:  3.626633465692804 %\n",
      "Epoch:  171 Loss:  18.351012891477293 Error:  3.6246633022889356 %\n",
      "Epoch:  172 Loss:  18.52843681541649 Error:  3.6155672223718316 %\n",
      "Epoch:  173 Loss:  18.45039594495619 Error:  3.6081700594172825 %\n",
      "Epoch:  174 Loss:  18.434361749941164 Error:  3.599502117717051 %\n",
      "Epoch:  175 Loss:  18.249875111622853 Error:  3.5888171863851244 %\n",
      "Epoch:  176 Loss:  18.32934895936433 Error:  3.5806648282183184 %\n",
      "Epoch:  177 Loss:  18.387415464933927 Error:  3.5710887245095533 %\n",
      "Epoch:  178 Loss:  18.33125469276497 Error:  3.564214736625955 %\n",
      "Epoch:  179 Loss:  18.375468382964264 Error:  3.5596114608484344 %\n",
      "Epoch:  180 Loss:  18.57865859366752 Error:  3.5566825570689664 %\n",
      "Epoch:  181 Loss:  18.91869862874349 Error:  3.556678603562686 %\n",
      "Epoch:  182 Loss:  18.966433739876962 Error:  3.556457524364059 %\n",
      "Epoch:  183 Loss:  19.13643676311046 Error:  3.558355673879116 %\n",
      "Epoch:  184 Loss:  19.33252305383081 Error:  3.5646732443490543 %\n",
      "Epoch:  185 Loss:  19.524674046146977 Error:  3.5825406209574093 %\n",
      "Epoch:  186 Loss:  19.440485739493155 Error:  3.6040203310213648 %\n",
      "Epoch:  187 Loss:  19.452767552556217 Error:  3.6068123807241252 %\n",
      "Epoch:  188 Loss:  19.431784449396908 Error:  3.602452804376413 %\n",
      "Epoch:  189 Loss:  19.411222200135928 Error:  3.6043726612587235 %\n",
      "Epoch:  190 Loss:  19.404613408956443 Error:  3.616568016576337 %\n",
      "Epoch:  191 Loss:  19.676874555982984 Error:  3.6362568369588337 %\n",
      "Epoch:  192 Loss:  19.948955535888672 Error:  3.633560117770423 %\n",
      "Epoch:  193 Loss:  19.712871396863783 Error:  3.62783100388877 %\n",
      "Epoch:  194 Loss:  19.458583436570727 Error:  3.6200966350398622 %\n",
      "Epoch:  195 Loss:  19.574728579134554 Error:  3.62446240510221 %\n",
      "Epoch:  196 Loss:  19.42362575702839 Error:  3.6208036968165693 %\n",
      "Epoch:  197 Loss:  19.468469963417398 Error:  3.611962334462651 %\n",
      "Epoch:  198 Loss:  19.89644786044284 Error:  3.602090169180621 %\n",
      "Epoch:  199 Loss:  19.933408324782913 Error:  3.594428888178087 %\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected np.ndarray (got Tensor)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m         train(model, subjects_adj, subjects_ground_truth, args)\n\u001b[1;32m      9\u001b[0m         test(model, test_adj, test_ground_truth, args)\n\u001b[0;32m---> 11\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 9\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m subjects_adj, test_adj, subjects_ground_truth, test_ground_truth \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m      7\u001b[0m     X[train_index], X[test_index], Y[train_index], Y[test_index]\n\u001b[1;32m      8\u001b[0m train(model, subjects_adj, subjects_ground_truth, args)\n\u001b[0;32m----> 9\u001b[0m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_adj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_ground_truth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/vol/bitbucket/km2120/DGL_Project/DGL24-Group-Project/AGSRNet_source/train.py:114\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(model, test_adj, test_labels, args)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m#preds = unpad(preds, args.padding)\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# if i == 0:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    111\u001b[0m \n\u001b[1;32m    112\u001b[0m \u001b[38;5;66;03m# preds_list.append(preds.flatten().detach().numpy())\u001b[39;00m\n\u001b[1;32m    113\u001b[0m preds_list\u001b[38;5;241m.\u001b[39mappend(preds\u001b[38;5;241m.\u001b[39mflatten()\u001b[38;5;241m.\u001b[39mdetach())\n\u001b[0;32m--> 114\u001b[0m error \u001b[38;5;241m=\u001b[39m criterion(preds, \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhr\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    115\u001b[0m error_mae \u001b[38;5;241m=\u001b[39m criterion_test(preds, torch\u001b[38;5;241m.\u001b[39mfrom_numpy(hr))\n\u001b[1;32m    116\u001b[0m g_t\u001b[38;5;241m.\u001b[39mappend(hr\u001b[38;5;241m.\u001b[39mflatten())\n",
      "\u001b[0;31mTypeError\u001b[0m: expected np.ndarray (got Tensor)"
     ]
    }
   ],
   "source": [
    "cv = KFold(n_splits=args.splits, random_state=42, shuffle=True)\n",
    "X, Y = lr_train, hr_train\n",
    "\n",
    "def train_model():\n",
    "    for train_index, test_index in cv.split(X):\n",
    "        subjects_adj, test_adj, subjects_ground_truth, test_ground_truth = \\\n",
    "            X[train_index], X[test_index], Y[train_index], Y[test_index]\n",
    "        train(model, subjects_adj, subjects_ground_truth, args)\n",
    "        test(model, test_adj, test_ground_truth, args)\n",
    "\n",
    "train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([268, 268])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_preds_and_convert_to_submission(file_name, model=model, test_set=x_test):\n",
    "    preds_list = []\n",
    "    with torch.no_grad():\n",
    "        for test_data in test_set:\n",
    "            pred, _, _, _ = model(test_data)\n",
    "            pred = unpad(pred, args.padding)\n",
    "            preds_list.append(pred)\n",
    "    pred_tensor = torch.stack(preds_list).cpu().numpy()\n",
    "    generate_submission_file(pred_tensor, f'/vol/bitbucket/km2120/DGL_Project/DGL24-Group-Project/submission_files/{file_name}')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
