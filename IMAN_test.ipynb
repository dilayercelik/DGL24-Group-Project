{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Sequential, Linear, ReLU, Sigmoid, Tanh, Dropout, Upsample\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import NNConv\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import BatchNorm\n",
    "import numpy as np\n",
    "from torch_geometric.data import Data\n",
    "from torch.autograd import Variable\n",
    "import networkx as nx\n",
    "\n",
    "import os.path as osp\n",
    "import pickle\n",
    "from scipy.linalg import sqrtm\n",
    "import argparse\n",
    "from scipy.stats import wasserstein_distance\n",
    "from torch.distributions import normal, kl\n",
    "\n",
    "\n",
    "import argparse\n",
    "from torch_geometric.datasets import Planetoid\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import GCNConv, GAE, VGAE, InnerProductDecoder, ARGVA\n",
    "from torch_geometric.utils import train_test_split_edges\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_preparation import load_data_tensor\n",
    "\n",
    "lr_train, lr_test, hr_train = load_data_tensor()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([167, 160, 160])\n",
      "torch.Size([167, 268, 268])\n"
     ]
    }
   ],
   "source": [
    "torch.set_printoptions(precision=8)\n",
    "print(lr_train.shape)\n",
    "print(hr_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of subjects in simulated data \n",
    "N_SUBJECTS = 167\n",
    "\n",
    "# Number of ROIs in source brain graph for simulated data \n",
    "N_SOURCE_NODES = 160\n",
    "\n",
    "# Number of ROIs in target brain graph for simulated data\n",
    "N_TARGET_NODES = 268\n",
    "\n",
    "# Number of traning epochs\n",
    "N_EPOCHS = 10\n",
    "\n",
    "\n",
    "####** DO NOT MODIFY BELOW **####\n",
    "N_SOURCE_NODES_F =int((N_SOURCE_NODES*(N_SOURCE_NODES-1))/2)\n",
    "N_TARGET_NODES_F =int((N_TARGET_NODES*(N_TARGET_NODES-1))/2)\n",
    "###**************************####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Aligner(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        \n",
    "        super(Aligner, self).__init__()\n",
    "\n",
    "        nn = Sequential(Linear(1, N_SOURCE_NODES*N_SOURCE_NODES), ReLU())\n",
    "        self.conv1 = NNConv(N_SOURCE_NODES, N_SOURCE_NODES, nn, aggr='mean', root_weight=True, bias=True)\n",
    "        self.conv11 = BatchNorm(N_SOURCE_NODES, eps=1e-03, momentum=0.1, affine=True, track_running_stats=True)\n",
    "\n",
    "        nn = Sequential(Linear(1, N_SOURCE_NODES), ReLU())\n",
    "        self.conv2 = NNConv(N_SOURCE_NODES, 1, nn, aggr='mean', root_weight=True, bias=True)\n",
    "        self.conv22 = BatchNorm(1, eps=1e-03, momentum=0.1, affine=True, track_running_stats=True)\n",
    "\n",
    "        nn = Sequential(Linear(1, N_SOURCE_NODES), ReLU())\n",
    "        self.conv3 = NNConv(1, N_SOURCE_NODES, nn, aggr='mean', root_weight=True, bias=True)\n",
    "        self.conv33 = BatchNorm(N_SOURCE_NODES, eps=1e-03, momentum=0.1, affine=True, track_running_stats=True)\n",
    "\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr = data.x, data.pos_edge_index, data.edge_attr\n",
    "\n",
    "        x1 = F.sigmoid(self.conv11(self.conv1(x, edge_index, edge_attr)))\n",
    "        x1 = F.dropout(x1, training=self.training)\n",
    "\n",
    "        x2 = F.sigmoid(self.conv22(self.conv2(x1, edge_index, edge_attr)))\n",
    "        x2 = F.dropout(x2, training=self.training)\n",
    "\n",
    "        x3 = torch.cat([F.sigmoid(self.conv33(self.conv3(x2, edge_index, edge_attr))), x1], dim=1)\n",
    "        x4 = x3[:, 0:N_SOURCE_NODES]\n",
    "        x5 = x3[:, N_SOURCE_NODES:2*N_SOURCE_NODES]\n",
    "\n",
    "        x6 = (x4 + x5) / 2\n",
    "        return x6\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        nn = Sequential(Linear(1, N_SOURCE_NODES*N_SOURCE_NODES),ReLU())\n",
    "        self.conv1 = NNConv(N_SOURCE_NODES, N_SOURCE_NODES, nn, aggr='mean', root_weight=True, bias=True)\n",
    "        self.conv11 = BatchNorm(N_SOURCE_NODES, eps=1e-03, momentum=0.1, affine=True, track_running_stats=True)\n",
    "\n",
    "        nn = Sequential(Linear(1, N_TARGET_NODES*N_SOURCE_NODES), ReLU())\n",
    "        self.conv2 = NNConv(N_TARGET_NODES, N_SOURCE_NODES, nn, aggr='mean', root_weight=True, bias=True)\n",
    "        self.conv22 = BatchNorm(N_SOURCE_NODES, eps=1e-03, momentum=0.1, affine=True, track_running_stats=True)\n",
    "\n",
    "        nn = Sequential(Linear(1, N_TARGET_NODES*N_SOURCE_NODES), ReLU())\n",
    "        self.conv3 = NNConv(N_SOURCE_NODES, N_TARGET_NODES, nn, aggr='mean', root_weight=True, bias=True)\n",
    "        self.conv33 = BatchNorm(N_TARGET_NODES, eps=1e-03, momentum=0.1, affine=True, track_running_stats=True)\n",
    "\n",
    "\n",
    "        # self.layer= torch.nn.ConvTranspose2d(N_TARGET_NODES, N_TARGET_NODES,5)\n",
    "\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr = data.x, data.pos_edge_index, data.edge_attr\n",
    "        # x = torch.squeeze(x)\n",
    "\n",
    "        x1 = F.sigmoid(self.conv11(self.conv1(x, edge_index, edge_attr)))\n",
    "        x1 = F.dropout(x1, training=self.training)\n",
    "\n",
    "        # x2 = F.sigmoid(self.conv22(self.conv2(x1, edge_index, edge_attr)))\n",
    "        # x2 = F.dropout(x2, training=self.training)\n",
    "\n",
    "        x3 = F.sigmoid(self.conv33(self.conv3(x1, edge_index, edge_attr)))\n",
    "        x3 = F.dropout(x3, training=self.training)\n",
    "\n",
    "\n",
    "\n",
    "        x4  = torch.matmul(x3.t(), x3)\n",
    "\n",
    "        return x4\n",
    "\n",
    "class Discriminator(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.conv1 = GCNConv(N_TARGET_NODES, N_TARGET_NODES, cached=True)\n",
    "        self.conv2 = GCNConv(N_TARGET_NODES, 1, cached=True)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr = data.x, data.pos_edge_index, data.edge_attr\n",
    "        x = torch.squeeze(x)\n",
    "        x1 = F.sigmoid(self.conv1(x, edge_index))\n",
    "        x1 = F.dropout(x1, training=self.training)\n",
    "        x2 = F.sigmoid(self.conv2(x1, edge_index))\n",
    "        #         # x2 = F.dropout(x2, training=self.training)\n",
    "\n",
    "\n",
    "        return x2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put it back into a 2D symmetric array\n",
    "\n",
    "\n",
    "def topological_measures(data):\n",
    "    # ROI is the number of brain regions (i.e.,35 in our case)\n",
    "    ROI = 160\n",
    "\n",
    "    topology = []\n",
    "\n",
    "\n",
    "\n",
    "    # A = to_2d(data)\n",
    "    np.fill_diagonal(data, 0)\n",
    "\n",
    "    # create a graph from similarity matrix\n",
    "    G = nx.from_numpy_matrix(np.absolute(data))\n",
    "    U = G.to_undirected()\n",
    "\n",
    "    # Centrality #\n",
    "\n",
    "    # compute closeness centrality and transform the output to vector\n",
    "    cc = nx.closeness_centrality(U, distance=\"weight\")\n",
    "    closeness_centrality = np.array([cc[g] for g in U])\n",
    "    # compute betweeness centrality and transform the output to vector\n",
    "    # bc = nx.betweenness_centrality(U, weight='weight')\n",
    "    # bc = (nx.betweenness_centrality(U))\n",
    "    betweenness_centrality = np.array([cc[g] for g in U])\n",
    "    # # compute egeinvector centrality and transform the output to vector\n",
    "    ec = nx.eigenvector_centrality_numpy(U)\n",
    "    eigenvector_centrality = np.array([ec[g] for g in U])\n",
    "\n",
    "\n",
    "    topology.append(closeness_centrality)  # 0\n",
    "    topology.append(betweenness_centrality)  # 1\n",
    "    topology.append(eigenvector_centrality)  # 2\n",
    "\n",
    "    return topology\n",
    "# put it back into a 2D symmetric array\n",
    "\n",
    "def eigen_centrality(data):\n",
    "    # ROI is the number of brain regions (i.e.,35 in our case)\n",
    "    ROI = 160\n",
    "\n",
    "    topology_eigen = []\n",
    "\n",
    "\n",
    "\n",
    "    # A = to_2d(data)\n",
    "    np.fill_diagonal(data, 0)\n",
    "\n",
    "    # create a graph from similarity matrix\n",
    "    G = nx.from_numpy_matrix(np.absolute(data))\n",
    "    U = G.to_undirected()\n",
    "\n",
    "    # Centrality #\n",
    "\n",
    "\n",
    "    # # compute egeinvector centrality and transform the output to vector\n",
    "    ec = nx.eigenvector_centrality_numpy(U)\n",
    "    eigenvector_centrality = np.array([ec[g] for g in U])\n",
    "\n",
    "\n",
    "\n",
    "    topology_eigen.append(eigenvector_centrality)  # 2\n",
    "\n",
    "    return topology_eigen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"running on GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"running on CPU\")\n",
    "\n",
    "l1_loss = torch.nn.L1Loss()\n",
    "adversarial_loss = torch.nn.BCELoss()\n",
    "adversarial_loss.to(device)\n",
    "l1_loss.to(device)\n",
    "\n",
    "\n",
    "def pearson_coor(input, target):\n",
    "    vx = input - torch.mean(input)\n",
    "    vy = target - torch.mean(target)\n",
    "    cost = torch.sum(vx * vy) / (torch.sqrt(torch.sum(vx ** 2)) * torch.sqrt(torch.sum(vy ** 2)))\n",
    "    return cost\n",
    "\n",
    "\n",
    "def GT_loss(target, predicted):\n",
    "\n",
    "    # l1_loss\n",
    "    loss_pix2pix = l1_loss(target, predicted)\n",
    "\n",
    "    # topological_loss\n",
    "    target_n = target.detach().cpu().clone().numpy()\n",
    "    predicted_n = predicted.detach().cpu().clone().numpy()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    target_t = eigen_centrality(target_n)\n",
    "    real_topology = torch.tensor(target_t)\n",
    "    predicted_t = eigen_centrality(predicted_n)\n",
    "    fake_topology = torch.tensor(predicted_t)\n",
    "    topo_loss = l1_loss(fake_topology, real_topology)\n",
    "\n",
    "    pc_loss = pearson_coor(target, predicted).to(device)\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    G_loss = loss_pix2pix + (1 - pc_loss) + topo_loss\n",
    "\n",
    "    return G_loss\n",
    "\n",
    "\n",
    "def Alignment_loss(target, predicted):\n",
    "    # l_loss1 = torch.abs(nn.KLDivLoss()(F.softmax(zt1), F.softmax(z_s1.t())))\n",
    "\n",
    "    kl_loss = torch.abs(F.kl_div(F.softmax(target), F.softmax(predicted), None, None, 'sum'))\n",
    "    kl_loss = (1/350) * kl_loss\n",
    "    return kl_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "from torch_geometric.data import Data\n",
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "def convert_vector_to_graph_FC(data):\n",
    "    \"\"\"\n",
    "        convert subject vector to adjacency matrix then use it to create a graph\n",
    "        edge_index:\n",
    "        edge_attr:\n",
    "        x:\n",
    "    \"\"\"\n",
    "\n",
    "    data.reshape(1, N_TARGET_NODES_F)\n",
    "    # create adjacency matrix\n",
    "    tri = np.zeros((N_TARGET_NODES, N_TARGET_NODES))\n",
    "    tri[np.triu_indices(N_TARGET_NODES, 1)] = data\n",
    "    tri = tri + tri.T\n",
    "    tri[np.diag_indices(N_TARGET_NODES)] = 1\n",
    "\n",
    "    edge_attr = torch.Tensor(tri).view(N_TARGET_NODES**2, 1)\n",
    "    edge_attr = torch.tensor(edge_attr, dtype=torch.float)\n",
    "    counter = 0\n",
    "    pos_counter = 0\n",
    "    neg_counter = 0\n",
    "    N_ROI = N_TARGET_NODES\n",
    "\n",
    "    pos_edge_index = torch.zeros(2, N_ROI * N_ROI)\n",
    "    neg_edge_indexe = []\n",
    "    # pos_edge_indexe = []\n",
    "    for i in range(N_ROI):\n",
    "        for j in range(N_ROI):\n",
    "            pos_edge_index[:, counter] = torch.tensor([i, j])\n",
    "            counter += 1\n",
    "\n",
    "        # xx = torch.ones(160, 160, dtype=torch.float)\n",
    "\n",
    "        x = torch.tensor(tri, dtype=torch.float)\n",
    "        pos_edge_index = torch.tensor(pos_edge_index, dtype=torch.long)\n",
    "\n",
    "\n",
    "    return Data(x=x, pos_edge_index=pos_edge_index, edge_attr=edge_attr)\n",
    "\n",
    "def convert_vector_to_graph_RH(data):\n",
    "    \"\"\"\n",
    "        convert subject vector to adjacency matrix then use it to create a graph\n",
    "        edge_index:\n",
    "        edge_attr:\n",
    "        x:\n",
    "    \"\"\"\n",
    "\n",
    "    data.reshape(1, N_SOURCE_NODES_F)\n",
    "    # create adjacency matrix\n",
    "    tri = np.zeros((N_SOURCE_NODES, N_SOURCE_NODES))\n",
    "    tri[np.triu_indices(N_SOURCE_NODES, 1)] = data\n",
    "    tri = tri + tri.T\n",
    "    tri[np.diag_indices(N_SOURCE_NODES)] = 1\n",
    "\n",
    "    edge_attr = torch.Tensor(tri).view(N_SOURCE_NODES**2, 1)\n",
    "    edge_attr = torch.tensor(edge_attr, dtype=torch.float)\n",
    "    counter = 0\n",
    "    pos_counter = 0\n",
    "    neg_counter = 0\n",
    "    N_ROI = N_SOURCE_NODES\n",
    "\n",
    "    pos_edge_index = torch.zeros(2, N_ROI * N_ROI)\n",
    "    neg_edge_indexe = []\n",
    "    # pos_edge_indexe = []\n",
    "    for i in range(N_ROI):\n",
    "        for j in range(N_ROI):\n",
    "            pos_edge_index[:, counter] = torch.tensor([i, j])\n",
    "            counter += 1\n",
    "\n",
    "        # xx = torch.ones(160, 160, dtype=torch.float)\n",
    "\n",
    "        x = torch.tensor(tri, dtype=torch.float)\n",
    "        pos_edge_index = torch.tensor(pos_edge_index, dtype=torch.long)\n",
    "\n",
    "        return Data(x=x, pos_edge_index=pos_edge_index, edge_attr=edge_attr)\n",
    "\n",
    "\n",
    "def cast_data_vector_RH(dataset):\n",
    "    \"\"\"\n",
    "        convert subject vectors to graph and append it in a list\n",
    "    \"\"\"\n",
    "\n",
    "    dataset_g = []\n",
    "\n",
    "    for subj in range(dataset.shape[0]):\n",
    "        dataset_g.append(convert_vector_to_graph_RH(dataset[subj]))\n",
    "\n",
    "    return dataset_g\n",
    "\n",
    "def cast_data_vector_FC(dataset):\n",
    "    \"\"\"\n",
    "        convert subject vectors to graph and append it in a list\n",
    "    \"\"\"\n",
    "\n",
    "    dataset_g = []\n",
    "\n",
    "    for subj in range(dataset.shape[0]):\n",
    "        dataset_g.append(convert_vector_to_graph_FC(dataset[subj]))\n",
    "\n",
    "def convert_vector_to_graph_RH_2(data):\n",
    "    \"\"\"\n",
    "        convert subject vector to adjacency matrix then use it to create a graph\n",
    "        edge_index:\n",
    "        edge_attr:\n",
    "        x:\n",
    "    \"\"\"\n",
    "    tri = data\n",
    "\n",
    "    edge_attr = torch.Tensor(tri).view(N_SOURCE_NODES**2, 1)\n",
    "    edge_attr = torch.tensor(edge_attr, dtype=torch.float)\n",
    "    counter = 0\n",
    "    pos_counter = 0\n",
    "    neg_counter = 0\n",
    "    N_ROI = N_SOURCE_NODES\n",
    "\n",
    "    pos_edge_index = torch.zeros(2, N_ROI * N_ROI)\n",
    "    neg_edge_indexe = []\n",
    "    # pos_edge_indexe = []\n",
    "    for i in range(N_ROI):\n",
    "        for j in range(N_ROI):\n",
    "            pos_edge_index[:, counter] = torch.tensor([i, j])\n",
    "            counter += 1\n",
    "\n",
    "        # xx = torch.ones(160, 160, dtype=torch.float)\n",
    "\n",
    "        x = torch.tensor(tri, dtype=torch.float)\n",
    "        pos_edge_index = torch.tensor(pos_edge_index, dtype=torch.long)\n",
    "\n",
    "        return Data(x=x, pos_edge_index=pos_edge_index, edge_attr=edge_attr)\n",
    "\n",
    "\n",
    "#Copied the above functions and adapted the beginning by deleting the part where they\n",
    "#transformed the vector to a matrix\n",
    "def convert_vector_to_graph_FC_2(data):\n",
    "    \"\"\"\n",
    "        convert subject vector to adjacency matrix then use it to create a graph\n",
    "        edge_index:\n",
    "        edge_attr:\n",
    "        x:\n",
    "    \"\"\"\n",
    "    tri = data\n",
    "    edge_attr = torch.Tensor(tri).view(N_TARGET_NODES**2, 1)\n",
    "    edge_attr = torch.tensor(edge_attr, dtype=torch.float)\n",
    "    counter = 0\n",
    "    pos_counter = 0\n",
    "    neg_counter = 0\n",
    "    N_ROI = N_TARGET_NODES\n",
    "\n",
    "    pos_edge_index = torch.zeros(2, N_ROI * N_ROI)\n",
    "    neg_edge_indexe = []\n",
    "    # pos_edge_indexe = []\n",
    "    for i in range(N_ROI):\n",
    "        for j in range(N_ROI):\n",
    "            pos_edge_index[:, counter] = torch.tensor([i, j])\n",
    "            counter += 1\n",
    "\n",
    "        # xx = torch.ones(160, 160, dtype=torch.float)\n",
    "\n",
    "        x = torch.tensor(tri, dtype=torch.float)\n",
    "        pos_edge_index = torch.tensor(pos_edge_index, dtype=torch.long)\n",
    "\n",
    "\n",
    "    return Data(x=x, pos_edge_index=pos_edge_index, edge_attr=edge_attr)\n",
    "\n",
    "\n",
    "def cast_data_vector_RH_2(dataset):\n",
    "    \"\"\"\n",
    "        convert subject vectors to graph and append it in a list\n",
    "    \"\"\"\n",
    "\n",
    "    dataset_g = []\n",
    "\n",
    "    for subj in range(dataset.shape[0]):\n",
    "        dataset_g.append(convert_vector_to_graph_RH_2(dataset[subj]))\n",
    "\n",
    "    return dataset_g\n",
    "\n",
    "def cast_data_vector_FC_2(dataset):\n",
    "    \"\"\"\n",
    "        convert subject vectors to graph and append it in a list\n",
    "    \"\"\"\n",
    "\n",
    "    dataset_g = []\n",
    "\n",
    "    for subj in range(dataset.shape[0]):\n",
    "        dataset_g.append(convert_vector_to_graph_FC_2(dataset[subj]))\n",
    "    return dataset_g\n",
    "\n",
    "\n",
    "\n",
    "def convert_generated_to_graph(data):\n",
    "    \"\"\"\n",
    "        convert generated output from G to a graph\n",
    "    \"\"\"\n",
    "\n",
    "    dataset = []\n",
    "\n",
    "# for data in data1:\n",
    "    counter = 0\n",
    "    N_ROI = N_TARGET_NODES\n",
    "    pos_edge_index = torch.zeros(2, N_ROI * N_ROI, dtype=torch.long)\n",
    "    for i in range(N_ROI):\n",
    "        for j in range(N_ROI):\n",
    "            pos_edge_index[:, counter] = torch.tensor([i, j])\n",
    "            counter += 1\n",
    "\n",
    "    x = data\n",
    "    pos_edge_index = torch.tensor(pos_edge_index, dtype=torch.long)\n",
    "    data = Data(x=x, pos_edge_index= pos_edge_index, edge_attr=data.view(N_TARGET_NODES**2, 1))\n",
    "    dataset.append(data)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def convert_generated_to_graph_Al(data1):\n",
    "    \"\"\"\n",
    "        convert generated output from G to a graph\n",
    "    \"\"\"\n",
    "\n",
    "    dataset = []\n",
    "\n",
    "    # for data in data1:\n",
    "    counter = 0\n",
    "    N_ROI = N_SOURCE_NODES\n",
    "    pos_edge_index = torch.zeros(2, N_ROI * N_ROI, dtype=torch.long)\n",
    "    for i in range(N_ROI):\n",
    "        for j in range(N_ROI):\n",
    "            pos_edge_index[:, counter] = torch.tensor([i, j])\n",
    "            counter += 1\n",
    "\n",
    "    # x = data\n",
    "    pos_edge_index = torch.tensor(pos_edge_index, dtype=torch.long)\n",
    "    data = Data(x=data1, pos_edge_index=pos_edge_index, edge_attr=data1.view(N_SOURCE_NODES*N_SOURCE_NODES, 1))\n",
    "    dataset.append(data)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "#  GAN\n",
    "aligner = Aligner()\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "# Losses\n",
    "adversarial_loss1 = torch.nn.BCELoss()\n",
    "l1_loss = torch.nn.L1Loss()\n",
    "\n",
    "# send 1st GAN to GPU\n",
    "aligner.to(device)\n",
    "generator.to(device)\n",
    "discriminator.to(device)\n",
    "adversarial_loss1.to(device)\n",
    "l1_loss.to(device)\n",
    "\n",
    "Aligner_optimizer = torch.optim.AdamW(aligner.parameters(), lr=0.025, betas=(0.5, 0.999))\n",
    "generator_optimizer = torch.optim.AdamW(generator.parameters(), lr=0.025, betas=(0.5, 0.999))\n",
    "discriminator_optimizer = torch.optim.AdamW(discriminator.parameters(), lr=0.025, betas=(0.5, 0.999))\n",
    "def IMANGraphNet (X_train_source, X_train_target):\n",
    "\n",
    "    #Kept only the training part and used the two new functions here to get the \n",
    "    #the matrix in a dataset then the original funcitons were used in the rest of the training\n",
    "\n",
    "    lr_train = cast_data_vector_RH_2(X_train_source)\n",
    "    #X_casted_test_source = cast_data_vector_RH(X_test_source)\n",
    "    hr_train = cast_data_vector_FC_2(X_train_target)\n",
    "    #X_casted_test_target = cast_data_vector_FC(X_test_target)\n",
    "\n",
    "    aligner.train()\n",
    "    generator.train()\n",
    "    discriminator.train()\n",
    "\n",
    "    nbre_epochs = N_EPOCHS\n",
    "    for epochs in range(nbre_epochs):\n",
    "        print(epochs)\n",
    "        # Train Generator\n",
    "        with torch.autograd.set_detect_anomaly(True):\n",
    "            Al_losses = []\n",
    "\n",
    "\n",
    "            Ge_losses = []\n",
    "            losses_discriminator = []\n",
    "\n",
    "            i = 0\n",
    "           \n",
    "           \n",
    "            for data_source, data_target in zip(lr_train, hr_train):\n",
    "                # print(i)\n",
    "\n",
    "                targett = data_target.edge_attr.view(N_TARGET_NODES, N_TARGET_NODES)\n",
    "                # ************    Domain alignment    ************\n",
    "                A_output = aligner(data_source.to(device))\n",
    "                A_casted = convert_generated_to_graph_Al(A_output)\n",
    "                A_casted = A_casted[0]\n",
    "\n",
    "                target = data_target.edge_attr.view(N_TARGET_NODES, N_TARGET_NODES).detach().cpu().clone().numpy()\n",
    "                target_mean = np.mean(target)\n",
    "                target_std = np.std(target)\n",
    "\n",
    "                d_target = torch.normal(target_mean, target_std, size=(1, N_SOURCE_NODES_F))\n",
    "                dd_target = cast_data_vector_RH(d_target)\n",
    "                dd_target = dd_target[0]\n",
    "                target_d = dd_target.edge_attr.view(N_SOURCE_NODES, N_SOURCE_NODES)\n",
    "\n",
    "                kl_loss = Alignment_loss(target_d.to(device), A_output.to(device))\n",
    "\n",
    "                Al_losses.append(kl_loss)\n",
    "\n",
    "                # ************     Super-resolution    ************\n",
    "                G_output = generator(A_casted.to(device))  # 35 x 35\n",
    "                # print(\"G_output: \", G_output.shape)\n",
    "                G_output_reshaped = (G_output.view(1, N_TARGET_NODES, N_TARGET_NODES, 1).type(torch.FloatTensor)).detach()\n",
    "                G_output_casted = convert_generated_to_graph(G_output_reshaped)\n",
    "                G_output_casted = G_output_casted[0]\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "                Gg_loss = GT_loss(targett, G_output)\n",
    "                torch.cuda.empty_cache()\n",
    "                D_real = discriminator(data_target)\n",
    "                D_fake = discriminator(G_output_casted)\n",
    "                torch.cuda.empty_cache()\n",
    "                G_adversarial = adversarial_loss(D_fake, (torch.ones_like(D_fake, requires_grad=False)))\n",
    "                G_loss = G_adversarial + Gg_loss\n",
    "                Ge_losses.append(G_loss)\n",
    "\n",
    "                D_real_loss = adversarial_loss(D_real, (torch.ones_like(D_real, requires_grad=False)))\n",
    "                # torch.cuda.empty_cache()\n",
    "                D_fake_loss = adversarial_loss(D_fake.detach(), torch.zeros_like(D_fake))\n",
    "                D_loss = (D_real_loss + D_fake_loss) / 2\n",
    "                print(D_loss)\n",
    "                print(G_loss)\n",
    "                # torch.cuda.empty_cache()\n",
    "                losses_discriminator.append(D_loss)\n",
    "                i += 1\n",
    "\n",
    "            # torch.cuda.empty_cache()\n",
    "\n",
    "            generator_optimizer.zero_grad()\n",
    "            Ge_losses = torch.mean(torch.stack(Ge_losses))\n",
    "            Ge_losses.backward(retain_graph=True)\n",
    "            generator_optimizer.step()\n",
    "\n",
    "            Aligner_optimizer.zero_grad()\n",
    "            Al_losses = torch.mean(torch.stack(Al_losses))\n",
    "            Al_losses.backward(retain_graph=True)\n",
    "            Aligner_optimizer.step()\n",
    "\n",
    "\n",
    "            discriminator_optimizer.zero_grad()\n",
    "            losses_discriminator = torch.mean(torch.stack(losses_discriminator))\n",
    "            losses_discriminator.backward(retain_graph=True)\n",
    "            discriminator_optimizer.step()\n",
    "\n",
    "        print(\"[Epoch: %d]| [Al loss: %f]| [Ge loss: %f]| [D loss: %f]\" % (epochs, Al_losses, Ge_losses, losses_discriminator))\n",
    "\n",
    "    torch.save(aligner.state_dict(), \"./weight\" + \"aligner_fold\" + \"_\" + \".model\")\n",
    "    torch.save(generator.state_dict(), \"./weight\" + \"generator_fold\" + \"_\" + \".model\")\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # #     ######################################### TESTING PART #########################################\n",
    "    \"\"\" restore_aligner = \"./weight\" + \"aligner_fold\" + \"_\" + \".model\"\n",
    "    restore_generator = \"./weight\" + \"generator_fold\" + \"_\" + \".model\"\n",
    "\n",
    "    aligner.load_state_dict(torch.load(restore_aligner))\n",
    "    generator.load_state_dict(torch.load(restore_generator))\n",
    "\n",
    "    aligner.eval()\n",
    "    generator.eval()\n",
    "\n",
    "    i = 0\n",
    "    predicted_test_graphs = []\n",
    "    losses_test = []\n",
    "    eigenvector_losses_test = []\n",
    "    l1_tests = []\n",
    "    Closeness_test = []\n",
    "    Eigenvector_test = []\n",
    "    for data_source, data_target in zip(X_casted_test_source, X_casted_test_target):\n",
    "        # print(i)\n",
    "        data_source_test = data_source.x.view(N_SOURCE_NODES, N_SOURCE_NODES)\n",
    "        data_target_test = data_target.x.view(N_TARGET_NODES, N_TARGET_NODES)\n",
    "\n",
    "\n",
    "        A_test = aligner(data_source)\n",
    "        A_test_casted = convert_generated_to_graph_Al(A_test)\n",
    "        A_test_casted = A_test_casted[0]\n",
    "        data_target = data_target_test.detach().cpu().clone().numpy()\n",
    "        # ************     Super-resolution    ************\n",
    "        G_output_test = generator(A_test_casted)  # 35 x35\n",
    "        G_output_test_casted = convert_generated_to_graph(G_output_test)\n",
    "        G_output_test_casted = G_output_test_casted[0]\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        L1_test = l1_loss(data_target_test, G_output_test)\n",
    "        # fold= 1\n",
    "        target_test = data_target_test.detach().cpu().clone().numpy()\n",
    "        predicted_test = G_output_test.detach().cpu().clone().numpy()\n",
    "        source_test = data_source_test.detach().cpu().clone().numpy()\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "        fake_topology_test = torch.tensor(topological_measures(predicted_test))\n",
    "        real_topology_test = torch.tensor(topological_measures(target_test))\n",
    "\n",
    "        eigenvector_test = (l1_loss(fake_topology_test[2], real_topology_test[2]))\n",
    "\n",
    "\n",
    "        l1_tests.append(L1_test.detach().cpu().numpy())\n",
    "        Eigenvector_test.append(eigenvector_test.detach().cpu().numpy())\n",
    "\n",
    "\n",
    "\n",
    "    mean_l1 = np.mean(l1_tests)\n",
    "    mean_eigenvector = np.mean(Eigenvector_test)\n",
    "\n",
    "    # print(\"Mean L1 Loss Test: \", fold_mean_l1_loss)\n",
    "    # print()\n",
    "\n",
    "    losses_test.append(mean_l1)\n",
    "    eigenvector_losses_test.append(mean_eigenvector) \"\"\"\n",
    "\n",
    "    # fold += 1\n",
    "    return (aligner, generator, discriminator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 2.44 GiB. GPU 0 has a total capacity of 15.70 GiB of which 1.88 GiB is free. Process 942360 has 2.81 GiB memory in use. Process 955824 has 2.96 GiB memory in use. Including non-PyTorch memory, this process has 7.83 GiB memory in use. Of the allocated memory 5.15 GiB is allocated by PyTorch, and 2.40 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 31\u001b[0m\n\u001b[1;32m     25\u001b[0m eigenvector_losses_test \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m#for train_index, test_index in kf.split(source_data):\u001b[39;00m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;66;03m# print( * \"#\" + \" FOLD \" + str(fold) + \" \" +  * \"#\")\u001b[39;00m\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;66;03m#X_train_source, X_test_source, X_train_target, X_test_target = source_data[train_index], source_data[test_index], target_data[train_index], target_data[test_index]\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m aligner, generator, discriminator \u001b[38;5;241m=\u001b[39m \u001b[43mIMANGraphNet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlr_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mhr_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m test_mean \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(l1_test)\n\u001b[1;32m     37\u001b[0m Eigenvector_test_mean \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(eigenvector_test)\n",
      "Cell \u001b[0;32mIn[9], line 68\u001b[0m, in \u001b[0;36mIMANGraphNet\u001b[0;34m(X_train_source, X_train_target)\u001b[0m\n\u001b[1;32m     65\u001b[0m Al_losses\u001b[38;5;241m.\u001b[39mappend(kl_loss)\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# ************     Super-resolution    ************\u001b[39;00m\n\u001b[0;32m---> 68\u001b[0m G_output \u001b[38;5;241m=\u001b[39m \u001b[43mgenerator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA_casted\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 35 x 35\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# print(\"G_output: \", G_output.shape)\u001b[39;00m\n\u001b[1;32m     70\u001b[0m G_output_reshaped \u001b[38;5;241m=\u001b[39m (G_output\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1\u001b[39m, N_TARGET_NODES, N_TARGET_NODES, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mtype(torch\u001b[38;5;241m.\u001b[39mFloatTensor))\u001b[38;5;241m.\u001b[39mdetach()\n",
      "File \u001b[0;32m/vol/bitbucket/se223/DGL24-Group-Project/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/vol/bitbucket/se223/DGL24-Group-Project/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[5], line 66\u001b[0m, in \u001b[0;36mGenerator.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     63\u001b[0m x, edge_index, edge_attr \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mx, data\u001b[38;5;241m.\u001b[39mpos_edge_index, data\u001b[38;5;241m.\u001b[39medge_attr\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# x = torch.squeeze(x)\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m x1 \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msigmoid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv11(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[1;32m     67\u001b[0m x1 \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mdropout(x1, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# x2 = F.sigmoid(self.conv22(self.conv2(x1, edge_index, edge_attr)))\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# x2 = F.dropout(x2, training=self.training)\u001b[39;00m\n",
      "File \u001b[0;32m/vol/bitbucket/se223/DGL24-Group-Project/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/vol/bitbucket/se223/DGL24-Group-Project/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/vol/bitbucket/se223/DGL24-Group-Project/venv/lib/python3.10/site-packages/torch_geometric/nn/conv/nn_conv.py:108\u001b[0m, in \u001b[0;36mNNConv.forward\u001b[0;34m(self, x, edge_index, edge_attr, size)\u001b[0m\n\u001b[1;32m    105\u001b[0m     x \u001b[38;5;241m=\u001b[39m (x, x)\n\u001b[1;32m    107\u001b[0m \u001b[38;5;66;03m# propagate_type: (x: OptPairTensor, edge_attr: OptTensor)\u001b[39;00m\n\u001b[0;32m--> 108\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpropagate\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medge_attr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m x_r \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x_r \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_weight:\n",
      "File \u001b[0;32m~/.cache/pyg/message_passing/torch_geometric.nn.conv.nn_conv_NNConv_propagate.py:167\u001b[0m, in \u001b[0;36mpropagate\u001b[0;34m(self, edge_index, x, edge_attr, size)\u001b[0m\n\u001b[1;32m    158\u001b[0m             kwargs \u001b[38;5;241m=\u001b[39m CollectArgs(\n\u001b[1;32m    159\u001b[0m                 x_j\u001b[38;5;241m=\u001b[39mhook_kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx_j\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    160\u001b[0m                 edge_attr\u001b[38;5;241m=\u001b[39mhook_kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge_attr\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    163\u001b[0m                 dim_size\u001b[38;5;241m=\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mdim_size,\n\u001b[1;32m    164\u001b[0m             )\n\u001b[1;32m    165\u001b[0m \u001b[38;5;66;03m# End Message Forward Pre Hook #########################################\u001b[39;00m\n\u001b[0;32m--> 167\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessage\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_j\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx_j\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m    \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_attr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# Begin Message Forward Hook ###########################################\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_scripting() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_compiling():\n",
      "File \u001b[0;32m/vol/bitbucket/se223/DGL24-Group-Project/venv/lib/python3.10/site-packages/torch_geometric/nn/conv/nn_conv.py:120\u001b[0m, in \u001b[0;36mNNConv.message\u001b[0;34m(self, x_j, edge_attr)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmessage\u001b[39m(\u001b[38;5;28mself\u001b[39m, x_j: Tensor, edge_attr: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 120\u001b[0m     weight \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_attr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m     weight \u001b[38;5;241m=\u001b[39m weight\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_channels_l, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_channels)\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mmatmul(x_j\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m), weight)\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/vol/bitbucket/se223/DGL24-Group-Project/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/vol/bitbucket/se223/DGL24-Group-Project/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/vol/bitbucket/se223/DGL24-Group-Project/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/vol/bitbucket/se223/DGL24-Group-Project/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/vol/bitbucket/se223/DGL24-Group-Project/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/vol/bitbucket/se223/DGL24-Group-Project/venv/lib/python3.10/site-packages/torch/nn/modules/activation.py:101\u001b[0m, in \u001b[0;36mReLU.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/vol/bitbucket/se223/DGL24-Group-Project/venv/lib/python3.10/site-packages/torch/nn/functional.py:1473\u001b[0m, in \u001b[0;36mrelu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m   1471\u001b[0m     result \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu_(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m   1472\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1473\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1474\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 2.44 GiB. GPU 0 has a total capacity of 15.70 GiB of which 1.88 GiB is free. Process 942360 has 2.81 GiB memory in use. Process 955824 has 2.96 GiB memory in use. Including non-PyTorch memory, this process has 7.83 GiB memory in use. Of the allocated memory 5.15 GiB is allocated by PyTorch, and 2.40 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "\"\"\"#Training\"\"\"\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"running on GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"running on CPU\")\n",
    "\n",
    "source_data = np.random.normal(0, 0.5, (N_SUBJECTS, N_SOURCE_NODES_F))\n",
    "target_data = np.random.normal(0, 0.5, (N_SUBJECTS, N_TARGET_NODES_F))\n",
    "\n",
    "kf = KFold(n_splits=3, shuffle=True, random_state=1773)\n",
    "\n",
    "fold = 0\n",
    "losses_test = []\n",
    "closeness_losses_test = []\n",
    "# betweenness_losses_test = []\n",
    "eigenvector_losses_test = []\n",
    "\n",
    "#for train_index, test_index in kf.split(source_data):\n",
    "    # print( * \"#\" + \" FOLD \" + str(fold) + \" \" +  * \"#\")\n",
    "    #X_train_source, X_test_source, X_train_target, X_test_target = source_data[train_index], source_data[test_index], target_data[train_index], target_data[test_index]\n",
    "   \n",
    "aligner, generator, discriminator = IMANGraphNet(lr_train.to(device),  hr_train.to(device))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test_mean = np.mean(l1_test)\n",
    "Eigenvector_test_mean = np.mean(eigenvector_test)\n",
    "plot_source(source_test)\n",
    "plot_target(data_target)\n",
    "plot_target(predicted_test)\n",
    "\n",
    "print(\"Mean L1 Test\", test_mean)\n",
    "\n",
    "print(\"Mean Eigenvector Test\", Eigenvector_test_mean)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
