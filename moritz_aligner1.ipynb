{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from aligner import Aligner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_preparation import load_data_tensor\n",
    "\n",
    "lr_train, lr_test, hr_train = load_data_tensor(\"dgl-icl\")\n",
    "\n",
    "lr_X_dim1 = torch.load('model_autoencoder/final_embeddings/encode_lr.pt')\n",
    "lr_X_dim3 = torch.load('model_autoencoder/final_embeddings/encode_lr_3.pt')\n",
    "hr_X_dim1 = torch.load('model_autoencoder/final_embeddings/encode_hr.pt')\n",
    "hr_X_dim3 = torch.load('model_autoencoder/final_embeddings/encode_hr_3.pt')\n",
    "lr_X_dim1_test = torch.load('model_autoencoder/final_embeddings/encode_lr_test.pt')\n",
    "hr_X_dim3_test = torch.load('model_autoencoder/final_embeddings/encode_lr_test_3.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Sequential, Linear, ReLU, Sigmoid, Tanh, Dropout, Upsample\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch_geometric\n",
    "from torch_geometric.nn import NNConv\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import BatchNorm\n",
    "import numpy as np\n",
    "from torch_geometric.data import Data\n",
    "from torch.autograd import Variable\n",
    "\n",
    "N_SOURCE_NODES = 160\n",
    "N_TARGET_NODES = 268\n",
    "\n",
    "class Aligner(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        \n",
    "        super(Aligner, self).__init__()\n",
    "\n",
    "        nn = Sequential(Linear(1, N_SOURCE_NODES*N_SOURCE_NODES), ReLU())\n",
    "        self.conv1 = NNConv(N_SOURCE_NODES, N_SOURCE_NODES, nn, aggr='mean', root_weight=True, bias=True)\n",
    "        self.conv11 = BatchNorm(N_SOURCE_NODES, eps=1e-03, momentum=0.1, affine=True, track_running_stats=True)\n",
    "\n",
    "        nn = Sequential(Linear(1, N_SOURCE_NODES), ReLU())\n",
    "        self.conv2 = NNConv(N_SOURCE_NODES, 1, nn, aggr='mean', root_weight=True, bias=True)\n",
    "        self.conv22 = BatchNorm(1, eps=1e-03, momentum=0.1, affine=True, track_running_stats=True)\n",
    "\n",
    "        nn = Sequential(Linear(1, N_SOURCE_NODES), ReLU())\n",
    "        self.conv3 = NNConv(1, N_SOURCE_NODES, nn, aggr='mean', root_weight=True, bias=True)\n",
    "        self.conv33 = BatchNorm(N_SOURCE_NODES, eps=1e-03, momentum=0.1, affine=True, track_running_stats=True)\n",
    "\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "\n",
    "        x1 = F.sigmoid(self.conv11(self.conv1(x, edge_index, edge_attr)))\n",
    "        x1 = F.dropout(x1, training=self.training)\n",
    "\n",
    "        x2 = F.sigmoid(self.conv22(self.conv2(x1, edge_index, edge_attr)))\n",
    "        x2 = F.dropout(x2, training=self.training)\n",
    "\n",
    "        x3 = torch.cat([F.sigmoid(self.conv33(self.conv3(x2, edge_index, edge_attr))), x1], dim=1)\n",
    "        x4 = x3[:, 0:N_SOURCE_NODES]\n",
    "        x5 = x3[:, N_SOURCE_NODES:2*N_SOURCE_NODES]\n",
    "\n",
    "        x6 = (x4 + x5) / 2\n",
    "        return x6\n",
    "\n",
    "def create_batch(X, A):\n",
    "    data_list = []\n",
    "    for x, adj in zip(X, A):\n",
    "        edge_index = adj.nonzero().t()\n",
    "        edge_weights = adj[edge_index[0], edge_index[1]]\n",
    "        edge_index, edge_weights = torch_geometric.utils.add_self_loops(edge_index, edge_weights) # add self connections\n",
    "        data = Data(x=x, edge_index=edge_index, edge_attr=edge_weights.view(-1, 1))\n",
    "        data_list.append(data)\n",
    "    return data_list\n",
    "\n",
    "def convert_generated_to_graph(data):\n",
    "    \"\"\"\n",
    "        convert generated output from G to a graph\n",
    "    \"\"\"\n",
    "\n",
    "    dataset = []\n",
    "\n",
    "    for data in data1:\n",
    "        counter = 0\n",
    "        N_ROI = N_TARGET_NODES\n",
    "        pos_edge_index = torch.zeros(2, N_ROI * N_ROI, dtype=torch.long)\n",
    "        for i in range(N_ROI):\n",
    "            for j in range(N_ROI):\n",
    "                pos_edge_index[:, counter] = torch.tensor([i, j])\n",
    "                counter += 1\n",
    "\n",
    "        x = data\n",
    "        pos_edge_index = torch.tensor(pos_edge_index, dtype=torch.long)\n",
    "        data = Data(x=x, pos_edge_index= pos_edge_index, edge_attr=data.view(N_TARGET_NODES**2, 1))\n",
    "        dataset.append(data)\n",
    "\n",
    "    return dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "aligner = Aligner()\n",
    "aligner.to(DEVICE)\n",
    "Aligner_optimizer = torch.optim.AdamW(aligner.parameters(), lr=0.025, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choo Choo Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Aligner(\n",
       "  (conv1): NNConv(160, 160, aggr=mean, nn=Sequential(\n",
       "    (0): Linear(in_features=1, out_features=25600, bias=True)\n",
       "    (1): ReLU()\n",
       "  ))\n",
       "  (conv11): BatchNorm(160)\n",
       "  (conv2): NNConv(160, 1, aggr=mean, nn=Sequential(\n",
       "    (0): Linear(in_features=1, out_features=160, bias=True)\n",
       "    (1): ReLU()\n",
       "  ))\n",
       "  (conv22): BatchNorm(1)\n",
       "  (conv3): NNConv(1, 160, aggr=mean, nn=Sequential(\n",
       "    (0): Linear(in_features=1, out_features=160, bias=True)\n",
       "    (1): ReLU()\n",
       "  ))\n",
       "  (conv33): BatchNorm(160)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aligner.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GlobalStorage' object has no attribute 'pos_edge_index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 17\u001b[0m\n\u001b[1;32m     11\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data_source, data_target \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(lr_data, hr_data):\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# print(i)\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# print(data_source.shape)\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# print(data_target.shape)\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m# ************    Domain alignment    ************\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m     A_output \u001b[38;5;241m=\u001b[39m \u001b[43maligner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_source\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     target \u001b[38;5;241m=\u001b[39m data_target\u001b[38;5;241m.\u001b[39medge_attr\u001b[38;5;241m.\u001b[39mview(N_TARGET_NODES, N_TARGET_NODES)\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mclone()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     20\u001b[0m     target_mean \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(target)\n",
      "File \u001b[0;32m/vol/bitbucket/meh23/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/vol/bitbucket/meh23/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[15], line 35\u001b[0m, in \u001b[0;36mAligner.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, data):\n\u001b[0;32m---> 35\u001b[0m     x, edge_index, edge_attr \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mx, \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpos_edge_index\u001b[49m, data\u001b[38;5;241m.\u001b[39medge_attr\n\u001b[1;32m     37\u001b[0m     x1 \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msigmoid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv11(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x, edge_index, edge_attr)))\n\u001b[1;32m     38\u001b[0m     x1 \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mdropout(x1, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n",
      "File \u001b[0;32m/vol/bitbucket/meh23/.venv/lib/python3.10/site-packages/torch_geometric/data/data.py:559\u001b[0m, in \u001b[0;36mData.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_store\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n\u001b[1;32m    554\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    555\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object was created by an older version of PyG. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    556\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf this error occurred while loading an already existing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    557\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset, remove the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprocessed/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m directory in the dataset\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    558\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroot folder and try again.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 559\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_store\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/vol/bitbucket/meh23/.venv/lib/python3.10/site-packages/torch_geometric/data/storage.py:96\u001b[0m, in \u001b[0;36mBaseStorage.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[key]\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m---> 96\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m     97\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     98\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GlobalStorage' object has no attribute 'pos_edge_index'"
     ]
    }
   ],
   "source": [
    "lr_data = create_batch(lr_X_dim1, lr_train)\n",
    "hr_data = create_batch(hr_X_dim1, hr_train)\n",
    "N_TARGET_NODES = 268\n",
    "nbre_epochs = 50\n",
    "\n",
    "for epochs in range(nbre_epochs):\n",
    "        # Train Generator\n",
    "        with torch.autograd.set_detect_anomaly(True):\n",
    "            Al_losses = []\n",
    "\n",
    "            i = 0\n",
    "            for data_source, data_target in zip(lr_data, hr_data):\n",
    "                # print(i)\n",
    "                # print(data_source.shape)\n",
    "                # print(data_target.shape)\n",
    "                # ************    Domain alignment    ************\n",
    "                A_output = aligner(data_source)\n",
    "\n",
    "                target = data_target\n",
    "                target_mean = np.mean(target)\n",
    "                target_std = np.std(target)\n",
    "\n",
    "                d_target = torch.normal(target_mean, target_std, size=(1, N_SOURCE_NODES_F))\n",
    "                dd_target = cast_data_vector_RH(d_target)\n",
    "                dd_target = dd_target[0]\n",
    "                target_d = dd_target.edge_attr.view(N_SOURCE_NODES, N_SOURCE_NODES)\n",
    "\n",
    "                kl_loss = Alignment_loss(target_d, A_output)\n",
    "\n",
    "                Al_losses.append(kl_loss)\n",
    "                i += 1\n",
    "\n",
    "            torch.cuda.empty_cache()\n",
    "            Aligner_optimizer.zero_grad()\n",
    "            Al_losses = torch.mean(torch.stack(Al_losses))\n",
    "            Al_losses.backward(retain_graph=True)\n",
    "            Aligner_optimizer.step()\n",
    "\n",
    "        print(\"[Epoch: %d]| [Al loss: %f]|\" % (epochs, Al_losses))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
