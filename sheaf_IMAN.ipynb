{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Sequential, Linear, ReLU, Sigmoid, Tanh, Dropout, Upsample\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import NNConv\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import BatchNorm\n",
    "import numpy as np\n",
    "from torch_geometric.data import Data\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from torch.distributions import normal, kl\n",
    "\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import GCNConv, GAE, VGAE, InnerProductDecoder, ARGVA\n",
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd\n",
    "from MatrixVectorizer import MatrixVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set global variables\n",
    "N_SUBJECTS = 167\n",
    "\n",
    "N_LR_NODES = 160\n",
    "\n",
    "N_HR_NODES = 268\n",
    "\n",
    "EPOCHS = 10\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "N_LR_NODES_F = int(N_LR_NODES * (N_LR_NODES-1) / 2)\n",
    "N_HR_NODES_F = int(N_HR_NODES * (N_HR_NODES-1) / 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SheafConvLayer(nn.Module):\n",
    "    def __init__(self, n_nodes, d, f_in, f_out=None):\n",
    "        super().__init__()\n",
    "        self.d = d\n",
    "        self.n_nodes = n_nodes\n",
    "        self.f_in = f_in\n",
    "        self.f_out = f_out\n",
    "        # random init weight matrices\n",
    "        if f_out is None:\n",
    "            f_out = f_in \n",
    "        self.weight1 = nn.Parameter(torch.randn((d, d), device=DEVICE))\n",
    "        self.weight2 = nn.Parameter(torch.randn((f_in, f_out), device=DEVICE))\n",
    "        self.edge_weights = nn.Parameter(torch.randn((n_nodes, n_nodes, d, 2*d), device=DEVICE))\n",
    "\n",
    "\n",
    "    def forward(self, X, adj):\n",
    "        kron_prod = torch.kron(torch.eye(self.n_nodes).to(DEVICE), self.weight1)\n",
    "        L = self.sheaf_laplacian(X, adj)\n",
    "        if self.f_out is None:\n",
    "            return X - F.elu(L @ kron_prod @ X @ self.weight2), L\n",
    "        else:\n",
    "            return F.elu(L @ kron_prod @ X @ self.weight2), L\n",
    "\n",
    "\n",
    "    def sheaf_laplacian(self, X, adj, epsilon=1e-6):\n",
    "        X_reshaped = X.reshape(self.n_nodes, self.d, -1)\n",
    "        idx_pairs = torch.cartesian_prod(torch.arange(self.n_nodes), torch.arange(self.n_nodes))\n",
    "        all_stacked_features = X_reshaped[idx_pairs].reshape(self.n_nodes, self.n_nodes, 2*self.d, -1).to(DEVICE)\n",
    "        lin_trans = F.elu(torch.matmul(self.edge_weights, all_stacked_features))\n",
    "        inner_transpose = torch.transpose(lin_trans, -1, -2)\n",
    "        L_v = -1 * torch.matmul(lin_trans, torch.transpose(inner_transpose, 0, 1))\n",
    "        row_cond = torch.isclose(torch.sum(adj, dim=1), torch.zeros_like(torch.sum(adj, dim=1)))\n",
    "        col_cond = torch.isclose(torch.sum(adj, dim=0), torch.zeros_like(torch.sum(adj, dim=0)))\n",
    "        adj_row_weights = adj / (torch.sum(adj, dim=1)[:, None] + epsilon)\n",
    "        adj_col_weights = adj / (torch.sum(adj, dim=0)[:, None] + epsilon)\n",
    "        # adj_col_weights = torch.where(col_cond[None, :], 0., adj / torch.sum(adj, dim=0)[None, :])\n",
    "        adj_weights = torch.maximum(adj_row_weights * adj_col_weights, torch.zeros_like(adj_row_weights))\n",
    "\n",
    "        adj_diag_weights = adj_row_weights ** 2\n",
    "        diag_blocks = torch.sum(adj_diag_weights[:, :, None, None] * torch.matmul(lin_trans, inner_transpose), dim=1)\n",
    "        L_v[range(self.n_nodes), range(self.n_nodes)] = diag_blocks\n",
    "        return L_v.view(-1, self.n_nodes * self.d)\n",
    "        ### NOTE IGNORE MATRIX NORMALISATION FOR NOW #####\n",
    "        # inv_root_diag_blocks = torch.pow(diag_blocks+epsilon, -1/2)\n",
    "        # normalise_mat = torch.block_diag(*inv_root_diag_blocks)\n",
    "\n",
    "        # return normalise_mat @ L_v.view(-1, self.n_nodes * self.d) @ normalise_mat\n",
    "        ################################################\n",
    "\n",
    "        # laplacian_ls = []\n",
    "        # for v in range(self.n_nodes):\n",
    "        #     L_v = torch.zeros((self.d, self.d)).to(DEVICE)\n",
    "        #     if torch.sum(adj[v]) > 0:\n",
    "        #         for u in range(self.n_nodes):\n",
    "        #             edge_weight = self.edge_weights[v, u]\n",
    "        #             stacked_features = torch.concat((X[v*self.d:(v+1)*self.d], X[u*self.d:(u+1)*self.d]))\n",
    "        #             lin_trans = F.elu(edge_weight @ stacked_features).to(DEVICE)\n",
    "        #             L_v += adj[v, u] * lin_trans @ lin_trans.T\n",
    "        #         laplacian_ls.append(L_v / torch.sum(adj[v]))\n",
    "        #     else:\n",
    "        #         laplacian_ls.append(L_v)\n",
    "\n",
    "        # return torch.block_diag(*laplacian_ls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SheafAligner(nn.Module):\n",
    "    \n",
    "    def __init__(self, d, f):\n",
    "        super().__init__()\n",
    "\n",
    "        self.d = d\n",
    "        self.f = f\n",
    "\n",
    "        self.sheafconv1 = SheafConvLayer(N_LR_NODES, d, f)\n",
    "        self.batchnorm1 = BatchNorm(f)\n",
    "\n",
    "        self.sheafconv2 = SheafConvLayer(N_LR_NODES, d, f)\n",
    "        self.batchnorm2 = BatchNorm(f)\n",
    "\n",
    "        self.sheafconv3 = SheafConvLayer(N_LR_NODES, d, f)\n",
    "        self.batchnorm3 = BatchNorm(f)\n",
    "\n",
    "    def forward(self, X, adj):\n",
    "\n",
    "        x1, L1 = self.sheafconv1(X, adj)\n",
    "        x1 = F.sigmoid(self.batchnorm1(x1))\n",
    "        x1 = F.dropout(x1, training=self.training)\n",
    "\n",
    "        mean_x1 = x1.reshape(N_LR_NODES, self.d, self.f).mean(dim=-1)\n",
    "        adj1 = torch.matmul(mean_x1[:,None, None, :], L1.reshape(N_LR_NODES, N_LR_NODES, self.d, self.d))\n",
    "        adj1 = torch.matmul(adj1, mean_x1[None, :, :, None])\n",
    "        adj1 = F.sigmoid(adj1.squeeze())\n",
    "\n",
    "        x2, L2 = self.sheafconv2(x1, adj1)\n",
    "        x2 = F.sigmoid(self.batchnorm2(x2))\n",
    "        x2 = F.dropout(x2, training=self.training)\n",
    "        \n",
    "        mean_x2 = x2.reshape(N_LR_NODES, self.d, self.f).mean(dim=-1)\n",
    "        adj2 = torch.matmul(mean_x2[:,None, None, :], L2.reshape(N_LR_NODES, N_LR_NODES, self.d, self.d))\n",
    "        adj2 = torch.matmul(adj2, mean_x2[None, :, :, None])\n",
    "        adj2 = F.sigmoid(adj2.squeeze())\n",
    "\n",
    "        x3, L3 = self.sheafconv3(x2, adj2)\n",
    "        x3 = F.sigmoid(self.batchnorm3(x3))\n",
    "\n",
    "        mean_x3 = x3.reshape(N_LR_NODES, self.d, self.f).mean(dim=-1)\n",
    "        adj3 = torch.matmul(mean_x3[:,None, None, :], L3.reshape(N_LR_NODES, N_LR_NODES, self.d, self.d))\n",
    "        adj3 = torch.matmul(adj3, mean_x3[None, :, :, None])\n",
    "        adj3 = F.sigmoid(adj3.squeeze())\n",
    "\n",
    "        # x3 = torch.cat([x3, x1], dim=1)\n",
    "\n",
    "        # x4 = x3[:, 0:16]\n",
    "        # x5 = x3[:, 16:2*16]\n",
    "\n",
    "\n",
    "        return x3, adj3\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SheafGenerator(nn.Module):\n",
    "    def __init__(self, d, f):\n",
    "        super().__init__()\n",
    "\n",
    "        self.d = d\n",
    "        self.f = f\n",
    "        \n",
    "        self.sheafconv1 = SheafConvLayer(N_LR_NODES, d, f)\n",
    "        self.batchnorm1 = BatchNorm(f)\n",
    "\n",
    "        self.sheafconv2 = SheafConvLayer(N_LR_NODES, d, f)\n",
    "        self.batchnorm2 = BatchNorm(f)\n",
    "\n",
    "        self.sheafconv3 = SheafConvLayer(N_LR_NODES, d, f, N_HR_NODES)\n",
    "        self.batchnorm3 = BatchNorm(N_HR_NODES)\n",
    "\n",
    "        self.out_mat = nn.Parameter(torch.randn((N_LR_NODES, 2*N_LR_NODES), device=DEVICE))\n",
    "\n",
    "        self.out_sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "    def forward(self, X, adj):\n",
    "        x1, L1 = self.sheafconv1(X, adj) # returns (d*lr_n) * f\n",
    "        x1 = F.sigmoid(self.batchnorm1(x1))\n",
    "        x1 = F.dropout(x1, p=0.1, training=self.training)\n",
    "\n",
    "        mean_x1 = x1.reshape(N_LR_NODES, self.d, self.f).mean(dim=-1)\n",
    "        adj1 = torch.matmul(mean_x1[:,None, None, :], L1.reshape(N_LR_NODES, N_LR_NODES, self.d, self.d))\n",
    "        adj1 = torch.matmul(adj1, mean_x1[None, :, :, None])\n",
    "        adj1 = F.sigmoid(adj1.squeeze())\n",
    "\n",
    "        x2, L2 = self.sheafconv2(x1, adj1) # returns (d*lr_n) * f\n",
    "        x2 = self.batchnorm2(x2)\n",
    "        x2 = F.sigmoid(x2)\n",
    "        x2 = F.dropout(x2, p=0.1, training=self.training)\n",
    "\n",
    "        mean_x2 = x2.reshape(N_LR_NODES, self.d, self.f).mean(dim=-1)\n",
    "        adj2 = torch.matmul(mean_x2[:,None, None, :], L2.reshape(N_LR_NODES, N_LR_NODES, self.d, self.d))\n",
    "        adj2 = torch.matmul(adj2, mean_x2[None, :, :, None])\n",
    "        adj2 = F.sigmoid(adj2.squeeze())\n",
    "\n",
    "        x3, L3 = self.sheafconv3(x2, adj2) # returns (d*lr_n) * hr_n\n",
    "        x3 = F.sigmoid(self.batchnorm3(x3))\n",
    "\n",
    "        # mean_x3 = x3.reshape(N_LR_NODES, self.d, N_HR_NODES).mean(dim=0).T\n",
    "        # adj3 = torch.matmul(mean_x3[:,None, None, :], L3.reshape(N_HR_NODES, , self.d, self.d))\n",
    "        # adj3 = torch.matmul(adj3, mean_x3[None, :, :, None])\n",
    "        # adj3 = F.sigmoid(adj3.squeeze())\n",
    "\n",
    "        x3 = torch.matmul(self.out_mat, x3)\n",
    "        adj3 = torch.sigmoid(torch.t(x3) @ adj2 @ x3)\n",
    "\n",
    "        return (adj3 + torch.t(adj3)) / 2 # to ensure the matrix is symmetric\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SheafDiscriminator(nn.Module):\n",
    "    def __init__(self, d, f):\n",
    "        super().__init__()\n",
    "\n",
    "        self.d = d\n",
    "        self.f = f\n",
    "\n",
    "        self.sheafconv1 = SheafConvLayer(N_HR_NODES, d, f)\n",
    "        self.sheafconv2 = SheafConvLayer(N_HR_NODES, d, f, 1)\n",
    "        self.out = torch.nn.Linear(2*N_HR_NODES, 1)\n",
    "\n",
    "    def forward(self, X, adj):\n",
    "        x1, L1 = self.sheafconv1(X, adj)\n",
    "        x1 = F.sigmoid(x1)\n",
    "        x1 = F.dropout(x1, p=0.1, training=self.training)\n",
    "\n",
    "        mean_x1 = x1.reshape(N_HR_NODES, self.d, self.f).mean(dim=-1)\n",
    "        adj1 = torch.matmul(mean_x1[:,None, None, :], L1.reshape(N_HR_NODES, N_HR_NODES, self.d, self.d))\n",
    "        adj1 = torch.matmul(adj1, mean_x1[None, :, :, None])\n",
    "        adj1 = F.sigmoid(adj1.squeeze())\n",
    "        x2 = self.batchnorm2(x2)\n",
    "\n",
    "\n",
    "        x2, L2 = self.sheafconv2(x1, adj)\n",
    "        x2 = F.sigmoid(x2).flatten()\n",
    "        x3 = F.sigmoid(self.out(x2))\n",
    "        return x3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearson_coor(input, target, epsilon=1e-7):\n",
    "    vx = input - torch.mean(input, dim=(1, 2))[:, None, None]\n",
    "    vy = target - torch.mean(target, dim=(1, 2))[:, None, None]\n",
    "    cost = torch.sum(vx * vy) / (torch.sqrt(torch.sum(vx ** 2)+epsilon) * torch.sqrt(torch.sum(vy ** 2)+epsilon)+epsilon)\n",
    "    return cost\n",
    "\n",
    "def GT_loss(target, predicted):\n",
    "\n",
    "    # l1_loss\n",
    "    l1_loss = torch.nn.L1Loss()\n",
    "    loss_pix2pix = l1_loss(target, predicted)\n",
    "\n",
    "    # topological_loss\n",
    "    target_n = target.detach().cpu().clone().numpy()\n",
    "    predicted_n = predicted.detach().cpu().clone().numpy()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    topo_loss = []\n",
    "    \n",
    "\n",
    "    for i in range(len(target_n)):\n",
    "\n",
    "        cur_target = target_n[i]\n",
    "        cur_predicted = predicted_n[i]\n",
    "\n",
    "        target_t = eigen_centrality(cur_target)\n",
    "        real_topology = torch.tensor(target_t[0])\n",
    "        predicted_t = eigen_centrality(cur_predicted)\n",
    "        fake_topology = torch.tensor(predicted_t[0])\n",
    "        topo_loss.append(l1_loss(real_topology, fake_topology))\n",
    "\n",
    "    topo_loss = torch.sum(torch.stack(topo_loss))\n",
    "\n",
    "    pc_loss = pearson_coor(target, predicted).to(DEVICE)\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    G_loss = loss_pix2pix + (1 - pc_loss) + topo_loss\n",
    "\n",
    "    return G_loss\n",
    "        x2 = self.batchnorm2(x2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "\n",
    "# put it back into a 2D symmetric array\n",
    "\n",
    "\n",
    "def topological_measures(data):\n",
    "    # ROI is the number of brain regions (i.e.,35 in our case)\n",
    "    ROI = 160\n",
    "\n",
    "    topology = []\n",
    "\n",
    "\n",
    "\n",
    "    # A = to_2d(data)\n",
    "    np.fill_diagonal(data, 0)\n",
    "\n",
    "    # create a graph from similarity matrix\n",
    "    G = nx.from_numpy_matrix(np.absolute(data))\n",
    "    U = G.to_undirected()\n",
    "\n",
    "    # Centrality #\n",
    "\n",
    "    # compute closeness centrality and transform the output to vector\n",
    "    cc = nx.closeness_centrality(U, distance=\"weight\")\n",
    "    closeness_centrality = np.array([cc[g] for g in U])\n",
    "    # compute betweeness centrality and transform the output to vector\n",
    "    # bc = nx.betweenness_centrality(U, weight='weight')\n",
    "    # bc = (nx.betweenness_centrality(U))\n",
    "    betweenness_centrality = np.array([cc[g] for g in U])\n",
    "    # # compute egeinvector centrality and transform the output to vector\n",
    "    ec = nx.eigenvector_centrality_numpy(U)\n",
    "    eigenvector_centrality = np.array([ec[g] for g in U])\n",
    "\n",
    "\n",
    "    topology.append(closeness_centrality)  # 0\n",
    "    topology.append(betweenness_centrality)  # 1\n",
    "    topology.append(eigenvector_centrality)  # 2\n",
    "\n",
    "    return topology\n",
    "# put it back into a 2D symmetric array\n",
    "\n",
    "def eigen_centrality(data):\n",
    "    # ROI is the number of brain regions (i.e.,35 in our case)\n",
    "    ROI = 160\n",
    "\n",
    "    topology_eigen = []\n",
    "\n",
    "    G = nx.from_numpy_array(np.absolute(data))\n",
    "    U = G.to_undirected()\n",
    "\n",
    "    # A = to_2d(data)\n",
    "    np.fill_diagonal(data, 0)\n",
    "\n",
    "    # create a graph frL2\n",
    "    # # compute egeinvector centrality and transform the output to vector\n",
    "    ec = nx.eigenvector_centrality_numpy(U)\n",
    "    \n",
    "    eigenvector_centrality = np.array([ec[g] for g in U])\n",
    "\n",
    "\n",
    "\n",
    "    topology_eigen.append(eigenvector_centrality)  # 2\n",
    "\n",
    "    return topology_eigen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_model(model):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "def unfreeze_model(model):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.randn((2*N_LR_NODES, 16))\n",
    "adj = lr_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "SheafAligner.__init__() missing 1 required positional argument: 'f'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m aligner \u001b[38;5;241m=\u001b[39m \u001b[43mSheafAligner\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m aligned \u001b[38;5;241m=\u001b[39m aligner(X\u001b[38;5;241m.\u001b[39mto(DEVICE), adj\u001b[38;5;241m.\u001b[39mto(DEVICE)) \u001b[38;5;66;03m# should return (n_lr * d) * f matrix\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: SheafAligner.__init__() missing 1 required positional argument: 'f'"
     ]
    }
   ],
   "source": [
    "aligner = SheafAligner(2).to('cuda')\n",
    "aligned = aligner(X.to(DEVICE), adj.to(DEVICE)) # should return (n_lr * d) * f matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'aligned' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43maligned\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'aligned' is not defined"
     ]
    }
   ],
   "source": [
    "aligned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = SheafGenerator(2).to('cuda')\n",
    "generated = generator(aligned, adj.to(DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([268, 268])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = torch.randn((N_HR_NODES*2, 16))\n",
    "discriminator = SheafDiscriminator(2).to('cuda')\n",
    "dis_decision = discriminator(Y.to(DEVICE), generated.to(DEVICE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_preparation import load_data_tensor\n",
    "\n",
    "lr_train, lr_test, hr_train = load_data_tensor(\"dgl-icl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_X_dim1 = torch.load('model_autoencoder/encode_lr_1.pt')\n",
    "lr_X_dim2 = torch.load('model_autoencoder/encode_lr_2.pt')\n",
    "hr_X_dim1 = torch.load('model_autoencoder/encode_hr_1.pt')\n",
    "hr_X_dim2 = torch.load('model_autoencoder/encode_hr_2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_X_dim1 = lr_X_dim1.detach()\n",
    "lr_X_dim2 = lr_X_dim2.detach()\n",
    "hr_X_dim1 = hr_X_dim1.detach()\n",
    "hr_X_dim2 = hr_X_dim2.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_X_all = torch.empty((167, 320, 32))\n",
    "for i in range(len(lr_X_dim1)):\n",
    "    a, b = lr_X_dim1[i], lr_X_dim2[i]\n",
    "    lr_X_all[i] = torch.cat([a, b], dim=-1).view(-1, a.shape[-1])\n",
    "\n",
    "hr_X_all = torch.empty((167, 536, 32))\n",
    "for i in range(len(hr_X_dim1)):\n",
    "    a, b = hr_X_dim1[i], hr_X_dim2[i]\n",
    "    hr_X_all[i] = torch.cat([a, b], dim=-1).view(-1, a.shape[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begin Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 2 # number of dimensions in each node\n",
    "f = 32 # length of node encoding\n",
    "\n",
    "aligner = SheafAligner(d, f).to(DEVICE)\n",
    "generator = SheafGenerator(d, f).to(DEVICE)\n",
    "discriminator = SheafDiscriminator(d, f).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2445361"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in aligner.parameters()) + sum(p.numel() for p in generator.parameters()) + sum(p.numel() for p in discriminator.parameters()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "aligner_optimizer = torch.optim.AdamW(aligner.parameters(), lr=0.025, betas=(0.5, 0.999))\n",
    "generator_optimizer = torch.optim.AdamW(generator.parameters(), lr=0.025, betas=(0.5, 0.999))\n",
    "discriminator_optimizer = torch.optim.AdamW(discriminator.parameters(), lr=0.025, betas=(0.5, 0.999))\n",
    "\n",
    "adversarial_loss = torch.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/se223/DGL24-Group-Project/venv/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: Error detected in SigmoidBackward0. Traceback of forward call that caused the error:\n",
      "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/vol/bitbucket/se223/DGL24-Group-Project/venv/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/vol/bitbucket/se223/DGL24-Group-Project/venv/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/vol/bitbucket/se223/DGL24-Group-Project/venv/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/vol/bitbucket/se223/DGL24-Group-Project/venv/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/vol/bitbucket/se223/DGL24-Group-Project/venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/vol/bitbucket/se223/DGL24-Group-Project/venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/vol/bitbucket/se223/DGL24-Group-Project/venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/vol/bitbucket/se223/DGL24-Group-Project/venv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 359, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/vol/bitbucket/se223/DGL24-Group-Project/venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/vol/bitbucket/se223/DGL24-Group-Project/venv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 446, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/vol/bitbucket/se223/DGL24-Group-Project/venv/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/vol/bitbucket/se223/DGL24-Group-Project/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/vol/bitbucket/se223/DGL24-Group-Project/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/vol/bitbucket/se223/DGL24-Group-Project/venv/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/vol/bitbucket/se223/DGL24-Group-Project/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/vol/bitbucket/se223/DGL24-Group-Project/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/vol/bitbucket/se223/DGL24-Group-Project/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_1585551/3040723124.py\", line 12, in <module>\n",
      "    aligned_X_lr, aligned_adj_lr = aligner(X_lr.to(DEVICE), adj_lr.to(DEVICE))\n",
      "  File \"/vol/bitbucket/se223/DGL24-Group-Project/venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/vol/bitbucket/se223/DGL24-Group-Project/venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_1585551/3350063542.py\", line 39, in forward\n",
      "    x3 = F.sigmoid(self.batchnorm3(x3))\n",
      "  File \"/vol/bitbucket/se223/DGL24-Group-Project/venv/lib/python3.10/site-packages/torch/nn/functional.py\", line 1983, in sigmoid\n",
      "    return input.sigmoid()\n",
      " (Triggered internally at ../torch/csrc/autograd/python_anomaly_mode.cpp:113.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[101], line 64\u001b[0m\n\u001b[1;32m     61\u001b[0m g_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     62\u001b[0m generator_optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 64\u001b[0m \u001b[43malignment_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# alignment_loss.backward()\u001b[39;00m\n\u001b[1;32m     66\u001b[0m aligner_optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m/vol/bitbucket/se223/DGL24-Group-Project/venv/lib/python3.10/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/vol/bitbucket/se223/DGL24-Group-Project/venv/lib/python3.10/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
     ]
    }
   ],
   "source": [
    "aligner.train()\n",
    "generator.train()\n",
    "discriminator.train()\n",
    "    \n",
    "with torch.autograd.set_detect_anomaly(True):\n",
    "    for i, sample in enumerate(zip(lr_X_all, lr_train, hr_X_all, hr_train)):\n",
    "        X_lr, adj_lr, X_hr, adj_hr = sample\n",
    "        aligner_optimizer.zero_grad()\n",
    "        generator_optimizer.zero_grad()\n",
    "        discriminator_optimizer.zero_grad()\n",
    "\n",
    "        aligned_X_lr, aligned_adj_lr = aligner(X_lr.to(DEVICE), adj_lr.to(DEVICE))\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        hr_mean = torch.mean(X_hr)\n",
    "        hr_std = torch.std(X_hr)\n",
    "\n",
    "        adj_hr_sampled = torch.normal(hr_mean, hr_std, size=(N_LR_NODES, N_LR_NODES)).to(DEVICE)\n",
    "        # hr_X_sampled = torch.Tensor(MatrixVectorizer().anti_vectorize(hr_X_sampled, N_HR_NODES))\n",
    "\n",
    "\n",
    "        alignment_loss = torch.abs(F.kl_div(F.softmax(adj_hr_sampled, dim=-1), F.softmax(aligned_adj_lr, dim=-1), None, None, 'sum'))\n",
    "\n",
    "\n",
    "\n",
    "        # generate hr adjacency\n",
    "        generated_adj_hr = generator(aligned_X_lr.to(DEVICE), adj_lr.to(DEVICE))\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "        # calculate losses for generator\n",
    "\n",
    "        #### NOTE TEMPORARY MEASURE BECAUSE THEY TAKE IN (BATCHSIZE, xx, xx) shape ####\n",
    "        temp_adj_hr = adj_hr.reshape(1, *adj_hr.shape)\n",
    "        temp_generated_adj_hr = generated_adj_hr.reshape(1, *generated_adj_hr.shape)\n",
    "        ##########################################################\n",
    "\n",
    "        g_topology_loss = GT_loss(temp_adj_hr.to(DEVICE), temp_generated_adj_hr.to(DEVICE))\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        d_real = discriminator(X_hr.to(DEVICE), adj_hr.to(DEVICE))\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        d_fake = discriminator(X_hr.to(DEVICE), generated_adj_hr.to(DEVICE))\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        g_adversarial_loss = adversarial_loss(d_fake, (torch.ones_like(d_fake, requires_grad=False)))\n",
    "        g_loss = g_adversarial_loss + g_topology_loss\n",
    "\n",
    "\n",
    "\n",
    "        d_real_loss = adversarial_loss(d_real, torch.ones_like(d_real, requires_grad=False))\n",
    "        torch.cuda.empty_cache()\n",
    "        d_fake_loss = adversarial_loss(d_fake, torch.zeros_like(d_fake, requires_grad=False))\n",
    "        d_loss = (d_real_loss + d_fake_loss) / 2\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "\n",
    "        # g_loss.backward(retain_graph=True)\n",
    "        g_loss.backward()\n",
    "        generator_optimizer.step()\n",
    "\n",
    "        alignment_loss.backward(retain_graph=True)\n",
    "        # alignment_loss.backward()\n",
    "        aligner_optimizer.step()\n",
    "\n",
    "        # d_loss.backward(retain_graph=True)\n",
    "        d_loss.backward()\n",
    "        discriminator_optimizer.step()\n",
    "\n",
    "        print(f'sample {i}: align_loss = {alignment_loss}, generator_loss = {g_loss}, discriminator = {d_loss}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
