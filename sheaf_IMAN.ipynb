{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Sequential, Linear, ReLU, Sigmoid, Tanh, Dropout, Upsample\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import NNConv\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import BatchNorm\n",
    "import numpy as np\n",
    "from torch_geometric.data import Data\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from torch.distributions import normal, kl\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import GCNConv, GAE, VGAE, InnerProductDecoder, ARGVA\n",
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd\n",
    "from MatrixVectorizer import MatrixVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set global variables\n",
    "N_SUBJECTS = 167\n",
    "\n",
    "N_LR_NODES = 160\n",
    "\n",
    "N_HR_NODES = 268\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "N_LR_NODES_F = int(N_LR_NODES * (N_LR_NODES-1) / 2)\n",
    "N_HR_NODES_F = int(N_HR_NODES * (N_HR_NODES-1) / 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SheafConvLayer(nn.Module):\n",
    "    def __init__(self, n_nodes, d, f_in, f_out=None):\n",
    "        super().__init__()\n",
    "        self.d = d\n",
    "        self.n_nodes = n_nodes\n",
    "        self.f_in = f_in\n",
    "        self.f_out = f_out\n",
    "        # random init weight matrices\n",
    "        if f_out is None:\n",
    "            f_out = f_in \n",
    "        self.weight1 = nn.Parameter(torch.randn((d, d), device=DEVICE))\n",
    "        self.weight2 = nn.Parameter(torch.randn((f_in, f_out), device=DEVICE))\n",
    "        self.edge_weights = nn.Parameter(torch.randn((n_nodes, n_nodes, d, 2*d), device=DEVICE))\n",
    "\n",
    "\n",
    "    def forward(self, X, adj):\n",
    "        kron_prod = torch.kron(torch.eye(self.n_nodes).to(DEVICE), self.weight1)\n",
    "        L = self.sheaf_laplacian(X, adj)\n",
    "        if self.f_out is None:\n",
    "            return X - F.elu(L @ kron_prod @ X @ self.weight2), L\n",
    "        else:\n",
    "            return F.elu(L @ kron_prod @ X @ self.weight2), L\n",
    "\n",
    "\n",
    "    def sheaf_laplacian(self, X, adj, epsilon=1e-6):\n",
    "        X_reshaped = X.reshape(self.n_nodes, self.d, -1)\n",
    "        idx_pairs = torch.cartesian_prod(torch.arange(self.n_nodes), torch.arange(self.n_nodes))\n",
    "        all_stacked_features = X_reshaped[idx_pairs].reshape(self.n_nodes, self.n_nodes, 2*self.d, -1).to(DEVICE)\n",
    "        lin_trans = F.elu(torch.matmul(self.edge_weights, all_stacked_features))\n",
    "        inner_transpose = torch.transpose(lin_trans, -1, -2)\n",
    "        L_v = -1 * torch.matmul(lin_trans, torch.transpose(inner_transpose, 0, 1))\n",
    "        row_cond = torch.isclose(torch.sum(adj, dim=1), torch.zeros_like(torch.sum(adj, dim=1)))\n",
    "        col_cond = torch.isclose(torch.sum(adj, dim=0), torch.zeros_like(torch.sum(adj, dim=0)))\n",
    "        adj_row_weights = adj / (torch.sum(adj, dim=1)[:, None] + epsilon)\n",
    "        adj_col_weights = adj / (torch.sum(adj, dim=0)[:, None] + epsilon)\n",
    "        # adj_col_weights = torch.where(col_cond[None, :], 0., adj / torch.sum(adj, dim=0)[None, :])\n",
    "        adj_weights = torch.maximum(adj_row_weights * adj_col_weights, torch.zeros_like(adj_row_weights))\n",
    "\n",
    "        adj_diag_weights = adj_row_weights ** 2\n",
    "        diag_blocks = torch.sum(adj_diag_weights[:, :, None, None] * torch.matmul(lin_trans, inner_transpose), dim=1)\n",
    "        L_v[range(self.n_nodes), range(self.n_nodes)] = diag_blocks\n",
    "        return L_v.view(-1, self.n_nodes * self.d)\n",
    "        ### NOTE IGNORE MATRIX NORMALISATION FOR NOW #####\n",
    "        # inv_root_diag_blocks = torch.pow(diag_blocks+epsilon, -1/2)\n",
    "        # normalise_mat = torch.block_diag(*inv_root_diag_blocks)\n",
    "\n",
    "        # return normalise_mat @ L_v.view(-1, self.n_nodes * self.d) @ normalise_mat\n",
    "        ################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SheafAligner(nn.Module):\n",
    "    \n",
    "    def __init__(self, d, f):\n",
    "        super().__init__()\n",
    "\n",
    "        self.d = d\n",
    "        self.f = f\n",
    "\n",
    "        self.sheafconv1 = SheafConvLayer(N_LR_NODES, d, f)\n",
    "        self.batchnorm1 = BatchNorm(f)\n",
    "\n",
    "        self.sheafconv2 = SheafConvLayer(N_LR_NODES, d, f)\n",
    "        self.batchnorm2 = BatchNorm(f)\n",
    "\n",
    "        self.sheafconv3 = SheafConvLayer(N_LR_NODES, d, f)\n",
    "        self.batchnorm3 = BatchNorm(f)\n",
    "\n",
    "    def forward(self, X, adj):\n",
    "\n",
    "        x1, L1 = self.sheafconv1(X, adj)\n",
    "        x1 = F.sigmoid(self.batchnorm1(x1))\n",
    "        x1 = F.dropout(x1, training=self.training)\n",
    "\n",
    "        mean_x1 = x1.reshape(N_LR_NODES, self.d, self.f).mean(dim=-1)\n",
    "        adj1 = torch.matmul(mean_x1[:,None, None, :], L1.reshape(N_LR_NODES, N_LR_NODES, self.d, self.d))\n",
    "        adj1 = torch.matmul(adj1, mean_x1[None, :, :, None])\n",
    "        adj1 = F.sigmoid(adj1.squeeze())\n",
    "\n",
    "        x2, L2 = self.sheafconv2(x1, adj1)\n",
    "        x2 = F.sigmoid(self.batchnorm2(x2))\n",
    "        x2 = F.dropout(x2, training=self.training)\n",
    "        \n",
    "        mean_x2 = x2.reshape(N_LR_NODES, self.d, self.f).mean(dim=-1)\n",
    "        adj2 = torch.matmul(mean_x2[:,None, None, :], L2.reshape(N_LR_NODES, N_LR_NODES, self.d, self.d))\n",
    "        adj2 = torch.matmul(adj2, mean_x2[None, :, :, None])\n",
    "        adj2 = F.sigmoid(adj2.squeeze())\n",
    "\n",
    "        x3, L3 = self.sheafconv3(x2, adj2)\n",
    "        x3 = F.sigmoid(self.batchnorm3(x3))\n",
    "\n",
    "        mean_x3 = x3.reshape(N_LR_NODES, self.d, self.f).mean(dim=-1)\n",
    "        adj3 = torch.matmul(mean_x3[:,None, None, :], L3.reshape(N_LR_NODES, N_LR_NODES, self.d, self.d))\n",
    "        adj3 = torch.matmul(adj3, mean_x3[None, :, :, None])\n",
    "        adj3 = F.sigmoid(adj3.squeeze())\n",
    "\n",
    "        # x3 = torch.cat([x3, x1], dim=1)\n",
    "\n",
    "        # x4 = x3[:, 0:16]\n",
    "        # x5 = x3[:, 16:2*16]\n",
    "\n",
    "\n",
    "        return x3, adj3\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SheafGenerator(nn.Module):\n",
    "    def __init__(self, d, f):\n",
    "        super().__init__()\n",
    "\n",
    "        self.d = d\n",
    "        self.f = f\n",
    "        \n",
    "        self.sheafconv1 = SheafConvLayer(N_LR_NODES, d, f)\n",
    "        self.batchnorm1 = BatchNorm(f)\n",
    "\n",
    "        self.sheafconv2 = SheafConvLayer(N_LR_NODES, d, f)\n",
    "        self.batchnorm2 = BatchNorm(f)\n",
    "\n",
    "        self.sheafconv3 = SheafConvLayer(N_LR_NODES, d, f, N_HR_NODES)\n",
    "        self.batchnorm3 = BatchNorm(N_HR_NODES)\n",
    "\n",
    "        self.out_mat = nn.Parameter(torch.randn((N_LR_NODES, 2*N_LR_NODES), device=DEVICE))\n",
    "\n",
    "        self.out_sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "    def forward(self, X, adj):\n",
    "        x1, L1 = self.sheafconv1(X, adj) # returns (d*lr_n) * f\n",
    "        x1 = F.sigmoid(self.batchnorm1(x1))\n",
    "        x1 = F.dropout(x1, p=0.1, training=self.training)\n",
    "\n",
    "        mean_x1 = x1.reshape(N_LR_NODES, self.d, self.f).mean(dim=-1)\n",
    "        adj1 = torch.matmul(mean_x1[:,None, None, :], L1.reshape(N_LR_NODES, N_LR_NODES, self.d, self.d))\n",
    "        adj1 = torch.matmul(adj1, mean_x1[None, :, :, None])\n",
    "        adj1 = F.sigmoid(adj1.squeeze())\n",
    "\n",
    "        x2, L2 = self.sheafconv2(x1, adj1) # returns (d*lr_n) * f\n",
    "        x2 = F.sigmoid(self.batchnorm2(x2))\n",
    "        x2 = F.dropout(x2, p=0.1, training=self.training)\n",
    "\n",
    "        mean_x2 = x2.reshape(N_LR_NODES, self.d, self.f).mean(dim=-1)\n",
    "        adj2 = torch.matmul(mean_x2[:,None, None, :], L2.reshape(N_LR_NODES, N_LR_NODES, self.d, self.d))\n",
    "        adj2 = torch.matmul(adj2, mean_x2[None, :, :, None])\n",
    "        adj2 = F.sigmoid(adj2.squeeze())\n",
    "\n",
    "        x3, L3 = self.sheafconv3(x2, adj2) # returns (d*lr_n) * hr_n\n",
    "        x3 = F.sigmoid(self.batchnorm3(x3))\n",
    "\n",
    "        x3 = torch.matmul(self.out_mat, x3)\n",
    "        adj3 = torch.sigmoid(torch.t(x3) @ adj2 @ x3)\n",
    "\n",
    "        return (adj3 + torch.t(adj3)) / 2 # to ensure the matrix is symmetric\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SheafDiscriminator(nn.Module):\n",
    "    def __init__(self, d, f):\n",
    "        super().__init__()\n",
    "\n",
    "        self.d = d\n",
    "        self.f = f\n",
    "\n",
    "        self.sheafconv1 = SheafConvLayer(N_HR_NODES, d, f)\n",
    "        self.sheafconv2 = SheafConvLayer(N_HR_NODES, d, f, 1)\n",
    "        self.out = torch.nn.Linear(2*N_HR_NODES, 1)\n",
    "\n",
    "    def forward(self, X, adj):\n",
    "        x1, L1 = self.sheafconv1(X, adj)\n",
    "        x1 = F.sigmoid(x1)\n",
    "        x1 = F.dropout(x1, p=0.1, training=self.training)\n",
    "\n",
    "        mean_x1 = x1.reshape(N_HR_NODES, self.d, self.f).mean(dim=-1)\n",
    "        adj1 = torch.matmul(mean_x1[:,None, None, :], L1.reshape(N_HR_NODES, N_HR_NODES, self.d, self.d))\n",
    "        adj1 = torch.matmul(adj1, mean_x1[None, :, :, None])\n",
    "        adj1 = F.sigmoid(adj1.squeeze())\n",
    "\n",
    "\n",
    "        x2, L2 = self.sheafconv2(x1, adj)\n",
    "        x2 = F.sigmoid(x2).flatten()\n",
    "        x3 = F.sigmoid(self.out(x2))\n",
    "        return x3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearson_coor(input, target, epsilon=1e-7):\n",
    "    vx = input - torch.mean(input, dim=(1, 2))[:, None, None]\n",
    "    vy = target - torch.mean(target, dim=(1, 2))[:, None, None]\n",
    "    cost = torch.sum(vx * vy) / (torch.sqrt(torch.sum(vx ** 2)+epsilon) * torch.sqrt(torch.sum(vy ** 2)+epsilon)+epsilon)\n",
    "    return cost\n",
    "\n",
    "def GT_loss(target, predicted):\n",
    "\n",
    "    # l1_loss\n",
    "    l1_loss = torch.nn.L1Loss()\n",
    "    loss_pix2pix = l1_loss(target, predicted)\n",
    "\n",
    "    # topological_loss\n",
    "    target_n = target.detach().cpu().clone().numpy()\n",
    "    predicted_n = predicted.detach().cpu().clone().numpy()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    topo_loss = []\n",
    "    \n",
    "\n",
    "    for i in range(len(target_n)):\n",
    "\n",
    "        cur_target = target_n[i]\n",
    "        cur_predicted = predicted_n[i]\n",
    "\n",
    "        target_t = eigen_centrality(cur_target)\n",
    "        real_topology = torch.tensor(target_t[0])\n",
    "        predicted_t = eigen_centrality(cur_predicted)\n",
    "        fake_topology = torch.tensor(predicted_t[0])\n",
    "        topo_loss.append(l1_loss(real_topology, fake_topology))\n",
    "\n",
    "    topo_loss = torch.sum(torch.stack(topo_loss))\n",
    "\n",
    "    pc_loss = pearson_coor(target, predicted).to(DEVICE)\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    G_loss = loss_pix2pix + (1 - pc_loss) + topo_loss\n",
    "\n",
    "    return G_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "\n",
    "# put it back into a 2D symmetric array\n",
    "\n",
    "\n",
    "def topological_measures(data):\n",
    "    # ROI is the number of brain regions (i.e.,35 in our case)\n",
    "    ROI = 160\n",
    "\n",
    "    topology = []\n",
    "\n",
    "\n",
    "\n",
    "    # A = to_2d(data)\n",
    "    np.fill_diagonal(data, 0)\n",
    "\n",
    "    # create a graph from similarity matrix\n",
    "    G = nx.from_numpy_matrix(np.absolute(data))\n",
    "    U = G.to_undirected()\n",
    "\n",
    "    # Centrality #\n",
    "\n",
    "    # compute closeness centrality and transform the output to vector\n",
    "    cc = nx.closeness_centrality(U, distance=\"weight\")\n",
    "    closeness_centrality = np.array([cc[g] for g in U])\n",
    "    # compute betweeness centrality and transform the output to vector\n",
    "    # bc = nx.betweenness_centrality(U, weight='weight')\n",
    "    # bc = (nx.betweenness_centrality(U))\n",
    "    betweenness_centrality = np.array([cc[g] for g in U])\n",
    "    # # compute egeinvector centrality and transform the output to vector\n",
    "    ec = nx.eigenvector_centrality_numpy(U)\n",
    "    eigenvector_centrality = np.array([ec[g] for g in U])\n",
    "\n",
    "\n",
    "    topology.append(closeness_centrality)  # 0\n",
    "    topology.append(betweenness_centrality)  # 1\n",
    "    topology.append(eigenvector_centrality)  # 2\n",
    "\n",
    "    return topology\n",
    "# put it back into a 2D symmetric array\n",
    "\n",
    "def eigen_centrality(data):\n",
    "    # ROI is the number of brain regions (i.e.,35 in our case)\n",
    "    ROI = 160\n",
    "\n",
    "    topology_eigen = []\n",
    "\n",
    "    G = nx.from_numpy_array(np.absolute(data))\n",
    "    U = G.to_undirected()\n",
    "\n",
    "    # A = to_2d(data)\n",
    "    np.fill_diagonal(data, 0)\n",
    "\n",
    "    # create a graph frL2\n",
    "    # # compute egeinvector centrality and transform the output to vector\n",
    "    ec = nx.eigenvector_centrality_numpy(U)\n",
    "    \n",
    "    eigenvector_centrality = np.array([ec[g] for g in U])\n",
    "\n",
    "\n",
    "\n",
    "    topology_eigen.append(eigenvector_centrality)  # 2\n",
    "\n",
    "    return topology_eigen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_model(model):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "def unfreeze_model(model):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_preparation import load_data_tensor\n",
    "\n",
    "lr_train, lr_test, hr_train = load_data_tensor(\"dgl-icl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_X_dim1 = torch.load('model_autoencoder/encode_lr_1.pt')\n",
    "lr_X_dim2 = torch.load('model_autoencoder/encode_lr_2.pt')\n",
    "hr_X_dim1 = torch.load('model_autoencoder/encode_hr_1.pt')\n",
    "hr_X_dim2 = torch.load('model_autoencoder/encode_hr_2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_X_dim1 = lr_X_dim1.detach()\n",
    "lr_X_dim2 = lr_X_dim2.detach()\n",
    "hr_X_dim1 = hr_X_dim1.detach()\n",
    "hr_X_dim2 = hr_X_dim2.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_X_all = torch.empty((167, 320, 32))\n",
    "for i in range(len(lr_X_dim1)):\n",
    "    a, b = lr_X_dim1[i], lr_X_dim2[i]\n",
    "    lr_X_all[i] = torch.cat([a, b], dim=-1).view(-1, a.shape[-1])\n",
    "\n",
    "hr_X_all = torch.empty((167, 536, 32))\n",
    "for i in range(len(hr_X_dim1)):\n",
    "    a, b = hr_X_dim1[i], hr_X_dim2[i]\n",
    "    hr_X_all[i] = torch.cat([a, b], dim=-1).view(-1, a.shape[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begin Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 2 # number of dimensions in each node\n",
    "f = 32 # length of node encoding\n",
    "BATCHSIZE = 1\n",
    "N_TRAIN_SAMPLES = len(lr_train)\n",
    "EPOCHS = 10\n",
    "\n",
    "\n",
    "aligner = SheafAligner(d, f).to(DEVICE)\n",
    "generator = SheafGenerator(d, f).to(DEVICE)\n",
    "discriminator = SheafDiscriminator(d, f).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2445361"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in aligner.parameters()) + sum(p.numel() for p in generator.parameters()) + sum(p.numel() for p in discriminator.parameters()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aligner_optimizer = torch.optim.AdamW(aligner.parameters(), lr=0.0001, betas=(0.5, 0.999))\n",
    "generator_optimizer = torch.optim.AdamW(list(aligner.parameters()) + list(generator.parameters()), lr=0.001, betas=(0.5, 0.999))\n",
    "# generator_optimizer = torch.optim.AdamW(generator.parameters(), lr=0.0001, betas=(0.5, 0.999))\n",
    "discriminator_optimizer = torch.optim.AdamW(discriminator.parameters(), lr=0.001, betas=(0.5, 0.999))\n",
    "\n",
    "adversarial_loss = torch.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "167it [01:30,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample 166: align_loss = 2.2779397764605678, generator_loss = 4.297052858447212, discriminator = 0.7001583790350817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "167it [01:27,  1.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample 166: align_loss = 2.2759501177393746, generator_loss = 4.308342304972839, discriminator = 0.7017527158388834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "167it [01:29,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample 166: align_loss = 2.273845638343674, generator_loss = 4.300948695404031, discriminator = 0.6967396721868457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "167it [01:29,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample 166: align_loss = 2.272154424004926, generator_loss = 4.3013737910897625, discriminator = 0.7050466169854124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "167it [01:30,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample 166: align_loss = 2.2709390817288155, generator_loss = 4.287943477996801, discriminator = 0.7018628702192249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "167it [01:29,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample 166: align_loss = 2.2700527185451485, generator_loss = 4.2931852012868195, discriminator = 0.7052331481151238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "167it [01:29,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample 166: align_loss = 2.269451432599279, generator_loss = 4.287606989296893, discriminator = 0.6968093246756913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "167it [01:30,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample 166: align_loss = 2.2690015667212937, generator_loss = 4.288538918223221, discriminator = 0.6939879841433314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "167it [01:30,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample 166: align_loss = 2.268679653099197, generator_loss = 4.288750791450956, discriminator = 0.6971237456013343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "167it [01:30,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample 166: align_loss = 2.2684369843877006, generator_loss = 4.290398674295217, discriminator = 0.7004004256454056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "aligner.train()\n",
    "generator.train()\n",
    "discriminator.train()\n",
    "    \n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "    alignment_loss_ls = []\n",
    "    generator_loss_ls = []\n",
    "    disciriminator_loss_ls = []\n",
    "\n",
    "    for i, sample in tqdm(enumerate(zip(lr_X_all, lr_train, hr_X_all, hr_train))):\n",
    "\n",
    "        # aligner_optimizer.zero_grad()\n",
    "        generator_optimizer.zero_grad()\n",
    "        discriminator_optimizer.zero_grad()\n",
    "\n",
    "        X_lr, adj_lr, X_hr, adj_hr = sample\n",
    "\n",
    "        aligned_X_lr, aligned_adj_lr = aligner(X_lr.to(DEVICE), adj_lr.to(DEVICE))\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        hr_mean = torch.mean(X_hr)\n",
    "        hr_std = torch.std(X_hr)\n",
    "\n",
    "        adj_hr_sampled = torch.normal(hr_mean, hr_std, size=(N_LR_NODES, N_LR_NODES)).to(DEVICE)\n",
    "        # hr_X_sampled = torch.Tensor(MatrixVectorizer().anti_vectorize(hr_X_sampled, N_HR_NODES))\n",
    "\n",
    "\n",
    "        alignment_loss = torch.abs(F.kl_div(F.softmax(adj_hr_sampled, dim=-1), F.softmax(aligned_adj_lr, dim=-1), None, None, 'sum'))\n",
    "        alignment_loss = alignment_loss / 350\n",
    "\n",
    "        alignment_loss_ls.append(alignment_loss.detach().item())\n",
    "\n",
    "        # generate hr adjacency\n",
    "        generated_adj_hr = generator(aligned_X_lr.to(DEVICE), aligned_adj_lr.to(DEVICE))\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        freeze_model(generator)\n",
    "        freeze_model(aligner)\n",
    "        unfreeze_model(discriminator)\n",
    "\n",
    "        d_real = discriminator(X_hr.to(DEVICE), adj_hr.to(DEVICE))\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        d_fake = discriminator(X_hr.to(DEVICE), generated_adj_hr.to(DEVICE))\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        d_real_loss = adversarial_loss(d_real, torch.ones_like(d_real, requires_grad=False))\n",
    "        torch.cuda.empty_cache()\n",
    "        d_fake_loss = adversarial_loss(d_fake, torch.zeros_like(d_fake, requires_grad=False))\n",
    "        d_loss = (d_real_loss + d_fake_loss) / 2\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        disciriminator_loss_ls.append(d_loss.detach().item())\n",
    "\n",
    "        d_loss.backward(retain_graph=True)\n",
    "        discriminator_optimizer.step()\n",
    "\n",
    "        unfreeze_model(generator)\n",
    "        unfreeze_model(aligner)\n",
    "        freeze_model(discriminator)\n",
    "\n",
    "        ### NOTE TEMPORARY MEASURE BECAUSE THEY TAKE IN (BATCHSIZE, xx, xx) shape ####\n",
    "        temp_adj_hr = adj_hr.reshape(1, *adj_hr.shape)\n",
    "        temp_generated_adj_hr = generated_adj_hr.reshape(1, *generated_adj_hr.shape)\n",
    "        ##########################################################\n",
    "\n",
    "        g_topology_loss = GT_loss(temp_adj_hr.to(DEVICE), temp_generated_adj_hr.to(DEVICE))\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        d_fake = discriminator(X_hr.to(DEVICE), generated_adj_hr.to(DEVICE))\n",
    "\n",
    "        g_adversarial_loss = adversarial_loss(d_fake, (torch.ones_like(d_fake)))\n",
    "        g_loss = g_adversarial_loss + g_topology_loss + alignment_loss\n",
    "\n",
    "        generator_loss_ls.append(g_loss.detach().item())\n",
    "\n",
    "      \n",
    "        g_loss.backward()\n",
    "        generator_optimizer.step()\n",
    "\n",
    "    avg_align_loss = np.mean(alignment_loss_ls)\n",
    "    avg_generator_loss = np.mean(generator_loss_ls)\n",
    "    avg_discriminator_loss = np.mean(disciriminator_loss_ls)\n",
    "\n",
    "    print(f'sample {i}: align_loss = {avg_align_loss}, generator_loss = {avg_generator_loss}, discriminator = {avg_discriminator_loss}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(aligner, generator, discriminator, train_X_lr, train_adj_lr, train_X_hr, train_adj_hr, generator_optim, discriminator_optimizer, adversarial_loss=torch.nn.BCELoss()):\n",
    "    aligner.train()\n",
    "    generator.train()\n",
    "    discriminator.train()\n",
    "\n",
    "    train_data = (train_X_lr, train_adj_lr, train_X_hr, train_adj_hr)\n",
    "        \n",
    "    for epoch in range(EPOCHS):\n",
    "\n",
    "        alignment_loss_ls = []\n",
    "        generator_loss_ls = []\n",
    "        disciriminator_loss_ls = []\n",
    "\n",
    "\n",
    "\n",
    "        for i, sample in tqdm(enumerate(zip(*train_data))):\n",
    "\n",
    "            generator_optimizer.zero_grad()\n",
    "            discriminator_optimizer.zero_grad()\n",
    "\n",
    "            X_lr, adj_lr, X_hr, adj_hr = sample\n",
    "\n",
    "            aligned_X_lr, aligned_adj_lr = aligner(X_lr.to(DEVICE), adj_lr.to(DEVICE))\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            hr_mean = torch.mean(X_hr)\n",
    "            hr_std = torch.std(X_hr)\n",
    "\n",
    "            adj_hr_sampled = torch.normal(hr_mean, hr_std, size=(N_LR_NODES, N_LR_NODES)).to(DEVICE)\n",
    "\n",
    "\n",
    "            alignment_loss = torch.abs(F.kl_div(F.softmax(adj_hr_sampled, dim=-1), F.softmax(aligned_adj_lr, dim=-1), None, None, 'sum'))\n",
    "            alignment_loss = alignment_loss / 350\n",
    "\n",
    "            alignment_loss_ls.append(alignment_loss.detach().item())\n",
    "\n",
    "            # generate hr adjacency\n",
    "            generated_adj_hr = generator(aligned_X_lr.to(DEVICE), aligned_adj_lr.to(DEVICE))\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            freeze_model(generator)\n",
    "            freeze_model(aligner)\n",
    "            unfreeze_model(discriminator)\n",
    "\n",
    "            d_real = discriminator(X_hr.to(DEVICE), adj_hr.to(DEVICE))\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            d_fake = discriminator(X_hr.to(DEVICE), generated_adj_hr.to(DEVICE))\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            d_real_loss = adversarial_loss(d_real, torch.ones_like(d_real, requires_grad=False))\n",
    "            torch.cuda.empty_cache()\n",
    "            d_fake_loss = adversarial_loss(d_fake, torch.zeros_like(d_fake, requires_grad=False))\n",
    "            d_loss = (d_real_loss + d_fake_loss) / 2\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            disciriminator_loss_ls.append(d_loss.detach().item())\n",
    "\n",
    "            d_loss.backward(retain_graph=True)\n",
    "            discriminator_optimizer.step()\n",
    "\n",
    "            unfreeze_model(generator)\n",
    "            unfreeze_model(aligner)\n",
    "            freeze_model(discriminator)\n",
    "\n",
    "            ### NOTE TEMPORARY MEASURE BECAUSE THEY TAKE IN (BATCHSIZE, xx, xx) shape ####\n",
    "            temp_adj_hr = adj_hr.reshape(1, *adj_hr.shape)\n",
    "            temp_generated_adj_hr = generated_adj_hr.reshape(1, *generated_adj_hr.shape)\n",
    "            ##########################################################\n",
    "\n",
    "            g_topology_loss = GT_loss(temp_adj_hr.to(DEVICE), temp_generated_adj_hr.to(DEVICE))\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            d_fake = discriminator(X_hr.to(DEVICE), generated_adj_hr.to(DEVICE))\n",
    "\n",
    "            g_adversarial_loss = adversarial_loss(d_fake, (torch.ones_like(d_fake)))\n",
    "            g_loss = g_adversarial_loss + g_topology_loss + alignment_loss\n",
    "\n",
    "            generator_loss_ls.append(g_loss.detach().item())\n",
    "\n",
    "        n_samples\n",
    "            g_loss.backward(retain_graph=True)\n",
    "            generator_optimizer.step()\n",
    "\n",
    "        avg_align_loss = np.mean(alignment_loss_ls)\n",
    "        avg_generator_loss = np.mean(generator_loss_ls)\n",
    "        avg_discriminator_loss = np.mean(disciriminator_loss_ls)\n",
    "\n",
    "        print(f'sample {i}: align_loss = {avg_align_loss}, generator_loss = {avg_generator_loss}, discriminator = {avg_discriminator_loss}')\n",
    "\n",
    "    return aligner, generator, discriminator\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from evaluation_fn import evaluate_predictions\n",
    "\n",
    "\n",
    "def validation(aligner, generator, val_X_lr, val_adj_lr, val_adj_hr):\n",
    "    aligner.eval()\n",
    "    generator.eval()\n",
    "\n",
    "    all_predictions = torch.empty((len(val_X_lr), N_HR_NODES, N_HR_NODES))\n",
    "\n",
    "    for i in range(len(val_X_lr)):\n",
    "                    \n",
    "        aligned_X_lr, aligned_adj_lr = aligner(val_X_lr[i].to(DEVICE), val_adj_lr[i].to(DEVICE))\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        generated_adj_hr = generator(aligned_X_lr.to(DEVICE), aligned_adj_lr.to(DEVICE))\n",
    "\n",
    "        all_predictions[i] = generated_adj_hr\n",
    "\n",
    "    return evaluate_predictions(all_predictions, val_adj_hr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 15.70 GiB of which 30.75 MiB is free. Process 4068805 has 2.50 GiB memory in use. Including non-PyTorch memory, this process has 12.71 GiB memory in use. Of the allocated memory 11.51 GiB is allocated by PyTorch, and 933.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mvalidation\u001b[49m\u001b[43m(\u001b[49m\u001b[43maligner\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_X_all\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhr_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[28], line 12\u001b[0m, in \u001b[0;36mvalidation\u001b[0;34m(aligner, generator, val_X_lr, val_adj_lr, val_adj_hr)\u001b[0m\n\u001b[1;32m      8\u001b[0m all_predictions \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mempty((\u001b[38;5;28mlen\u001b[39m(val_X_lr), N_HR_NODES, N_HR_NODES))\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(val_X_lr)):\n\u001b[0;32m---> 12\u001b[0m     aligned_X_lr, aligned_adj_lr \u001b[38;5;241m=\u001b[39m \u001b[43maligner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_X_lr\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_adj_lr\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[1;32m     15\u001b[0m     generated_adj_hr \u001b[38;5;241m=\u001b[39m generator(aligned_X_lr\u001b[38;5;241m.\u001b[39mto(DEVICE), aligned_adj_lr\u001b[38;5;241m.\u001b[39mto(DEVICE))\n",
      "File \u001b[0;32m/vol/bitbucket/tcwong/deep_graph_learning/DGL24-Group-Project/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/vol/bitbucket/tcwong/deep_graph_learning/DGL24-Group-Project/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[4], line 20\u001b[0m, in \u001b[0;36mSheafAligner.forward\u001b[0;34m(self, X, adj)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, adj):\n\u001b[0;32m---> 20\u001b[0m     x1, L1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msheafconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     x1 \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msigmoid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatchnorm1(x1))\n\u001b[1;32m     22\u001b[0m     x1 \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mdropout(x1, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n",
      "File \u001b[0;32m/vol/bitbucket/tcwong/deep_graph_learning/DGL24-Group-Project/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/vol/bitbucket/tcwong/deep_graph_learning/DGL24-Group-Project/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[3], line 18\u001b[0m, in \u001b[0;36mSheafConvLayer.forward\u001b[0;34m(self, X, adj)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, adj):\n\u001b[1;32m     17\u001b[0m     kron_prod \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mkron(torch\u001b[38;5;241m.\u001b[39meye(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_nodes)\u001b[38;5;241m.\u001b[39mto(DEVICE), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight1)\n\u001b[0;32m---> 18\u001b[0m     L \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msheaf_laplacian\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     20\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m X \u001b[38;5;241m-\u001b[39m F\u001b[38;5;241m.\u001b[39melu(L \u001b[38;5;241m@\u001b[39m kron_prod \u001b[38;5;241m@\u001b[39m X \u001b[38;5;241m@\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight2), L\n",
      "Cell \u001b[0;32mIn[3], line 29\u001b[0m, in \u001b[0;36mSheafConvLayer.sheaf_laplacian\u001b[0;34m(self, X, adj, epsilon)\u001b[0m\n\u001b[1;32m     27\u001b[0m idx_pairs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcartesian_prod(torch\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_nodes), torch\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_nodes))\n\u001b[1;32m     28\u001b[0m all_stacked_features \u001b[38;5;241m=\u001b[39m X_reshaped[idx_pairs]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_nodes, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_nodes, \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[0;32m---> 29\u001b[0m lin_trans \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43melu\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_stacked_features\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m inner_transpose \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtranspose(lin_trans, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     31\u001b[0m L_v \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(lin_trans, torch\u001b[38;5;241m.\u001b[39mtranspose(inner_transpose, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m/vol/bitbucket/tcwong/deep_graph_learning/DGL24-Group-Project/venv/lib/python3.10/site-packages/torch/nn/functional.py:1564\u001b[0m, in \u001b[0;36melu\u001b[0;34m(input, alpha, inplace)\u001b[0m\n\u001b[1;32m   1562\u001b[0m     result \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39melu_(\u001b[38;5;28minput\u001b[39m, alpha)\n\u001b[1;32m   1563\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1564\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43melu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1565\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 15.70 GiB of which 30.75 MiB is free. Process 4068805 has 2.50 GiB memory in use. Including non-PyTorch memory, this process has 12.71 GiB memory in use. Of the allocated memory 11.51 GiB is allocated by PyTorch, and 933.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "validation(aligner, generator, lr_X_all[:20], lr_train[:20], hr_train[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(n_fold, X_lr, adj_lr, X_hr, adj_hr, d=2, f=32):\n",
    "    kf = KFold(3, shuffle=Ttrainrue, random_state=99)\n",
    "    runs_results = []\n",
    "    for train_idx, val_idx in kf.split(X_lr):\n",
    "        train_X_lr, val_X_lr = X_lr[train_idx], X_lr[val_idx]\n",
    "        train_adj_lr, val_adj_lr = adj_lr[train_idx], adj_lr[val_idx]\n",
    "        train_X_hr = X_hr[train_idx]\n",
    "        train_adj_hr, val_adj_hr = adj_hr[train_idx], adj_hr[val_idx]\n",
    "\n",
    "        aligner = SheafAligner(d, f).to(DEVICE)\n",
    "        generator = SheafGenerator(d, f).to(DEVICE)\n",
    "        discriminator = SheafDiscriminator(d, f).to(DEVICE)\n",
    "\n",
    "        generator_optimizer = torch.optim.AdamW(list(aligner.parameters()) + list(generator.parameters()), lr=0.001, betas=(0.5, 0.999))\n",
    "        discriminator_optimizer = torch.optim.AdamW(discriminator.parameters(), lr=0.001, betas=(0.5, 0.999))        \n",
    "        \n",
    "        aligner, generator, discriminator = train(aligner, generator, discriminator, train_X_lr, train_adj_lr, train_X_hr, train_adj_hr, generator_optim, discriminator_optimizer, adversarial_loss)\n",
    "        val_metrics = validation(aligner, generator, val_X_lr, val_adj_lr, val_adj_hr)\n",
    "        runs_results.append(val_metrics)\n",
    "\n",
    "    return runs_results\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
