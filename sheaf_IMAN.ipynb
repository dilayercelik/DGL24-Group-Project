{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Sequential, Linear, ReLU, Sigmoid, Tanh, Dropout, Upsample\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import NNConv\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import BatchNorm\n",
    "import numpy as np\n",
    "from torch_geometric.data import Data\n",
    "from torch.autograd import Variable\n",
    "import networkx as nx\n",
    "\n",
    "import os.path as osp\n",
    "from scipy.linalg import sqrtm\n",
    "from scipy.stats import wasserstein_distance\n",
    "from torch.distributions import normal, kl\n",
    "\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import GCNConv, GAE, VGAE, InnerProductDecoder, ARGVA\n",
    "from torch_geometric.utils import train_test_split_edges\n",
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_preparation import load_data_tensor\n",
    "\n",
    "lr_train, lr_test, hr_train = load_data_tensor(\"dgl-icl\")\n",
    "\n",
    "# set global variables\n",
    "N_SUBJECTS = 167\n",
    "\n",
    "N_LR_NODES = 160\n",
    "\n",
    "N_HR_NODES = 268\n",
    "\n",
    "EPOCHS = 10\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "N_LR_NODES_F = int(N_LR_NODES * (N_LR_NODES-1) / 2)\n",
    "N_HR_NODES_F = int(N_HR_NODES * (N_HR_NODES-1) / 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SheafConvLayer(nn.Module):\n",
    "    def __init__(self, n_nodes, d, f_in, f_out=None):\n",
    "        super().__init__()\n",
    "        self.d = d\n",
    "        self.n_nodes = n_nodes\n",
    "        self.f_out = f_out\n",
    "        # random init weight matrices\n",
    "        if f_out is None:\n",
    "            f_out = f_in \n",
    "        self.weight1 = nn.Parameter(torch.randn((d, d))).to(DEVICE)\n",
    "        self.weight2 = nn.Parameter(torch.randn((f_in, f_out))).to(DEVICE)\n",
    "        self.edge_weights = nn.Parameter(torch.randn((d*n_nodes,2*d*n_nodes))).to(DEVICE)\n",
    "\n",
    "\n",
    "    def forward(self, X, adj):\n",
    "        kron_prod = torch.kron(torch.eye(self.n_nodes).to(DEVICE), self.weight1)\n",
    "        L = self.sheaf_laplacian(X, adj)\n",
    "        if self.f_out is None:\n",
    "            return X - F.relu(L @ kron_prod @ X @ self.weight2) \n",
    "        else:\n",
    "            return F.relu(L @ kron_prod @ X @ self.weight2) \n",
    "\n",
    "\n",
    "    def sheaf_laplacian(self, X, adj):\n",
    "        laplacian_ls = []\n",
    "        for v in range(self.n_nodes):\n",
    "            L_v = torch.zeros((self.d, self.d)).to(DEVICE)\n",
    "            for u in range(self.n_nodes):\n",
    "                edge_weight = self.edge_weights[v*self.d:(v+1)*self.d, u*2*self.d:(u+1)*2*self.d]\n",
    "                stacked_features = torch.concat((X[v*self.d:(v+1)*self.d], X[u*self.d:(u+1)*self.d]))\n",
    "                lin_trans = F.relu(edge_weight @ stacked_features).to(DEVICE)\n",
    "                L_v += adj[v, u] * lin_trans @ lin_trans.T\n",
    "            laplacian_ls.append(L_v / torch.sum(adj[v]))\n",
    "        return torch.block_diag(*laplacian_ls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SheafAligner(nn.Module):\n",
    "    \n",
    "    def __init__(self, d):\n",
    "        super().__init__()\n",
    "\n",
    "        self.sheafconv1 = SheafConvLayer(N_LR_NODES, d, 16)\n",
    "        self.batchnorm1 = BatchNorm(16)\n",
    "\n",
    "        self.sheafconv2 = SheafConvLayer(N_LR_NODES, d, 16)\n",
    "        self.batchnorm2 = BatchNorm(16)\n",
    "\n",
    "        self.sheafconv3 = SheafConvLayer(N_LR_NODES, d, 16)\n",
    "        self.batchnorm3 = BatchNorm(16)\n",
    "\n",
    "    def forward(self, X, adj):\n",
    "\n",
    "        x1 = self.sheafconv1(X, adj)\n",
    "        x1 = F.sigmoid(self.batchnorm1(x1))\n",
    "        x1 = F.dropout(x1, training=self.training)\n",
    "\n",
    "        x2 = self.sheafconv2(x1, adj)\n",
    "        x2 = F.sigmoid(self.batchnorm2(x2))\n",
    "        x2 = F.dropout(x2, training=self.training)\n",
    "\n",
    "        x3 = self.sheafconv3(x2, adj)\n",
    "        x3 = F.sigmoid(self.batchnorm3(x3))\n",
    "        # x3 = torch.cat([x3, x1], dim=1)\n",
    "\n",
    "        # x4 = x3[:, 0:16]\n",
    "        # x5 = x3[:, 16:2*16]\n",
    "\n",
    "\n",
    "        return x3\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SheafGenerator(nn.Module):\n",
    "    def __init__(self, d):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.sheafconv1 = SheafConvLayer(N_LR_NODES, d, 16)\n",
    "        self.batchnorm1 = BatchNorm(16)\n",
    "\n",
    "        self.sheafconv2 = SheafConvLayer(N_LR_NODES, d, 16)\n",
    "        self.batchnorm2 = BatchNorm(16)\n",
    "\n",
    "        self.sheafconv3 = SheafConvLayer(N_LR_NODES, d, 16, N_HR_NODES)\n",
    "        self.batchnorm3 = BatchNorm(N_HR_NODES)\n",
    "\n",
    "        self.out_mat = nn.Parameter(torch.randn((N_LR_NODES, 2*N_LR_NODES))).to(DEVICE)\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "    def forward(self, X, adj):\n",
    "        x1 = self.sheafconv1(X, adj) # returns (d*lr_n) * 16\n",
    "        x1 = F.sigmoid(self.batchnorm1(x1))\n",
    "        x1 = F.dropout(x1, p=0.1, training=self.training)\n",
    "\n",
    "        x2 = self.sheafconv2(x1, adj) # returns (d*lr_n) * 16\n",
    "        x2 = F.sigmoid(self.batchnorm2(x2))\n",
    "        x2 = F.dropout(x2, p=0.1, training=self.training)\n",
    "\n",
    "        x3 = self.sheafconv3(x2, adj) # returns (d*lr_n) * hr_n\n",
    "        x3 = F.sigmoid(self.batchnorm3(x3))\n",
    "        x3 = F.sigmoid(x3.T @  self.out_mat.T @ adj @ self.out_mat @ x3)\n",
    "\n",
    "        return (x3 + x3.T) / 2 # to ensure the matrix is symmetric\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(N_HR_NODES, N_HR_NODES)\n",
    "        self.conv2 = GCNConv(N_HR_NODES, 1)\n",
    "        self.linear = torch.nn.Linear(N_HR_NODES, 1)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr = data.x, data.pos_edge_index, data.edge_attr\n",
    "        x1 = F.sigmoid(self.conv1(x, edge_index))\n",
    "        x1 = F.dropout(x1, p=0.1)\n",
    "        x2 = F.sigmoid(self.conv2(x1, edge_index))\n",
    "        return x2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEEDS TO CHANGE AND ADAPT\n",
    "class SheafDiscriminator(nn.Module):\n",
    "    def __init__(self, d):\n",
    "        super().__init__()\n",
    "        self.sheafconv1 = SheafConvLayer(N_HR_NODES, d, 16)\n",
    "\n",
    "        self.sheafconv2 = SheafConvLayer(N_HR_NODES, d, 16, 1)\n",
    "        self.out = torch.nn.Linear(2*N_HR_NODES, 1)\n",
    "\n",
    "    def forward(self, X, adj):\n",
    "        x1 = F.sigmoid(self.sheafconv1(X, adj))\n",
    "        x1 = F.dropout(x1, p=0.1, training=self.training)\n",
    "        x2 = F.sigmoid(self.sheafconv2(X, adj))\n",
    "        x3 = F.sigmoid(self.out(x2.flatten()))\n",
    "        return x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = Data(x=torch.randn((3, 3)), pos_edge_index=torch.randint(0, 3, (2, 9)), edge_attr=torch.randn((9, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.randn((2*N_LR_NODES, 16))\n",
    "adj = lr_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "aligner = SheafAligner(2).to('cuda')\n",
    "aligned = aligner(X.to(DEVICE), adj.to(DEVICE)) # should return (n_lr * d) * f matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([320, 16])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aligned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = SheafGenerator(2).to('cuda')\n",
    "generated = generator(aligned, adj.to(DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([268, 268])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = torch.randn((N_HR_NODES*2, 16))\n",
    "discriminator = SheafDiscriminator(2).to('cuda')\n",
    "dis_decision = discriminator(Y.to(DEVICE), generated.to(DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4299], device='cuda:0', grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dis_decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
