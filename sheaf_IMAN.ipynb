{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Sequential, Linear, ReLU, Sigmoid, Tanh, Dropout, Upsample\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import NNConv\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import BatchNorm\n",
    "import numpy as np\n",
    "from torch_geometric.data import Data\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from torch.distributions import normal, kl\n",
    "\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import GCNConv, GAE, VGAE, InnerProductDecoder, ARGVA\n",
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd\n",
    "from MatrixVectorizer import MatrixVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set global variables\n",
    "N_SUBJECTS = 167\n",
    "\n",
    "N_LR_NODES = 160\n",
    "\n",
    "N_HR_NODES = 268\n",
    "\n",
    "EPOCHS = 10\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "N_LR_NODES_F = int(N_LR_NODES * (N_LR_NODES-1) / 2)\n",
    "N_HR_NODES_F = int(N_HR_NODES * (N_HR_NODES-1) / 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SheafConvLayer(nn.Module):\n",
    "    def __init__(self, n_nodes, d, f_in, f_out=None):\n",
    "        super().__init__()\n",
    "        self.d = d\n",
    "        self.n_nodes = n_nodes\n",
    "        self.f_in = f_in\n",
    "        self.f_out = f_out\n",
    "        # random init weight matrices\n",
    "        if f_out is None:\n",
    "            f_out = f_in \n",
    "        self.weight1 = nn.Parameter(torch.randn((d, d), device=DEVICE))\n",
    "        self.weight2 = nn.Parameter(torch.randn((f_in, f_out), device=DEVICE))\n",
    "        self.edge_weights = nn.Parameter(torch.randn((n_nodes, n_nodes, d, 2*d), device=DEVICE))\n",
    "\n",
    "\n",
    "    def forward(self, X, adj):\n",
    "        kron_prod = torch.kron(torch.eye(self.n_nodes).to(DEVICE), self.weight1)\n",
    "        L = self.sheaf_laplacian(X, adj)\n",
    "        if self.f_out is None:\n",
    "            return X - F.elu(L @ kron_prod @ X @ self.weight2) \n",
    "        else:\n",
    "            return F.elu(L @ kron_prod @ X @ self.weight2) \n",
    "\n",
    "\n",
    "    def sheaf_laplacian(self, X, adj, epsilon=1e-6):\n",
    "        X_reshaped = X.reshape(self.n_nodes, self.d, -1)\n",
    "        idx_pairs = torch.cartesian_prod(torch.arange(self.n_nodes), torch.arange(self.n_nodes))\n",
    "        all_stacked_features = X_reshaped[idx_pairs].reshape(self.n_nodes, self.n_nodes, 2*self.d, -1).to(DEVICE)\n",
    "        lin_trans = F.elu(torch.matmul(self.edge_weights, all_stacked_features))\n",
    "        inner_transpose = torch.transpose(lin_trans, -1, -2)\n",
    "        L_v = -1 * torch.matmul(lin_trans, torch.transpose(inner_transpose, 0, 1))\n",
    "        row_cond = torch.isclose(torch.sum(adj, dim=1), torch.zeros_like(torch.sum(adj, dim=1)))\n",
    "        col_cond = torch.isclose(torch.sum(adj, dim=0), torch.zeros_like(torch.sum(adj, dim=0)))\n",
    "        adj_row_weights = adj / (torch.sum(adj, dim=1)[:, None] + epsilon)\n",
    "        adj_col_weights = adj / (torch.sum(adj, dim=0)[:, None] + epsilon)\n",
    "        # adj_col_weights = torch.where(col_cond[None, :], 0., adj / torch.sum(adj, dim=0)[None, :])\n",
    "        adj_weights = torch.maximum(adj_row_weights * adj_col_weights, torch.zeros_like(adj_row_weights))\n",
    "\n",
    "        adj_diag_weights = adj_row_weights ** 2\n",
    "        diag_blocks = torch.sum(adj_diag_weights[:, :, None, None] * torch.matmul(lin_trans, inner_transpose), dim=1)\n",
    "        L_v[range(self.n_nodes), range(self.n_nodes)] = diag_blocks\n",
    "        return L_v.view(-1, self.n_nodes * self.d)\n",
    "        ### NOTE IGNORE MATRIX NORMALISATION FOR NOW #####\n",
    "        # inv_root_diag_blocks = torch.pow(diag_blocks+epsilon, -1/2)\n",
    "        # normalise_mat = torch.block_diag(*inv_root_diag_blocks)\n",
    "\n",
    "        # return normalise_mat @ L_v.view(-1, self.n_nodes * self.d) @ normalise_mat\n",
    "        ################################################\n",
    "\n",
    "        # laplacian_ls = []\n",
    "        # for v in range(self.n_nodes):\n",
    "        #     L_v = torch.zeros((self.d, self.d)).to(DEVICE)\n",
    "        #     if torch.sum(adj[v]) > 0:\n",
    "        #         for u in range(self.n_nodes):\n",
    "        #             edge_weight = self.edge_weights[v, u]\n",
    "        #             stacked_features = torch.concat((X[v*self.d:(v+1)*self.d], X[u*self.d:(u+1)*self.d]))\n",
    "        #             lin_trans = F.elu(edge_weight @ stacked_features).to(DEVICE)\n",
    "        #             L_v += adj[v, u] * lin_trans @ lin_trans.T\n",
    "        #         laplacian_ls.append(L_v / torch.sum(adj[v]))\n",
    "        #     else:\n",
    "        #         laplacian_ls.append(L_v)\n",
    "\n",
    "        # return torch.block_diag(*laplacian_ls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SheafAligner(nn.Module):\n",
    "    \n",
    "    def __init__(self, d, f):\n",
    "        super().__init__()\n",
    "\n",
    "        self.sheafconv1 = SheafConvLayer(N_LR_NODES, d, f)\n",
    "        self.batchnorm1 = BatchNorm(f)\n",
    "\n",
    "        self.sheafconv2 = SheafConvLayer(N_LR_NODES, d, f)\n",
    "        self.batchnorm2 = BatchNorm(f)\n",
    "\n",
    "        self.sheafconv3 = SheafConvLayer(N_LR_NODES, d, f)\n",
    "        self.batchnorm3 = BatchNorm(f)\n",
    "\n",
    "    def forward(self, X, adj):\n",
    "\n",
    "        x1 = self.sheafconv1(X, adj)\n",
    "        x1 = F.sigmoid(self.batchnorm1(x1))\n",
    "        x1 = F.dropout(x1, training=self.training)\n",
    "\n",
    "        x2 = self.sheafconv2(x1, adj)\n",
    "        x2 = F.sigmoid(self.batchnorm2(x2))\n",
    "        x2 = F.dropout(x2, training=self.training)\n",
    "\n",
    "        x3 = self.sheafconv3(x2, adj)\n",
    "        x3 = F.sigmoid(self.batchnorm3(x3))\n",
    "        # x3 = torch.cat([x3, x1], dim=1)\n",
    "\n",
    "        # x4 = x3[:, 0:16]\n",
    "        # x5 = x3[:, 16:2*16]\n",
    "\n",
    "\n",
    "        return x3\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SheafGenerator(nn.Module):\n",
    "    def __init__(self, d, f):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.sheafconv1 = SheafConvLayer(N_LR_NODES, d, f)\n",
    "        self.batchnorm1 = BatchNorm(f)\n",
    "\n",
    "        self.sheafconv2 = SheafConvLayer(N_LR_NODES, d, f)\n",
    "        self.batchnorm2 = BatchNorm(f)\n",
    "\n",
    "        self.sheafconv3 = SheafConvLayer(N_LR_NODES, d, f, N_HR_NODES)\n",
    "        self.batchnorm3 = BatchNorm(N_HR_NODES)\n",
    "\n",
    "        self.out_mat = nn.Parameter(torch.randn((N_LR_NODES, 2*N_LR_NODES), device=DEVICE))\n",
    "\n",
    "        self.out_sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "    def forward(self, X, adj):\n",
    "        x1 = self.sheafconv1(X, adj) # returns (d*lr_n) * f\n",
    "        x1 = F.sigmoid(self.batchnorm1(x1))\n",
    "        x1 = F.dropout(x1, p=0.1, training=self.training)\n",
    "\n",
    "        x2 = self.sheafconv2(x1, adj) # returns (d*lr_n) * f\n",
    "        x2 = F.sigmoid(self.batchnorm2(x2))\n",
    "        x2 = F.dropout(x2, p=0.1, training=self.training)\n",
    "\n",
    "        x3 = self.sheafconv3(x2, adj) # returns (d*lr_n) * hr_n\n",
    "        x3 = F.sigmoid(self.batchnorm3(x3))\n",
    "        x3 = torch.matmul(self.out_mat, x3.clone().detach())\n",
    "        x3 = torch.sigmoid(torch.t(x3) @ adj @ x3)\n",
    "\n",
    "        return (x3 + torch.t(x3)) / 2 # to ensure the matrix is symmetric\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SheafDiscriminator(nn.Module):\n",
    "    def __init__(self, d, f):\n",
    "        super().__init__()\n",
    "        self.sheafconv1 = SheafConvLayer(N_HR_NODES, d, f)\n",
    "\n",
    "        self.sheafconv2 = SheafConvLayer(N_HR_NODES, d, f, 1)\n",
    "        self.out = torch.nn.Linear(2*N_HR_NODES, 1)\n",
    "\n",
    "    def forward(self, X, adj):\n",
    "        x1 = F.sigmoid(self.sheafconv1(X, adj))\n",
    "        x1 = F.dropout(x1, p=0.1, training=self.training)\n",
    "        x2 = F.sigmoid(self.sheafconv2(x1, adj))\n",
    "        x3 = F.sigmoid(self.out(x2.flatten()))\n",
    "        return x3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearson_coor(input, target, epsilon=1e-7):\n",
    "    vx = input - torch.mean(input, dim=(1, 2))[:, None, None]\n",
    "    vy = target - torch.mean(target, dim=(1, 2))[:, None, None]\n",
    "    cost = torch.sum(vx * vy) / (torch.sqrt(torch.sum(vx ** 2)+epsilon) * torch.sqrt(torch.sum(vy ** 2)+epsilon)+epsilon)\n",
    "    return cost\n",
    "\n",
    "def GT_loss(target, predicted):\n",
    "\n",
    "    # l1_loss\n",
    "    l1_loss = torch.nn.L1Loss()\n",
    "    loss_pix2pix = l1_loss(target, predicted)\n",
    "\n",
    "    # topological_loss\n",
    "    target_n = target.detach().cpu().clone().numpy()\n",
    "    predicted_n = predicted.detach().cpu().clone().numpy()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    topo_loss = []\n",
    "    \n",
    "\n",
    "    for i in range(len(target_n)):\n",
    "\n",
    "        cur_target = target_n[i]\n",
    "        cur_predicted = predicted_n[i]\n",
    "\n",
    "        target_t = eigen_centrality(cur_target)\n",
    "        real_topology = torch.tensor(target_t[0])\n",
    "        predicted_t = eigen_centrality(cur_predicted)\n",
    "        fake_topology = torch.tensor(predicted_t[0])\n",
    "        topo_loss.append(l1_loss(real_topology, fake_topology))\n",
    "\n",
    "    topo_loss = torch.sum(torch.stack(topo_loss))\n",
    "\n",
    "    pc_loss = pearson_coor(target, predicted).to(DEVICE)\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    G_loss = loss_pix2pix + (1 - pc_loss) + topo_loss\n",
    "\n",
    "    return G_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "\n",
    "# put it back into a 2D symmetric array\n",
    "\n",
    "\n",
    "def topological_measures(data):\n",
    "    # ROI is the number of brain regions (i.e.,35 in our case)\n",
    "    ROI = 160\n",
    "\n",
    "    topology = []\n",
    "\n",
    "\n",
    "\n",
    "    # A = to_2d(data)\n",
    "    np.fill_diagonal(data, 0)\n",
    "\n",
    "    # create a graph from similarity matrix\n",
    "    G = nx.from_numpy_matrix(np.absolute(data))\n",
    "    U = G.to_undirected()\n",
    "\n",
    "    # Centrality #\n",
    "\n",
    "    # compute closeness centrality and transform the output to vector\n",
    "    cc = nx.closeness_centrality(U, distance=\"weight\")\n",
    "    closeness_centrality = np.array([cc[g] for g in U])\n",
    "    # compute betweeness centrality and transform the output to vector\n",
    "    # bc = nx.betweenness_centrality(U, weight='weight')\n",
    "    # bc = (nx.betweenness_centrality(U))\n",
    "    betweenness_centrality = np.array([cc[g] for g in U])\n",
    "    # # compute egeinvector centrality and transform the output to vector\n",
    "    ec = nx.eigenvector_centrality_numpy(U)\n",
    "    eigenvector_centrality = np.array([ec[g] for g in U])\n",
    "\n",
    "\n",
    "    topology.append(closeness_centrality)  # 0\n",
    "    topology.append(betweenness_centrality)  # 1\n",
    "    topology.append(eigenvector_centrality)  # 2\n",
    "\n",
    "    return topology\n",
    "# put it back into a 2D symmetric array\n",
    "\n",
    "def eigen_centrality(data):\n",
    "    # ROI is the number of brain regions (i.e.,35 in our case)\n",
    "    ROI = 160\n",
    "\n",
    "    topology_eigen = []\n",
    "\n",
    "\n",
    "\n",
    "    # A = to_2d(data)\n",
    "    np.fill_diagonal(data, 0)\n",
    "\n",
    "    # create a graph from similarity matrix\n",
    "    G = nx.from_numpy_array(np.absolute(data))\n",
    "    U = G.to_undirected()\n",
    "\n",
    "    # Centrality #\n",
    "\n",
    "\n",
    "    # # compute egeinvector centrality and transform the output to vector\n",
    "    ec = nx.eigenvector_centrality_numpy(U)\n",
    "    eigenvector_centrality = np.array([ec[g] for g in U])\n",
    "\n",
    "\n",
    "\n",
    "    topology_eigen.append(eigenvector_centrality)  # 2\n",
    "\n",
    "    return topology_eigen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_model(model):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "def unfreeze_model(model):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lr_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m X \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn((\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mN_LR_NODES, \u001b[38;5;241m16\u001b[39m))\n\u001b[0;32m----> 2\u001b[0m adj \u001b[38;5;241m=\u001b[39m \u001b[43mlr_train\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lr_train' is not defined"
     ]
    }
   ],
   "source": [
    "X = torch.randn((2*N_LR_NODES, 16))\n",
    "adj = lr_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aligner = SheafAligner(2).to('cuda')\n",
    "aligned = aligner(X.to(DEVICE), adj.to(DEVICE)) # should return (n_lr * d) * f matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([320, 16])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aligned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = SheafGenerator(2).to('cuda')\n",
    "generated = generator(aligned, adj.to(DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([268, 268])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = torch.randn((N_HR_NODES*2, 16))\n",
    "discriminator = SheafDiscriminator(2).to('cuda')\n",
    "dis_decision = discriminator(Y.to(DEVICE), generated.to(DEVICE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_preparation import load_data_tensor\n",
    "\n",
    "lr_train, lr_test, hr_train = load_data_tensor(\"dgl-icl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_X_dim1 = torch.load('model_autoencoder/encode_lr_1.pt')\n",
    "lr_X_dim2 = torch.load('model_autoencoder/encode_lr_2.pt')\n",
    "hr_X_dim1 = torch.load('model_autoencoder/encode_hr_1.pt')\n",
    "hr_X_dim2 = torch.load('model_autoencoder/encode_hr_2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_X_dim1 = lr_X_dim1.detach()\n",
    "lr_X_dim2 = lr_X_dim2.detach()\n",
    "hr_X_dim1 = hr_X_dim1.detach()\n",
    "hr_X_dim2 = hr_X_dim2.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_X_all = torch.empty((167, 320, 32))\n",
    "for i in range(len(lr_X_dim1)):\n",
    "    a, b = lr_X_dim1[i], lr_X_dim2[i]\n",
    "    lr_X_all[i] = torch.cat([a, b], dim=-1).view(-1, a.shape[-1])\n",
    "\n",
    "hr_X_all = torch.empty((167, 536, 32))\n",
    "for i in range(len(hr_X_dim1)):\n",
    "    a, b = hr_X_dim1[i], hr_X_dim2[i]\n",
    "    hr_X_all[i] = torch.cat([a, b], dim=-1).view(-1, a.shape[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begin Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 2 # number of dimensions in each node\n",
    "f = 32 # length of node encoding\n",
    "aligner = SheafAligner(d, f).to(DEVICE)\n",
    "generator = SheafGenerator(d, f).to(DEVICE)\n",
    "discriminator = SheafDiscriminator(d, f).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2445361"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in aligner.parameters()) + sum(p.numel() for p in generator.parameters()) + sum(p.numel() for p in discriminator.parameters()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "aligner_optimizer = torch.optim.AdamW(aligner.parameters(), lr=0.025, betas=(0.5, 0.999))\n",
    "generator_optimizer = torch.optim.AdamW(generator.parameters(), lr=0.025, betas=(0.5, 0.999))\n",
    "discriminator_optimizer = torch.optim.AdamW(discriminator.parameters(), lr=0.025, betas=(0.5, 0.999))\n",
    "\n",
    "adversarial_loss = torch.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample 0: align_loss = 1114.390625, generator_loss = 2.0100941188028534, discriminator = 0.6892502307891846\n",
      "sample 1: align_loss = 1113.7548828125, generator_loss = 1.4371374339022405, discriminator = 2.243126630783081\n",
      "sample 2: align_loss = 1113.7381591796875, generator_loss = 1.437778169171913, discriminator = 2.1479291915893555\n",
      "sample 3: align_loss = 1113.152587890625, generator_loss = 1.9087855829070923, discriminator = 1.1915571689605713\n",
      "sample 4: align_loss = 1112.8021240234375, generator_loss = 9.57127424844677, discriminator = 4.314239501953125\n",
      "sample 5: align_loss = 1112.4976806640625, generator_loss = 1.8031575555885766, discriminator = 0.7480059862136841\n",
      "sample 6: align_loss = 1112.283203125, generator_loss = 1.6689700331135826, discriminator = 1.7800630331039429\n",
      "sample 7: align_loss = 1111.794677734375, generator_loss = 1.754934936801602, discriminator = 2.4789435863494873\n",
      "sample 8: align_loss = 1111.4129638671875, generator_loss = 1.8014645477823776, discriminator = 1.1307402849197388\n",
      "sample 9: align_loss = 1111.143310546875, generator_loss = 1.8563663393061147, discriminator = 1.2031371593475342\n",
      "sample 10: align_loss = 1110.685546875, generator_loss = 1.9567514937794532, discriminator = 0.888299822807312\n",
      "sample 11: align_loss = 1110.26611328125, generator_loss = 3.215448274003383, discriminator = 0.8230775594711304\n",
      "sample 12: align_loss = 1109.9798583984375, generator_loss = 1.8654624750563626, discriminator = 1.0929113626480103\n",
      "sample 13: align_loss = 1109.38427734375, generator_loss = 1.8149570083009756, discriminator = 3.7595105171203613\n",
      "sample 14: align_loss = 1109.0728759765625, generator_loss = 2.1742256635072623, discriminator = 0.6729744076728821\n",
      "sample 15: align_loss = 1108.529541015625, generator_loss = 2.8794005645144134, discriminator = 0.7472651600837708\n",
      "sample 16: align_loss = 1108.0732421875, generator_loss = 1.69306857349764, discriminator = 1.3783069849014282\n",
      "sample 17: align_loss = 1107.8447265625, generator_loss = 1.729359529901727, discriminator = 2.344050884246826\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[148], line 60\u001b[0m\n\u001b[1;32m     55\u001b[0m d_loss \u001b[38;5;241m=\u001b[39m (d_real_loss \u001b[38;5;241m+\u001b[39m d_fake_loss) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m     56\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[0;32m---> 60\u001b[0m \u001b[43mg_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m generator_optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     63\u001b[0m alignment_loss\u001b[38;5;241m.\u001b[39mbackward(retain_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/vol/bitbucket/tcwong/deep_graph_learning/DGL24-Group-Project/venv/lib/python3.10/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/vol/bitbucket/tcwong/deep_graph_learning/DGL24-Group-Project/venv/lib/python3.10/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "aligner.train()\n",
    "generator.train()\n",
    "discriminator.train()\n",
    "    \n",
    "with torch.autograd.set_detect_anomaly(True):\n",
    "    for i, sample in enumerate(zip(lr_X_all, lr_train, hr_X_all, hr_train)):\n",
    "        X_lr, adj_lr, X_hr, adj_hr = sample\n",
    "        aligner_optimizer.zero_grad()\n",
    "        generator_optimizer.zero_grad()\n",
    "        discriminator_optimizer.zero_grad()\n",
    "\n",
    "        aligned_X_lr = aligner(X_lr.to(DEVICE), adj_lr.to(DEVICE))\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        hr_mean = torch.mean(X_hr)\n",
    "        hr_std = torch.std(X_hr)\n",
    "\n",
    "        hr_X_sampled = torch.normal(hr_mean, hr_std, size=(N_LR_NODES*d, f)).to(DEVICE)\n",
    "        # hr_X_sampled = torch.Tensor(MatrixVectorizer().anti_vectorize(hr_X_sampled, N_HR_NODES))\n",
    "\n",
    "\n",
    "        alignment_loss = torch.abs(F.kl_div(F.softmax(hr_X_sampled, dim=-1), F.softmax(aligned_X_lr, dim=-1), None, None, 'sum'))\n",
    "\n",
    "\n",
    "\n",
    "        # generate hr adjacency\n",
    "        generated_adj_hr = generator(aligned_X_lr.to(DEVICE), adj_lr.to(DEVICE))\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "        # calculate losses for generator\n",
    "\n",
    "        #### NOTE TEMPORARY MEASURE BECAUSE THEY TAKE IN (BATCHSIZE, xx, xx) shape ####\n",
    "        temp_adj_hr = adj_hr.reshape(1, *adj_hr.shape)\n",
    "        temp_generated_adj_hr = generated_adj_hr.reshape(1, *generated_adj_hr.shape)\n",
    "        ##########################################################\n",
    "\n",
    "        g_topology_loss = GT_loss(temp_adj_hr.to(DEVICE), temp_generated_adj_hr.to(DEVICE))\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        d_real = discriminator(X_hr.to(DEVICE), adj_hr.to(DEVICE))\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        d_fake = discriminator(X_hr.to(DEVICE), generated_adj_hr.to(DEVICE))\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        g_adversarial_loss = adversarial_loss(d_fake, (torch.ones_like(d_fake, requires_grad=False)))\n",
    "        g_loss = g_adversarial_loss + g_topology_loss\n",
    "\n",
    "\n",
    "\n",
    "        d_real_loss = adversarial_loss(d_real, torch.ones_like(d_real, requires_grad=False))\n",
    "        torch.cuda.empty_cache()\n",
    "        d_fake_loss = adversarial_loss(d_fake, torch.zeros_like(d_fake, requires_grad=False))\n",
    "        d_loss = (d_real_loss + d_fake_loss) / 2\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "\n",
    "        g_loss.backward(retain_graph=True)\n",
    "        generator_optimizer.step()\n",
    "\n",
    "        alignment_loss.backward(retain_graph=True)\n",
    "        aligner_optimizer.step()\n",
    "\n",
    "        d_loss.backward(retain_graph=True)\n",
    "        discriminator_optimizer.step()\n",
    "\n",
    "        print(f'sample {i}: align_loss = {alignment_loss}, generator_loss = {g_loss}, discriminator = {d_loss}')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
