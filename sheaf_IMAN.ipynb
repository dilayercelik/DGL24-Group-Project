{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Sequential, Linear, ReLU, Sigmoid, Tanh, Dropout, Upsample\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import NNConv\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import BatchNorm\n",
    "import numpy as np\n",
    "from torch_geometric.data import Data\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from torch.distributions import normal, kl\n",
    "\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import GCNConv, GAE, VGAE, InnerProductDecoder, ARGVA\n",
    "from torch_geometric.utils import train_test_split_edges\n",
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd\n",
    "from MatrixVectorizer import MatrixVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_preparation import load_data_tensor\n",
    "\n",
    "lr_train, lr_test, hr_train = load_data_tensor(\"dgl-icl\")\n",
    "\n",
    "# set global variables\n",
    "N_SUBJECTS = 167\n",
    "\n",
    "N_LR_NODES = 160\n",
    "\n",
    "N_HR_NODES = 268\n",
    "\n",
    "EPOCHS = 10\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "N_LR_NODES_F = int(N_LR_NODES * (N_LR_NODES-1) / 2)\n",
    "N_HR_NODES_F = int(N_HR_NODES * (N_HR_NODES-1) / 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_X_dim1 = torch.load('model_autoencoder/encode_lr_1.pt')\n",
    "lr_X_dim2 = torch.load('model_autoencoder/encode_lr_2.pt')\n",
    "hr_X_dim1 = torch.load('model_autoencoder/encode_hr_1.pt')\n",
    "hr_X_dim2 = torch.load('model_autoencoder/encode_hr_2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_X_dim1 = lr_X_dim1.detach()\n",
    "lr_X_dim2 = lr_X_dim2.detach()\n",
    "hr_X_dim1 = hr_X_dim1.detach()\n",
    "hr_X_dim2 = hr_X_dim2.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_X = torch.empty((167, 320, 32))\n",
    "for i in range(len(lr_X_dim1)):\n",
    "    a, b = lr_X_dim1[i], lr_X_dim2[i]\n",
    "    lr_X[i] = torch.cat([a, b], dim=-1).view(-1, a.shape[-1])\n",
    "\n",
    "hr_X = torch.empty((167, 536, 32))\n",
    "for i in range(len(hr_X_dim1)):\n",
    "    a, b = hr_X_dim1[i], hr_X_dim2[i]\n",
    "    hr_X[i] = torch.cat([a, b], dim=-1).view(-1, a.shape[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SheafConvLayer(nn.Module):\n",
    "    def __init__(self, n_nodes, d, f_in, f_out=None):\n",
    "        super().__init__()\n",
    "        self.d = d\n",
    "        self.n_nodes = n_nodes\n",
    "        self.f_out = f_out\n",
    "        # random init weight matrices\n",
    "        if f_out is None:\n",
    "            f_out = f_in \n",
    "        self.weight1 = nn.Parameter(torch.randn((d, d))).to(DEVICE)\n",
    "        self.weight2 = nn.Parameter(torch.randn((f_in, f_out))).to(DEVICE)\n",
    "        self.edge_weights = nn.Parameter(torch.randn((d*n_nodes,2*d*n_nodes))).to(DEVICE)\n",
    "\n",
    "\n",
    "    def forward(self, X, adj):\n",
    "        kron_prod = torch.kron(torch.eye(self.n_nodes).to(DEVICE), self.weight1)\n",
    "        L = self.sheaf_laplacian(X, adj)\n",
    "        if self.f_out is None:\n",
    "            return X - F.relu(L @ kron_prod @ X @ self.weight2) \n",
    "        else:\n",
    "            return F.relu(L @ kron_prod @ X @ self.weight2) \n",
    "\n",
    "\n",
    "    def sheaf_laplacian(self, X, adj):\n",
    "        laplacian_ls = []\n",
    "        for v in range(self.n_nodes):\n",
    "            L_v = torch.zeros((self.d, self.d)).to(DEVICE)\n",
    "            for u in range(self.n_nodes):\n",
    "                edge_weight = self.edge_weights[v*self.d:(v+1)*self.d, u*2*self.d:(u+1)*2*self.d]\n",
    "                stacked_features = torch.concat((X[v*self.d:(v+1)*self.d], X[u*self.d:(u+1)*self.d]))\n",
    "                lin_trans = F.relu(edge_weight @ stacked_features).to(DEVICE)\n",
    "                L_v += adj[v, u] * lin_trans @ lin_trans.T\n",
    "            laplacian_ls.append(L_v / torch.sum(adj[v]))\n",
    "        return torch.block_diag(*laplacian_ls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SheafAligner(nn.Module):\n",
    "    \n",
    "    def __init__(self, d, f):\n",
    "        super().__init__()\n",
    "\n",
    "        self.sheafconv1 = SheafConvLayer(N_LR_NODES, d, f)\n",
    "        self.batchnorm1 = BatchNorm(f)\n",
    "\n",
    "        self.sheafconv2 = SheafConvLayer(N_LR_NODES, d, f)\n",
    "        self.batchnorm2 = BatchNorm(f)\n",
    "\n",
    "        self.sheafconv3 = SheafConvLayer(N_LR_NODES, d, f)\n",
    "        self.batchnorm3 = BatchNorm(f)\n",
    "\n",
    "    def forward(self, X, adj):\n",
    "\n",
    "        x1 = self.sheafconv1(X, adj)\n",
    "        x1 = F.sigmoid(self.batchnorm1(x1))\n",
    "        x1 = F.dropout(x1, training=self.training)\n",
    "\n",
    "        x2 = self.sheafconv2(x1, adj)\n",
    "        x2 = F.sigmoid(self.batchnorm2(x2))\n",
    "        x2 = F.dropout(x2, training=self.training)\n",
    "\n",
    "        x3 = self.sheafconv3(x2, adj)\n",
    "        x3 = F.sigmoid(self.batchnorm3(x3))\n",
    "        # x3 = torch.cat([x3, x1], dim=1)\n",
    "\n",
    "        # x4 = x3[:, 0:16]\n",
    "        # x5 = x3[:, 16:2*16]\n",
    "\n",
    "\n",
    "        return x3\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SheafGenerator(nn.Module):\n",
    "    def __init__(self, d, f):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.sheafconv1 = SheafConvLayer(N_LR_NODES, d, f)\n",
    "        self.batchnorm1 = BatchNorm(f)\n",
    "\n",
    "        self.sheafconv2 = SheafConvLayer(N_LR_NODES, d, f)\n",
    "        self.batchnorm2 = BatchNorm(f)\n",
    "\n",
    "        self.sheafconv3 = SheafConvLayer(N_LR_NODES, d, f, N_HR_NODES)\n",
    "        self.batchnorm3 = BatchNorm(N_HR_NODES)\n",
    "\n",
    "        self.out_mat = nn.Parameter(torch.randn((N_LR_NODES, 2*N_LR_NODES))).to(DEVICE)\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "    def forward(self, X, adj):\n",
    "        x1 = self.sheafconv1(X, adj) # returns (d*lr_n) * 16\n",
    "        x1 = F.sigmoid(self.batchnorm1(x1))\n",
    "        x1 = F.dropout(x1, p=0.1, training=self.training)\n",
    "\n",
    "        x2 = self.sheafconv2(x1, adj) # returns (d*lr_n) * 16\n",
    "        x2 = F.sigmoid(self.batchnorm2(x2))\n",
    "        x2 = F.dropout(x2, p=0.1, training=self.training)\n",
    "\n",
    "        x3 = self.sheafconv3(x2, adj) # returns (d*lr_n) * hr_n\n",
    "        x3 = F.sigmoid(self.batchnorm3(x3))\n",
    "        x3 = F.sigmoid(x3.T @  self.out_mat.T @ adj @ self.out_mat @ x3)\n",
    "\n",
    "        return (x3 + x3.T) / 2 # to ensure the matrix is symmetric\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SheafDiscriminator(nn.Module):\n",
    "    def __init__(self, d, f):\n",
    "        super().__init__()\n",
    "        self.sheafconv1 = SheafConvLayer(N_HR_NODES, d, f)\n",
    "\n",
    "        self.sheafconv2 = SheafConvLayer(N_HR_NODES, d, f, 1)\n",
    "        self.out = torch.nn.Linear(2*N_HR_NODES, 1)\n",
    "\n",
    "    def forward(self, X, adj):\n",
    "        x1 = F.sigmoid(self.sheafconv1(X, adj))\n",
    "        x1 = F.dropout(x1, p=0.1, training=self.training)\n",
    "        x2 = F.sigmoid(self.sheafconv2(X, adj))\n",
    "        x3 = F.sigmoid(self.out(x2.flatten()))\n",
    "        return x3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearson_coor(input, target):\n",
    "    vx = input - torch.mean(input, dim=(1, 2))[:, None, None]\n",
    "    vy = target - torch.mean(target, dim=(1, 2))[:, None, None]\n",
    "    cost = torch.sum(vx * vy) / (torch.sqrt(torch.sum(vx ** 2)) * torch.sqrt(torch.sum(vy ** 2)))\n",
    "    return cost\n",
    "\n",
    "def GT_loss(target, predicted):\n",
    "\n",
    "    # l1_loss\n",
    "    l1_loss = torch.nn.L1Loss()\n",
    "    loss_pix2pix = l1_loss(target, predicted)\n",
    "\n",
    "    # topological_loss\n",
    "    target_n = target.detach().cpu().clone().numpy()\n",
    "    predicted_n = predicted.detach().cpu().clone().numpy()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    topo_loss = []\n",
    "    \n",
    "\n",
    "    for i in range(len(target_n)):\n",
    "\n",
    "        cur_target = target_n[i]\n",
    "        cur_predicted = predicted_n[i]\n",
    "\n",
    "        target_t = eigen_centrality(cur_target)\n",
    "        real_topology = torch.tensor(target_t)\n",
    "        predicted_t = eigen_centrality(cur_predicted)\n",
    "        fake_topology = torch.tensor(predicted_t)\n",
    "        topo_loss.append(l1_loss(real_topology, fake_topology))\n",
    "\n",
    "    topo_loss = torch.sum(torch.stack(topo_loss))\n",
    "\n",
    "    pc_loss = pearson_coor(target, predicted).to(DEVICE)\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    G_loss = loss_pix2pix + (1 - pc_loss) + topo_loss\n",
    "\n",
    "    return G_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "\n",
    "# put it back into a 2D symmetric array\n",
    "\n",
    "\n",
    "def topological_measures(data):\n",
    "    # ROI is the number of brain regions (i.e.,35 in our case)\n",
    "    ROI = 160\n",
    "\n",
    "    topology = []\n",
    "\n",
    "\n",
    "\n",
    "    # A = to_2d(data)\n",
    "    np.fill_diagonal(data, 0)\n",
    "\n",
    "    # create a graph from similarity matrix\n",
    "    G = nx.from_numpy_matrix(np.absolute(data))\n",
    "    U = G.to_undirected()\n",
    "\n",
    "    # Centrality #\n",
    "\n",
    "    # compute closeness centrality and transform the output to vector\n",
    "    cc = nx.closeness_centrality(U, distance=\"weight\")\n",
    "    closeness_centrality = np.array([cc[g] for g in U])\n",
    "    # compute betweeness centrality and transform the output to vector\n",
    "    # bc = nx.betweenness_centrality(U, weight='weight')\n",
    "    # bc = (nx.betweenness_centrality(U))\n",
    "    betweenness_centrality = np.array([cc[g] for g in U])\n",
    "    # # compute egeinvector centrality and transform the output to vector\n",
    "    ec = nx.eigenvector_centrality_numpy(U)\n",
    "    eigenvector_centrality = np.array([ec[g] for g in U])\n",
    "\n",
    "\n",
    "    topology.append(closeness_centrality)  # 0\n",
    "    topology.append(betweenness_centrality)  # 1\n",
    "    topology.append(eigenvector_centrality)  # 2\n",
    "\n",
    "    return topology\n",
    "# put it back into a 2D symmetric array\n",
    "\n",
    "def eigen_centrality(data):\n",
    "    # ROI is the number of brain regions (i.e.,35 in our case)\n",
    "    ROI = 160\n",
    "\n",
    "    topology_eigen = []\n",
    "\n",
    "\n",
    "\n",
    "    # A = to_2d(data)\n",
    "    np.fill_diagonal(data, 0)\n",
    "\n",
    "    # create a graph from similarity matrix\n",
    "    G = nx.from_numpy_array(np.absolute(data))\n",
    "    U = G.to_undirected()\n",
    "\n",
    "    # Centrality #\n",
    "\n",
    "\n",
    "    # # compute egeinvector centrality and transform the output to vector\n",
    "    ec = nx.eigenvector_centrality_numpy(U)\n",
    "    eigenvector_centrality = np.array([ec[g] for g in U])\n",
    "\n",
    "\n",
    "\n",
    "    topology_eigen.append(eigenvector_centrality)  # 2\n",
    "\n",
    "    return topology_eigen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_model(model):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "def unfreeze_model(model):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.randn((2*N_LR_NODES, 16))\n",
    "adj = lr_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "aligner = SheafAligner(2).to('cuda')\n",
    "aligned = aligner(X.to(DEVICE), adj.to(DEVICE)) # should return (n_lr * d) * f matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([320, 16])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aligned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = SheafGenerator(2).to('cuda')\n",
    "generated = generator(aligned, adj.to(DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([268, 268])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = torch.randn((N_HR_NODES*2, 16))\n",
    "discriminator = SheafDiscriminator(2).to('cuda')\n",
    "dis_decision = discriminator(Y.to(DEVICE), generated.to(DEVICE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_X_dim1 = torch.load('model_autoencoder/encode_lr_1.pt')\n",
    "lr_X_dim2 = torch.load('model_autoencoder/encode_lr_2.pt')\n",
    "hr_X_dim1 = torch.load('model_autoencoder/encode_hr_1.pt')\n",
    "hr_X_dim2 = torch.load('model_autoencoder/encode_hr_2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_X_dim1 = lr_X_dim1.detach()\n",
    "lr_X_dim2 = lr_X_dim2.detach()\n",
    "hr_X_dim1 = hr_X_dim1.detach()\n",
    "hr_X_dim2 = hr_X_dim2.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_X_all = torch.empty((167, 320, 32))\n",
    "for i in range(len(lr_X_dim1)):\n",
    "    a, b = lr_X_dim1[i], lr_X_dim2[i]\n",
    "    lr_X_all[i] = torch.cat([a, b], dim=-1).view(-1, a.shape[-1])\n",
    "\n",
    "hr_X_all = torch.empty((167, 536, 32))\n",
    "for i in range(len(hr_X_dim1)):\n",
    "    a, b = hr_X_dim1[i], hr_X_dim2[i]\n",
    "    hr_X_all[i] = torch.cat([a, b], dim=-1).view(-1, a.shape[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begin Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 2 # number of dimensions in each node\n",
    "f = 32 # length of node encoding\n",
    "aligner = SheafAligner(d, f).to(DEVICE)\n",
    "generator = SheafGenerator(d, f).to(DEVICE)\n",
    "discriminator = SheafDiscriminator(d, f).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "aligner_optimizer = torch.optim.AdamW(aligner.parameters(), lr=0.025, betas=(0.5, 0.999))\n",
    "generator_optimizer = torch.optim.AdamW(generator.parameters(), lr=0.025, betas=(0.5, 0.999))\n",
    "discriminator_optimizer = torch.optim.AdamW(discriminator.parameters(), lr=0.025, betas=(0.5, 0.999))\n",
    "\n",
    "adversarial_loss = torch.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1232893/574460122.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  alignment_loss = torch.abs(F.kl_div(F.softmax(hr_X_sampled), F.softmax(X_lr), None, None, 'sum'))\n",
      "../aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [0,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[91], line 56\u001b[0m\n\u001b[1;32m     51\u001b[0m d_loss \u001b[38;5;241m=\u001b[39m (d_real_loss \u001b[38;5;241m+\u001b[39m d_fake_loss) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m     52\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[0;32m---> 56\u001b[0m \u001b[43mg_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m generator_optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     59\u001b[0m alignment_loss\u001b[38;5;241m.\u001b[39mbackward(retain_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/vol/bitbucket/tcwong/deep_graph_learning/DGL24-Group-Project/venv/lib/python3.10/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/vol/bitbucket/tcwong/deep_graph_learning/DGL24-Group-Project/venv/lib/python3.10/site-packages/torch/autograd/__init__.py:259\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    250\u001b[0m inputs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    251\u001b[0m     (inputs,)\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inputs, (torch\u001b[38;5;241m.\u001b[39mTensor, graph\u001b[38;5;241m.\u001b[39mGradientEdge))\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m()\n\u001b[1;32m    256\u001b[0m )\n\u001b[1;32m    258\u001b[0m grad_tensors_ \u001b[38;5;241m=\u001b[39m _tensor_or_tensors_to_tuple(grad_tensors, \u001b[38;5;28mlen\u001b[39m(tensors))\n\u001b[0;32m--> 259\u001b[0m grad_tensors_ \u001b[38;5;241m=\u001b[39m \u001b[43m_make_grads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_grads_batched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retain_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n",
      "File \u001b[0;32m/vol/bitbucket/tcwong/deep_graph_learning/DGL24-Group-Project/venv/lib/python3.10/site-packages/torch/autograd/__init__.py:142\u001b[0m, in \u001b[0;36m_make_grads\u001b[0;34m(outputs, grads, is_grads_batched)\u001b[0m\n\u001b[1;32m    136\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    137\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrad can be implicitly created only for real scalar outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    138\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mout\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    139\u001b[0m         )\n\u001b[1;32m    140\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg)\n\u001b[1;32m    141\u001b[0m     new_grads\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 142\u001b[0m         \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreserve_format\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m     )\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    145\u001b[0m     new_grads\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "for i, sample in enumerate(zip(lr_X_all, lr_train, hr_X_all, hr_train)):\n",
    "    X_lr, adj_lr, X_hr, adj_hr = sample\n",
    "    aligner_optimizer.zero_grad()\n",
    "    generator_optimizer.zero_grad()\n",
    "    discriminator_optimizer.zero_grad()\n",
    "\n",
    "\n",
    "    aligned_X_lr = aligner(X_lr.to(DEVICE), adj_lr.to(DEVICE))\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    hr_mean = torch.mean(X_hr)\n",
    "    hr_std = torch.std(X_hr)\n",
    "\n",
    "    hr_X_sampled = torch.normal(hr_mean, hr_std, size=(N_LR_NODES*d, f))\n",
    "    # hr_X_sampled = torch.Tensor(MatrixVectorizer().anti_vectorize(hr_X_sampled, N_HR_NODES))\n",
    "\n",
    "\n",
    "    alignment_loss = torch.abs(F.kl_div(F.softmax(hr_X_sampled), F.softmax(X_lr), None, None, 'sum'))\n",
    "\n",
    "\n",
    "\n",
    "    # generate hr adjacency\n",
    "    generated_adj_hr = generator(aligned_X_lr.to(DEVICE), adj_lr.to(DEVICE))\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "    # calculate losses for generator\n",
    "\n",
    "    #### NOTE TEMPORARY MEASURE BECAUSE THEY TAKE IN (BATCHSIZE, xx, xx) shape ####\n",
    "    temp_adj_hr = adj_hr.reshape(1, *adj_hr.shape)\n",
    "    temp_generated_adj_hr = generated_adj_hr.reshape(1, *generated_adj_hr.shape)\n",
    "    ##########################################################\n",
    "\n",
    "    g_topology_loss = GT_loss(temp_adj_hr.to(DEVICE), temp_generated_adj_hr.to(DEVICE))\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    d_real = discriminator(X_hr.to(DEVICE), adj_hr.to(DEVICE))\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    d_fake = discriminator(X_hr.to(DEVICE), generated_adj_hr.to(DEVICE))\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    g_adversarial_loss = adversarial_loss(d_fake, (torch.ones_like(d_fake, requires_grad=False)))\n",
    "    g_loss = g_adversarial_loss + g_topology_loss\n",
    "\n",
    "\n",
    "\n",
    "    d_real_loss = adversarial_loss(d_real, (torch.ones_like(d_real, requires_grad=False)))\n",
    "    torch.cuda.empty_cache()\n",
    "    d_fake_loss = adversarial_loss(d_fake.detach(), torch.zeros_like(d_fake))\n",
    "    d_loss = (d_real_loss + d_fake_loss) / 2\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "\n",
    "    g_loss.backward(retain_graph=True)\n",
    "    generator_optimizer.step()\n",
    "\n",
    "    alignment_loss.backward(retain_graph=True)\n",
    "    aligner_optimizer.step()\n",
    "\n",
    "    d_loss.backward(retain_graph=True)\n",
    "    discriminator_optimizer.step()\n",
    "\n",
    "    print(f'sample {i}: align_loss = {alignment_loss}, generator_loss = {g_loss}, discriminator = {d_loss}')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
