{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Sequential, Linear, ReLU, Sigmoid, Tanh, Dropout, Upsample\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GENConv, GATv2Conv\n",
    "import numpy as np\n",
    "from torch_geometric.data import Data\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torch_geometric.utils import dense_to_sparse\n",
    "import torch_geometric.utils\n",
    "\n",
    "from torch.distributions import normal, kl\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd\n",
    "from MatrixVectorizer import MatrixVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set global variables\n",
    "N_SUBJECTS = 167\n",
    "\n",
    "N_LR_NODES = 160\n",
    "\n",
    "N_HR_NODES = 268\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "N_LR_NODES_F = int(N_LR_NODES * (N_LR_NODES-1) / 2)\n",
    "N_HR_NODES_F = int(N_HR_NODES * (N_HR_NODES-1) / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_preparation import load_data_tensor\n",
    "\n",
    "lr_train, lr_test, hr_train = load_data_tensor(\"dgl-icl\")\n",
    "\n",
    "lr_X_dim1 = torch.load('model_autoencoder/final_embeddings/encode_lr.pt')\n",
    "lr_X_dim3 = torch.load('model_autoencoder/final_embeddings/encode_lr_3.pt')\n",
    "hr_X_dim1 = torch.load('model_autoencoder/final_embeddings/encode_hr.pt')\n",
    "hr_X_dim3 = torch.load('model_autoencoder/final_embeddings/encode_hr_3.pt')\n",
    "lr_X_dim1_test = torch.load('model_autoencoder/final_embeddings/encode_lr_test.pt')\n",
    "hr_X_dim3_test = torch.load('model_autoencoder/final_embeddings/encode_lr_test_3.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_steps(num_steps, low=N_LR_NODES, high=N_HR_NODES):\n",
    "    step_size = (high - low) / (num_steps - 1)\n",
    "    steps_list = [round(low + step_size * i) for i in range(num_steps)]\n",
    "    return steps_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class AdjacencyStep(nn.Module):\n",
    "    def __init__(self, old_dim, new_dim, channels, dt=1., alpha=0.3, gamma=0.3, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.dt = dt\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        # self.gnn = GENConv(channels, channels, aggr='powermean', learn_p=True)\n",
    "        self.gnn = GATv2Conv(channels, channels, edge_dim=1).to(DEVICE)\n",
    "        self.dropout = dropout\n",
    "        # self.dim_changer1 = nn.Parameter(torch.randn((new_dim, 1), device=DEVICE))\n",
    "        # self.dim_changer2 = nn.Parameter(torch.randn((1, old_dim), device=DEVICE))\n",
    "        self.dim_changer = nn.Parameter(torch.randn((new_dim, old_dim), device=DEVICE))\n",
    "        self.A_dim_changer = nn.Parameter(torch.randn((new_dim, old_dim), device=DEVICE))\n",
    "        # self.A_dim_changer1 = nn.Parameter(torch.randn((new_dim, 1), device=DEVICE))   \n",
    "        # self.A_dim_changer2 = nn.Parameter(torch.randn((1, old_dim), device=DEVICE))\n",
    "        self.Z_dim_changer = nn.Parameter(torch.randn((channels, new_dim), device=DEVICE))\n",
    "\n",
    "        # self.Z_dim_changer1 = nn.Parameter(torch.randn((channels, 1), device=DEVICE))   \n",
    "        # self.Z_dim_changer2 = nn.Parameter(torch.randn((1, new_dim), device=DEVICE))\n",
    "\n",
    "        self.forget_gate = nn.Parameter(torch.randn(new_dim, device=DEVICE))\n",
    "        self.input_gate = nn.Parameter(torch.randn(new_dim, device=DEVICE))\n",
    "\n",
    "        self.batchnorm_A = torch_geometric.nn.norm.BatchNorm(new_dim)\n",
    "        self.layernorm_forget_A = torch_geometric.nn.norm.LayerNorm((new_dim, new_dim))\n",
    "        self.layernorm_input_Z = torch_geometric.nn.norm.LayerNorm((new_dim, new_dim))\n",
    "        self.batchnorm_X = torch_geometric.nn.norm.BatchNorm(new_dim)\n",
    "        self.batchnorm_Y = torch_geometric.nn.norm.BatchNorm(new_dim)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, X, Y, A):\n",
    "        # solve ODEs using simple IMEX scheme\n",
    "        # dim_changer = self.dim_changer1 @ self.dim_changer2 \n",
    "        # A_dim_changer = self.A_dim_changer1 @ self.A_dim_changer2\n",
    "        # Z_dim_changer = self.Z_dim_changer1 @ self.Z_dim_changer2\n",
    "        dim_changer = self.dim_changer\n",
    "        A_dim_changer = self.A_dim_changer\n",
    "        Z_dim_changer = self.Z_dim_changer\n",
    "\n",
    "        # forget gate from previous adjacency\n",
    "        f = F.sigmoid(self.forget_gate)\n",
    "        i = F.sigmoid(self.input_gate)\n",
    "        forget_A = F.elu(A_dim_changer @ A @ A_dim_changer.T)\n",
    "        forget_A = f[:, None] * self.layernorm_forget_A(forget_A)\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    \n",
    "        # update node features with gcn\n",
    "        # edge_index, edge_weights = dense_to_sparse(A)\n",
    "        data_list = []\n",
    "        for x, adj in zip(X, A):\n",
    "            edge_index = adj.nonzero().t()\n",
    "            edge_weights = adj[edge_index[0], edge_index[1]]\n",
    "            data = Data(x=x, edge_index=edge_index, edge_attr=edge_weights.view(-1, 1))\n",
    "            data_list.append(data)\n",
    "        graph_batch = torch_geometric.data.Batch().from_data_list(data_list)\n",
    "        Z = self.gnn(graph_batch.x, graph_batch.edge_index, graph_batch.edge_attr).reshape(X.shape)\n",
    "        torch.cuda.empty_cache()\n",
    "        input_Z = F.elu(dim_changer @ Z @ Z_dim_changer)\n",
    "        input_Z = i[:, None] * self.layernorm_input_Z(input_Z)\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "\n",
    "        # get new adjacency matrix\n",
    "        new_A = forget_A + input_Z\n",
    "        new_A = self.batchnorm_A(new_A)\n",
    "        new_A = (new_A + torch.transpose(new_A, -1, -2)) / 2\n",
    "        new_A = F.tanh(F.relu(new_A))\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "        # new_A = new_A + torch.diag_embed(torch.diagonal(new_A, 0)).to(DEVICE) - torch.eye(new_A.shape[0]).to(DEVICE)  # remove self connections\n",
    "\n",
    "\n",
    "        # update feature embeiddings\n",
    "        Y_temp = Y\n",
    "        Y = dim_changer @ (Y + self.dt * (Z - self.alpha * Y - self.gamma * X))\n",
    "        X = dim_changer @ (X + self.dt * Y_temp) \n",
    "\n",
    "        X = self.batchnorm_X(X)\n",
    "        Y = self.batchnorm_Y(Y)   \n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "        if (self.dropout is not None):\n",
    "            Y = F.dropout(Y, self.dropout, training=self.training)\n",
    "            X = F.dropout(X, self.dropout, training=self.training)\n",
    "\n",
    "        return X, Y, new_A\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdjacencyDimChanger(nn.Module):\n",
    "\n",
    "    def __init__(self, dim_steps, f):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.layers = nn.ModuleList([AdjacencyStep(dim_steps[i], dim_steps[i+1], f) for i in range(len(dim_steps)-1)])\n",
    "        # self.batchnorms = nn.ModuleList([nn.BatchNorm1d(dim_steps[i+1]) for i in range(len(dim_steps)-1)])\n",
    "        \n",
    "    def forward(self, X, Y, A):\n",
    "        adj_ls = [A]\n",
    "        x, y, adj = X, Y, A\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            x, y, adj = layer(x, y, adj)\n",
    "            adj_ls.append(adj)\n",
    "            \n",
    "\n",
    "\n",
    "        return adj_ls\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_model(model):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "def unfreeze_model(model):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "def eigen_centrality(data):\n",
    "    # ROI is the number of brain regions (i.e.,35 in our case)\n",
    "    ROI = 160\n",
    "\n",
    "    topology_eigen = []\n",
    "\n",
    "    G = nx.from_numpy_array(np.absolute(data))\n",
    "    U = G.to_undirected()\n",
    "\n",
    "    # A = to_2d(data)\n",
    "    np.fill_diagonal(data, 0)\n",
    "\n",
    "    # create a graph frL2\n",
    "    # # compute egeinvector centrality and transform the output to vector\n",
    "    ec = nx.eigenvector_centrality_numpy(U)\n",
    "    \n",
    "    eigenvector_centrality = np.array([ec[g] for g in U])\n",
    "\n",
    "\n",
    "\n",
    "    topology_eigen.append(eigenvector_centrality)  # 2\n",
    "\n",
    "    return topology_eigen\n",
    "\n",
    "def pearson_coor(input, target, epsilon=1e-7):\n",
    "    vx = input - torch.mean(input, dim=(1, 2))[:, None, None]\n",
    "    vy = target - torch.mean(target, dim=(1, 2))[:, None, None]\n",
    "    cost = torch.sum(vx * vy) / (torch.sqrt(torch.sum(vx ** 2)+epsilon) * torch.sqrt(torch.sum(vy ** 2)+epsilon)+epsilon)\n",
    "    return cost\n",
    "\n",
    "def GT_loss(target, predicted):\n",
    "\n",
    "    # l1_loss\n",
    "    l1_loss = torch.nn.L1Loss()\n",
    "    # loss_pix2pix = l1_loss(target, predicted)\n",
    "\n",
    "    # topological_loss\n",
    "    target_n = target.detach().cpu().clone().numpy()\n",
    "    predicted_n = predicted.detach().cpu().clone().numpy()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    topo_loss = []\n",
    "    \n",
    "\n",
    "    for i in range(len(target_n)):\n",
    "\n",
    "        cur_target = target_n[i]\n",
    "        cur_predicted = predicted_n[i]\n",
    "\n",
    "        target_t = eigen_centrality(cur_target)\n",
    "        real_topology = torch.tensor(target_t[0])\n",
    "        predicted_t = eigen_centrality(cur_predicted)\n",
    "        fake_topology = torch.tensor(predicted_t[0])\n",
    "        topo_loss.append(l1_loss(real_topology, fake_topology))\n",
    "\n",
    "    topo_loss = torch.sum(torch.stack(topo_loss))\n",
    "\n",
    "    pc_loss = pearson_coor(target, predicted).to(DEVICE)\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # G_loss = loss_pix2pix + (1 - pc_loss) + topo_loss\n",
    "    G_loss = (1 - pc_loss) + topo_loss\n",
    "\n",
    "\n",
    "    return G_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_calc(adj_ls, opp_adj_ls, alpha=0.6, weights=None):\n",
    "    total_loss = torch.Tensor([0]).to(DEVICE)\n",
    "    mse_loss_fn = nn.MSELoss()\n",
    "\n",
    "    # calculate the loss for the upper traingle of the matrix because thats what we care about\n",
    "    final_dim = adj_ls[-1].shape[-1]\n",
    "    upper_tri_idx = torch.triu_indices(final_dim, final_dim, offset=1)\n",
    "    final_upper_tri_adj = adj_ls[-1][:,upper_tri_idx.unbind()[0], upper_tri_idx.unbind()[1]]\n",
    "    final_upper_tri_other_adj = opp_adj_ls[0][:,upper_tri_idx.unbind()[0], upper_tri_idx.unbind()[1]]\n",
    "    \n",
    "    total_loss = total_loss + alpha*mse_loss_fn(final_upper_tri_adj, final_upper_tri_other_adj)\n",
    "\n",
    "    if weights is None:\n",
    "        n = len(opp_adj_ls[1:])\n",
    "        weights = torch.Tensor([1/n for _ in range(n)])\n",
    "    \n",
    "    # calculate the loss for the remaining intermediate adjacent matrices\n",
    "    intermediate_mse_loss = torch.Tensor([0]).to(DEVICE)\n",
    "    for i, (adj, opp_adj) in enumerate(zip(adj_ls[1:-1][::-1], opp_adj_ls[1:])):\n",
    "        intermediate_mse_loss = intermediate_mse_loss + weights[i] * mse_loss_fn(adj, opp_adj)\n",
    "            \n",
    "    total_loss = total_loss + (1 - alpha) * intermediate_mse_loss\n",
    "        \n",
    "\n",
    "    # gt_loss = torch.Tensor([0]).to(DEVICE)\n",
    "    # for i, (adj, opp_adj) in enumerate(zip(adj_ls, opp_adj_ls[::-1])):\n",
    "\n",
    "    #     ### NOTE TEMPORARY MEASURE BECAUSE THEY TAKE IN (BATCHSIZE, xx, xx) shape ####\n",
    "    #     temp_adj = adj.reshape(1, *adj.shape)\n",
    "    #     temp_opp_adj = opp_adj.reshape(1, *opp_adj.shape)\n",
    "    #     ##########################################################\n",
    "    #     gt_loss = gt_loss + GT_loss(temp_adj, temp_opp_adj)\n",
    "\n",
    "    # gt_loss = gt_loss / n\n",
    "        \n",
    "    return total_loss\n",
    "\n",
    "\n",
    "def end_adj_loss_calc(adj, opp_adj):\n",
    "    mae_loss_fn = torch.nn.L1Loss()\n",
    "    n = len(adj)\n",
    "    upper_tri_idx = torch.triu_indices(n, n, offset=1)\n",
    "    upper_tri_adj = adj.detach()[upper_tri_idx.unbind()]\n",
    "    upper_tri_opp_adj = opp_adj.detach()[upper_tri_idx.unbind()]\n",
    "    mae_loss = mae_loss_fn(upper_tri_adj, upper_tri_opp_adj)\n",
    "    # temp_adj = adj.reshape(1, *adj.shape)\n",
    "    # temp_opp_adj = opp_adj.reshape(1, *opp_adj.shape)\n",
    "    # gt_loss = GT_loss(temp_adj, temp_opp_adj)\n",
    "    return mae_loss.detach().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2331008"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainloader = DataLoader(list(zip(lr_X_dim1, lr_X_dim3, lr_train, hr_X_dim1, hr_X_dim3, hr_train)), shuffle=True, batch_size=32)\n",
    "# testloader = DataLoader(list(zip(lr_X_dim1_test, lr_X_dim3, lr_test)), shuffle=True, batch_size=32)\n",
    "\n",
    "dim_steps = generate_steps(num_steps=5)\n",
    "\n",
    "up_changer = AdjacencyDimChanger(dim_steps, f=32).to(DEVICE)\n",
    "down_changer = AdjacencyDimChanger(dim_steps[::-1],f=32).to(DEVICE)\n",
    "\n",
    "up_optimizer = torch.optim.AdamW(up_changer.parameters(), lr=0.001, betas=(0.5, 0.999))\n",
    "down_optimizer = torch.optim.AdamW(down_changer.parameters(), lr=0.001, betas=(0.5, 0.999))\n",
    "\n",
    "sum(p.numel() for model in [up_changer, down_changer] for p in model.parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs, up_changer, down_changer, trainloader, up_optimizer, down_optimizer):\n",
    "\n",
    "    loss_log = {'up': [], 'down': [], 'up_end_mae':[], 'down_end_mae':[]}\n",
    "    up_changer.train()\n",
    "    down_changer.train()    \n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        up_losses = []\n",
    "        up_final_mae_ls = []\n",
    "        down_final_mae_ls = []\n",
    "        down_losses = []\n",
    "\n",
    "        for X_lr, Y_lr, adj_lr, X_hr, Y_hr, adj_hr in tqdm(trainloader):\n",
    "\n",
    "            freeze_model(up_changer)\n",
    "            unfreeze_model(down_changer)\n",
    "        \n",
    "            down_optimizer.zero_grad()\n",
    "            up_optimizer.zero_grad()\n",
    "\n",
    "            down_batch_loss = []\n",
    "            \n",
    "            up_adj_ls = up_changer(X_lr.to(DEVICE), Y_lr.to(DEVICE), adj_lr.to(DEVICE))\n",
    "            torch.cuda.empty_cache()\n",
    "            down_adj_ls = down_changer(X_hr.to(DEVICE), Y_hr.to(DEVICE), adj_hr.to(DEVICE))\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            down_batch_loss.append(loss_calc(down_adj_ls[1:], up_adj_ls[:-1]))\n",
    "        \n",
    "            # for printing loss only\n",
    "            down_final_mae_ls.append(end_adj_loss_calc(down_adj_ls[-1].detach(), up_adj_ls[0].detach()))\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "            # del down_end_adj_gt_loss\n",
    "            down_loss = torch.mean(torch.stack(down_batch_loss))\n",
    "            down_loss.backward()\n",
    "            down_optimizer.step()\n",
    "\n",
    "            down_losses.append(down_loss.detach().item())\n",
    "            del down_loss\n",
    "            del down_batch_loss\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            unfreeze_model(up_changer)\n",
    "            freeze_model(down_changer)\n",
    "        \n",
    "            down_optimizer.zero_grad()\n",
    "            up_optimizer.zero_grad()\n",
    "\n",
    "            up_batch_loss = []\n",
    "                \n",
    "            up_end_adj_mse_loss = []\n",
    "            # up_end_adj_gt_loss = []\n",
    "\n",
    "            up_adj_ls = up_changer(X_lr.to(DEVICE), Y_lr.to(DEVICE), adj_lr.to(DEVICE))\n",
    "            torch.cuda.empty_cache()\n",
    "            down_adj_ls = down_changer(X_hr.to(DEVICE), Y_hr.to(DEVICE), adj_hr.to(DEVICE))\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "            up_batch_loss.append(loss_calc(up_adj_ls[1:], down_adj_ls[:-1]))\n",
    "            \n",
    "            # for printing loss only\n",
    "            up_final_mae_ls.append(end_adj_loss_calc(up_adj_ls[-1].detach(), down_adj_ls[0].detach()))\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            \n",
    "            up_loss = torch.mean(torch.stack(up_batch_loss))\n",
    "            up_loss.backward()\n",
    "            up_optimizer.step()\n",
    "\n",
    "            up_losses.append(up_loss.detach().item())\n",
    "            del up_loss\n",
    "            del up_batch_loss\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "        \n",
    "        epoch_up_loss = np.mean(up_losses)\n",
    "        epoch_down_loss = np.mean(down_losses)\n",
    "        epoch_up_final_mae = np.mean(up_final_mae_ls)\n",
    "        epoch_down_final_mae = np.mean(down_final_mae_ls)\n",
    "        \n",
    "        loss_log['up'].append(epoch_up_loss)\n",
    "        loss_log['down'].append(epoch_down_loss)\n",
    "        loss_log['up_end_mae'].append(epoch_up_final_mae)\n",
    "        loss_log['down_end_mae'].append(epoch_down_final_mae)\n",
    "\n",
    "        print(f'epoch {epoch}: down loss = {epoch_down_loss}, up loss = {epoch_up_loss}')\n",
    "        print(f'Down end adj mae {epoch_down_final_mae}')\n",
    "        print(f'Up end adj mae {epoch_up_final_mae}')\n",
    "\n",
    "\n",
    "    return up_changer, down_changer, loss_log\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:02<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: down loss = 0.025778924425443012, up loss = 0.030583732140560944\n",
      "Down end adj mae 0.13701507449150085\n",
      "Up end adj mae 0.15456563979387283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:02<00:00,  2.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: down loss = 0.026600792072713375, up loss = 0.0315919720257322\n",
      "Down end adj mae 0.1395497793952624\n",
      "Up end adj mae 0.15647024909655252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:02<00:00,  2.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2: down loss = 0.02638251396516959, up loss = 0.030962116705874603\n",
      "Down end adj mae 0.13737196723620096\n",
      "Up end adj mae 0.1531627873579661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:02<00:00,  2.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3: down loss = 0.025918276359637577, up loss = 0.030985345443089802\n",
      "Down end adj mae 0.13376009712616602\n",
      "Up end adj mae 0.1526301105817159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:02<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4: down loss = 0.026555402825276058, up loss = 0.03130533856650194\n",
      "Down end adj mae 0.13861909011999765\n",
      "Up end adj mae 0.15595256040493646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:02<00:00,  2.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5: down loss = 0.0272050853818655, up loss = 0.030735858095188934\n",
      "Down end adj mae 0.13949456065893173\n",
      "Up end adj mae 0.1560887023806572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:02<00:00,  2.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6: down loss = 0.025987986475229263, up loss = 0.03058808638403813\n",
      "Down end adj mae 0.1363291914264361\n",
      "Up end adj mae 0.153910664220651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [00:01<00:01,  1.66it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m up_changer, down_changer, loss_log \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mup_changer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdown_changer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mup_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdown_optimizer\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[30], line 42\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(epochs, up_changer, down_changer, trainloader, up_optimizer, down_optimizer)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m down_loss\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m down_batch_loss\n\u001b[0;32m---> 42\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m unfreeze_model(up_changer)\n\u001b[1;32m     45\u001b[0m freeze_model(down_changer)\n",
      "File \u001b[0;32m/vol/bitbucket/tcwong/deep_graph_learning/DGL24-Group-Project/venv/lib/python3.10/site-packages/torch/cuda/memory.py:162\u001b[0m, in \u001b[0;36mempty_cache\u001b[0;34m()\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Release all unoccupied cached memory currently held by the caching\u001b[39;00m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;124;03mallocator so that those can be used in other GPU application and visible in\u001b[39;00m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;124;03m`nvidia-smi`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;124;03m    more details about GPU memory management.\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_initialized():\n\u001b[0;32m--> 162\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_emptyCache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "up_changer, down_changer, loss_log = train(100, up_changer, down_changer, trainloader, up_optimizer, down_optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(up_changer.state_dict(), 'tim_files/up_changer.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:01<00:00,  2.01it/s]\n"
     ]
    }
   ],
   "source": [
    "# to generate test predictions\n",
    "testloader = DataLoader(list(zip(lr_X_dim1_test, lr_X_dim3, lr_test)), shuffle=True, batch_size=32)\n",
    "\n",
    "up_changer.eval()\n",
    "test_predictions = []\n",
    "for X_lr, Y_lr, adj_lr in tqdm(testloader):\n",
    "    pred = up_changer(X_lr.to(DEVICE), Y_lr.to(DEVICE), adj_lr.to(DEVICE))[-1].detach()\n",
    "    test_predictions.append(pred)\n",
    "test_predictions = torch.cat(test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(test_predictions, 'submission_files/tim_deep1_pred.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from data_preparation import generate_histogram\n",
    "generate_histogram(test_predictions.cpu(), hr_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_preparation import generate_submission_file\n",
    "\n",
    "df = generate_submission_file(test_predictions.cpu(), 'submission_files/tim_deep1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation_fn import evaluate_predictions\n",
    "\n",
    "def validation(up_changer, testloader, val_adj_hr):\n",
    "    print('begin validation')\n",
    "    up_changer.eval()\n",
    "\n",
    "    val_predictions = []\n",
    "    for X_lr, Y_lr, adj_lr in tqdm(testloader):\n",
    "        pred = up_changer(X_lr.to(DEVICE), Y_lr.to(DEVICE), adj_lr.to(DEVICE))[-1].detach()\n",
    "        val_predictions.append(pred)\n",
    "        val_predictions = torch.cat(val_predictions)\n",
    "\n",
    "    return evaluate_predictions(val_predictions, val_adj_hr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(epochs, batch_size, n_fold, X_lr, Y_lr, adj_lr, X_hr, Y_hr, adj_hr, num_steps, f=32):\n",
    "    kf = KFold(n_fold, shuffle=True, random_state=99)\n",
    "    runs_results = []\n",
    "    for train_idx, val_idx in kf.split(X_lr):\n",
    "        train_X_lr, val_X_lr = X_lr[train_idx], X_lr[val_idx]\n",
    "        train_Y_lr, val_Y_lr = Y_lr[train_idx], Y_lr[val_idx]\n",
    "        train_adj_lr, val_adj_lr = adj_lr[train_idx], adj_lr[val_idx]\n",
    "        train_X_hr = X_hr[train_idx]\n",
    "        train_Y_hr = Y_hr[train_idx]\n",
    "        train_adj_hr, val_adj_hr = adj_hr[train_idx], adj_hr[val_idx]\n",
    "\n",
    "        trainloader = DataLoader(list(zip(train_X_lr, train_Y_lr, train_adj_lr, train_X_hr, train_Y_hr, train_adj_hr)), shuffle=True, batch_size=batch_size)\n",
    "\n",
    "        dim_steps = generate_steps(num_steps=10)\n",
    "\n",
    "        up_changer = AdjacencyDimChanger(dim_steps, f=f).to(DEVICE)\n",
    "        down_changer = AdjacencyDimChanger(dim_steps[::-1], f=f).to(DEVICE)\n",
    "\n",
    "        up_optimizer = torch.optim.AdamW(up_changer.parameters(), lr=0.001, betas=(0.5, 0.999))\n",
    "        down_optimizer = torch.optim.AdamW(down_changer.parameters(), lr=0.001, betas=(0.5, 0.999))    \n",
    "        \n",
    "        up_changer, down_changer, _ = train(epochs, up_changer, down_changer, trainloader, up_optimizer, down_optimizer)\n",
    "\n",
    "        testloader = DataLoader(list(zip(val_X_lr, val_Y_lr, val_adj_lr)), shuffle=True, batch_size=batch_size)\n",
    "        val_metrics = validation(up_changer, testloader, val_adj_hr)\n",
    "        runs_results.append(val_metrics)\n",
    "\n",
    "    return runs_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: down loss = 0.16657862812280655, up loss = 0.17240623757243156\n",
      "Down end adj mae 0.2933386266231537\n",
      "Up end adj mae 0.3219270035624504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: down loss = 0.1626523919403553, up loss = 0.16844239458441734\n",
      "Down end adj mae 0.2819127216935158\n",
      "Up end adj mae 0.3124385103583336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2: down loss = 0.15839369967579842, up loss = 0.16447226703166962\n",
      "Down end adj mae 0.27673444896936417\n",
      "Up end adj mae 0.30724405497312546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3: down loss = 0.15335677191615105, up loss = 0.16132723540067673\n",
      "Down end adj mae 0.2676369547843933\n",
      "Up end adj mae 0.2964955344796181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4: down loss = 0.14681177586317062, up loss = 0.15725039690732956\n",
      "Down end adj mae 0.2593224421143532\n",
      "Up end adj mae 0.2961497902870178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5: down loss = 0.14200948178768158, up loss = 0.15268298611044884\n",
      "Down end adj mae 0.24048680439591408\n",
      "Up end adj mae 0.27916480600833893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6: down loss = 0.1396225169301033, up loss = 0.14996973052620888\n",
      "Down end adj mae 0.24390818551182747\n",
      "Up end adj mae 0.27464043349027634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7: down loss = 0.13328664749860764, up loss = 0.1465534344315529\n",
      "Down end adj mae 0.2331133522093296\n",
      "Up end adj mae 0.2700587958097458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8: down loss = 0.12946145981550217, up loss = 0.14318590611219406\n",
      "Down end adj mae 0.22815408930182457\n",
      "Up end adj mae 0.2646156772971153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9: down loss = 0.12732424959540367, up loss = 0.14039869233965874\n",
      "Down end adj mae 0.22381966933608055\n",
      "Up end adj mae 0.260972585529089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_X_dim1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_X_dim3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhr_X_dim1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhr_X_dim3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhr_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[43], line 22\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(epochs, batch_size, n_fold, X_lr, Y_lr, adj_lr, X_hr, Y_hr, adj_hr, num_steps, f)\u001b[0m\n\u001b[1;32m     19\u001b[0m up_optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdamW(up_changer\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m, betas\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.999\u001b[39m))\n\u001b[1;32m     20\u001b[0m down_optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdamW(down_changer\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m, betas\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.999\u001b[39m))    \n\u001b[0;32m---> 22\u001b[0m up_changer, down_changer \u001b[38;5;241m=\u001b[39m train(epochs, up_changer, down_changer, trainloader, up_optimizer, down_optimizer)\n\u001b[1;32m     24\u001b[0m testloader \u001b[38;5;241m=\u001b[39m DataLoader(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(val_X_lr, val_Y_lr, val_adj_lr)), shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, batch_size\u001b[38;5;241m=\u001b[39mbatch_size)\n\u001b[1;32m     25\u001b[0m val_metrics \u001b[38;5;241m=\u001b[39m validation(up_changer, testloader, val_adj_hr)\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "cross_validate(10, 32, 3, lr_X_dim1, lr_X_dim3, lr_train, hr_X_dim1, hr_X_dim3, hr_train, num_steps=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
