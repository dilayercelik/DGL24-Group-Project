{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Sequential, Linear, ReLU, Sigmoid, Tanh, Dropout, Upsample\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GENConv, GATv2Conv\n",
    "import numpy as np\n",
    "from torch_geometric.data import Data\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torch_geometric.utils import dense_to_sparse\n",
    "\n",
    "from torch.distributions import normal, kl\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd\n",
    "from MatrixVectorizer import MatrixVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set global variables\n",
    "N_SUBJECTS = 167\n",
    "\n",
    "N_LR_NODES = 160\n",
    "\n",
    "N_HR_NODES = 268\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "N_LR_NODES_F = int(N_LR_NODES * (N_LR_NODES-1) / 2)\n",
    "N_HR_NODES_F = int(N_HR_NODES * (N_HR_NODES-1) / 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edge Index: tensor([[  0,   0,   0,  ..., 159, 159, 159],\n",
      "        [  1,   2,   3,  ..., 156, 157, 158]])\n",
      "Edge Weight: tensor([0.3388, 0.2025, 0.6895,  ..., 0.4202, 0.2553, 0.1834])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch_geometric\n",
    "from torch_geometric.utils import to_undirected\n",
    "\n",
    "# Example adjacency matrix tensor\n",
    "adjacency_matrix = lr_train[0]\n",
    "\n",
    "# Find non-zero indices (edges) and their corresponding weights\n",
    "edge_index = adjacency_matrix.nonzero(as_tuple=False).t()\n",
    "edge_weight = adjacency_matrix[edge_index[0], edge_index[1]]\n",
    "\n",
    "# Convert to undirected graph if needed\n",
    "edge_index = to_undirected(edge_index)\n",
    "\n",
    "print(\"Edge Index:\", edge_index)\n",
    "print(\"Edge Weight:\", edge_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ -55.6210,   17.0611,   31.0198,  ...,   41.2022,    1.5587,\n",
       "            36.1190],\n",
       "         [  38.4514,  -11.7945,  -21.4443,  ...,  -28.4836,   -1.0776,\n",
       "           -24.9695],\n",
       "         [ -19.8355,    6.0843,   11.0623,  ...,   14.6935,    0.5559,\n",
       "            12.8808],\n",
       "         ...,\n",
       "         [  38.1203,   -0.0000,  -21.2597,  ...,  -28.2383,   -1.0683,\n",
       "           -24.7544],\n",
       "         [-115.0808,   35.2997,    0.0000,  ...,   85.2483,    3.2250,\n",
       "            74.7309],\n",
       "         [ -10.7544,    3.2988,    5.9977,  ...,    7.9665,    0.3014,\n",
       "             6.9836]], grad_fn=<MulBackward0>),\n",
       " tensor([[ 22.0319,  -4.9978,  -0.0000,  ...,  -0.0000,  -8.8853,  -0.0000],\n",
       "         [ -0.0000,   3.4550,  13.7855,  ...,   0.0000,   6.1425,  10.1823],\n",
       "         [  0.0000,  -1.7823,  -7.1114,  ...,  -4.9164,  -3.1687,  -0.0000],\n",
       "         ...,\n",
       "         [ -0.0000,   0.0000,   0.0000,  ...,   9.4485,   6.0896,  10.0946],\n",
       "         [ 45.5844, -10.3406, -41.2586,  ..., -28.5239, -18.3839,  -0.0000],\n",
       "         [  4.2599,  -0.9663,  -3.8556,  ...,  -2.6656,  -1.7180,  -2.8479]],\n",
       "        grad_fn=<MulBackward0>),\n",
       " tensor([[0.0000, 0.3388, 0.2025,  ..., 0.6702, 0.3994, 0.1218],\n",
       "         [0.3388, 0.0000, 0.0398,  ..., 0.5899, 0.0000, 0.3450],\n",
       "         [0.2025, 0.0398, 0.0000,  ..., 0.3247, 0.1656, 0.0065],\n",
       "         ...,\n",
       "         [0.6702, 0.5899, 0.3247,  ..., 0.0000, 0.2633, 0.2553],\n",
       "         [0.3994, 0.0000, 0.1656,  ..., 0.2633, 0.0000, 0.1834],\n",
       "         [0.1218, 0.3450, 0.0065,  ..., 0.2553, 0.1834, 0.0000]]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = lr_X_dim1[0]\n",
    "a = lr_train[0]\n",
    "\n",
    "m = GraphCON(x.shape[0], 180, 32)\n",
    "m(x, x, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class GraphCON(nn.Module):\n",
    "    def __init__(self, old_dim, new_dim, channels, dt=1., alpha=1., gamma=1., dropout=0.2):\n",
    "        super(GraphCON, self).__init__()\n",
    "        self.dt = dt\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        # self.gnn = GENConv(channels, channels, aggr='powermean', learn_p=True)\n",
    "        self.gnn = GATv2Conv(channels, channels, edge_dim=1)\n",
    "        self.dropout = dropout\n",
    "        self.dim_changer1 = nn.Parameter(torch.randn((new_dim, 1), device=DEVICE))\n",
    "        self.dim_changer2 = nn.Parameter(torch.randn((1, old_dim), device=DEVICE))\n",
    "        self.A_dim_changer1 = nn.Parameter(torch.randn((new_dim, 1), device=DEVICE))   \n",
    "        self.A_dim_changer2 = nn.Parameter(torch.randn((1, old_dim), device=DEVICE))\n",
    "        self.Z_dim_changer1 = nn.Parameter(torch.randn((channels, 1), device=DEVICE))   \n",
    "        self.Z_dim_changer2 = nn.Parameter(torch.randn((1, new_dim), device=DEVICE))\n",
    "\n",
    "        self.forget_gate = nn.Parameter(torch.randn(new_dim, device=DEVICE))\n",
    "        self.input_gate = nn.Parameter(torch.randn(new_dim, device=DEVICE))\n",
    "\n",
    "\n",
    "    def forward(self, X, Y, A):\n",
    "        # solve ODEs using simple IMEX scheme\n",
    "        dim_changer = self.dim_changer1 @ self.dim_changer2 \n",
    "        A_dim_changer = self.A_dim_changer1 @ self.A_dim_changer2\n",
    "        Z_dim_changer = self.Z_dim_changer1 @ self.Z_dim_changer2\n",
    "\n",
    "        # forget gate from previous adjacency\n",
    "        f = F.sigmoid(self.forget_gate)\n",
    "        i = F.sigmoid(self.input_gate)\n",
    "        forget_A = f[:, None] * F.relu(A_dim_changer @ A @ A_dim_changer.T)\n",
    "    \n",
    "        # update node features with gcn\n",
    "        edge_index, edge_weights = dense_to_sparse(A)\n",
    "        Z = self.gnn(X, edge_index, edge_weights)\n",
    "        input_Z = i[:, None] * F.relu(dim_changer @ Z @ Z_dim_changer)\n",
    "\n",
    "        # get new adjacency matrix\n",
    "        new_A = forget_A + input_Z\n",
    "        new_A = (new_A + new_A.T) / 2\n",
    "        new_A = F.tanh(F.relu(new_A))\n",
    "        # new_A = new_A + torch.diag_embed(torch.diagonal(new_A, 0)).to(DEVICE) - torch.eye(new_A.shape[0]).to(DEVICE)  # remove self connections\n",
    "\n",
    "\n",
    "        # update feature vectorss\n",
    "        Y_temp = Y\n",
    "        Y = dim_changer @ (Y + self.dt * (Z - self.alpha * Y - self.gamma * X))\n",
    "        X = dim_changer @ (X + self.dt * Y_temp)        \n",
    "\n",
    "        if (self.dropout is not None):\n",
    "            Y = F.dropout(Y, self.dropout, training=self.training)\n",
    "            X = F.dropout(X, self.dropout, training=self.training)\n",
    "\n",
    "        return X, Y, A\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdjacencyDimChanger(nn.Module):\n",
    "    def __init__(self, new_n, old_n, old_f, d):\n",
    "        super().__init__()\n",
    "        self.new_n = new_n\n",
    "        self.old_n = old_n\n",
    "        self.d = d\n",
    "        self.sheafconv = SheafConvLayer(old_n, d, old_f, new_n)\n",
    "        self.layernorm = nn.LayerNorm([d, old_n]).to(DEVICE)\n",
    "\n",
    "    def forward(self, X, adj):\n",
    "\n",
    "        adj = adj - torch.diag_embed(torch.diagonal(adj, 0)).to(DEVICE) + torch.eye(adj.shape[0]).to(DEVICE)  # add self connections\n",
    "        x, L = self.sheafconv(X, adj)\n",
    "\n",
    "        x = x.reshape(self.old_n, self.d, self.new_n)\n",
    "        x = torch.transpose(x, 0, -1)\n",
    "        x = self.layernorm(x)\n",
    "        \n",
    "        x_mean = x.mean(dim=-1)\n",
    "\n",
    "        L_mean = L.reshape(self.old_n, self.old_n, self.d, self.d).max(dim=0)[0].mean(dim=0) # aggregate by eigenvalues of each n by n mat?\n",
    "        adj_new = torch.matmul(x_mean, L_mean)\n",
    "        adj_new = torch.matmul(adj_new, x_mean.T)\n",
    "        adj_new_T = torch.t(adj_new)\n",
    "        adj_new = F.tanh(F.relu(((adj_new + adj_new_T) / 2))) # becomes a new f by new f adj1\n",
    "\n",
    "        return x.reshape(self.new_n*self.d, -1), adj_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdjacencyChangerUp(nn.Module):\n",
    "\n",
    "    def __init__(self, d, f_in):\n",
    "        super().__init__()\n",
    "        self.d = d\n",
    "\n",
    "        self.adjdim_changer1 = AdjacencyDimChanger(200, N_LR_NODES, f_in, d)\n",
    "        self.adjdim_changer2 = AdjacencyDimChanger(220, 200, N_LR_NODES, d)\n",
    "        self.adjdim_changer3 = AdjacencyDimChanger(N_HR_NODES, 220, 200, d)\n",
    "\n",
    "        \n",
    "    def forward(self, X, adj):\n",
    "        x1, adj1 = self.adjdim_changer1(X, adj)\n",
    "        x2, adj2 = self.adjdim_changer2(x1, adj1)\n",
    "        x3, adj3 = self.adjdim_changer3(x2, adj2)\n",
    "        return [adj, adj1, adj2, adj3]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdjacencyChangerDown(nn.Module):\n",
    "\n",
    "    def __init__(self, d, f_in):\n",
    "        super().__init__()\n",
    "        self.d = d\n",
    "\n",
    "        self.adjdim_changer1 = AdjacencyDimChanger(220, N_HR_NODES, f_in, d).to(DEVICE)\n",
    "        self.adjdim_changer2  = AdjacencyDimChanger(200, 220, N_HR_NODES, d).to(DEVICE)\n",
    "        self.adjdim_changer3 = AdjacencyDimChanger(N_LR_NODES, 200, 220, d).to(DEVICE)\n",
    "\n",
    "        \n",
    "    def forward(self, X, adj):\n",
    "        x1, adj1 = self.adjdim_changer1(X, adj)\n",
    "        x2, adj2 = self.adjdim_changer2(x1, adj1)\n",
    "        x3, adj3 = self.adjdim_changer3(x2, adj2)\n",
    "        return [adj, adj1, adj2, adj3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_model(model):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "def unfreeze_model(model):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "def eigen_centrality(data):\n",
    "    # ROI is the number of brain regions (i.e.,35 in our case)\n",
    "    ROI = 160\n",
    "\n",
    "    topology_eigen = []\n",
    "\n",
    "    G = nx.from_numpy_array(np.absolute(data))\n",
    "    U = G.to_undirected()\n",
    "\n",
    "    # A = to_2d(data)\n",
    "    np.fill_diagonal(data, 0)\n",
    "\n",
    "    # create a graph frL2\n",
    "    # # compute egeinvector centrality and transform the output to vector\n",
    "    ec = nx.eigenvector_centrality_numpy(U)\n",
    "    \n",
    "    eigenvector_centrality = np.array([ec[g] for g in U])\n",
    "\n",
    "\n",
    "\n",
    "    topology_eigen.append(eigenvector_centrality)  # 2\n",
    "\n",
    "    return topology_eigen\n",
    "\n",
    "def pearson_coor(input, target, epsilon=1e-7):\n",
    "    vx = input - torch.mean(input, dim=(1, 2))[:, None, None]\n",
    "    vy = target - torch.mean(target, dim=(1, 2))[:, None, None]\n",
    "    cost = torch.sum(vx * vy) / (torch.sqrt(torch.sum(vx ** 2)+epsilon) * torch.sqrt(torch.sum(vy ** 2)+epsilon)+epsilon)\n",
    "    return cost\n",
    "\n",
    "def GT_loss(target, predicted):\n",
    "\n",
    "    # l1_loss\n",
    "    l1_loss = torch.nn.L1Loss()\n",
    "    # loss_pix2pix = l1_loss(target, predicted)\n",
    "\n",
    "    # topological_loss\n",
    "    target_n = target.detach().cpu().clone().numpy()\n",
    "    predicted_n = predicted.detach().cpu().clone().numpy()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    topo_loss = []\n",
    "    \n",
    "\n",
    "    for i in range(len(target_n)):\n",
    "\n",
    "        cur_target = target_n[i]\n",
    "        cur_predicted = predicted_n[i]\n",
    "\n",
    "        target_t = eigen_centrality(cur_target)\n",
    "        real_topology = torch.tensor(target_t[0])\n",
    "        predicted_t = eigen_centrality(cur_predicted)\n",
    "        fake_topology = torch.tensor(predicted_t[0])\n",
    "        topo_loss.append(l1_loss(real_topology, fake_topology))\n",
    "\n",
    "    topo_loss = torch.sum(torch.stack(topo_loss))\n",
    "\n",
    "    pc_loss = pearson_coor(target, predicted).to(DEVICE)\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # G_loss = loss_pix2pix + (1 - pc_loss) + topo_loss\n",
    "    G_loss = (1 - pc_loss) + topo_loss\n",
    "\n",
    "\n",
    "    return G_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_calc(adj_ls, opp_adj_ls):\n",
    "    total_loss = torch.Tensor([0]).to(DEVICE)\n",
    "    mse_loss_fn = torch.nn.MSELoss()\n",
    "    for i, (adj, opp_adj) in enumerate(zip(adj_ls[::-1], opp_adj_ls)):\n",
    "\n",
    "        ### NOTE TEMPORARY MEASURE BECAUSE THEY TAKE IN (BATCHSIZE, xx, xx) shape ####\n",
    "        temp_adj = adj.reshape(1, *adj.shape)\n",
    "        temp_opp_adj = opp_adj.reshape(1, *opp_adj.shape)\n",
    "        ##########################################################\n",
    "        gt_loss = GT_loss(temp_adj, temp_opp_adj) / len(adj_ls)\n",
    "        mse_loss = torch.pow(mse_loss_fn(adj, opp_adj), 1/(i+1)) \n",
    "        total_loss = total_loss + mse_loss + gt_loss.to(DEVICE)\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_preparation import load_data_tensor\n",
    "\n",
    "lr_train, lr_test, hr_train = load_data_tensor(\"dgl-icl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (320) must match the existing size (240) at non-singleton dimension 0.  Target sizes: [320, 32].  Tensor sizes: [240, 32]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(lr_X_dim1)):\n\u001b[1;32m      9\u001b[0m     a, b \u001b[38;5;241m=\u001b[39m lr_X_dim1[i], lr_X_dim2[i]\n\u001b[0;32m---> 10\u001b[0m     \u001b[43mlr_X_all\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([a, b], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, a\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     12\u001b[0m hr_X_all \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mempty((\u001b[38;5;241m167\u001b[39m, \u001b[38;5;241m536\u001b[39m, \u001b[38;5;241m32\u001b[39m))\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(hr_X_dim1)):\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (320) must match the existing size (240) at non-singleton dimension 0.  Target sizes: [320, 32].  Tensor sizes: [240, 32]"
     ]
    }
   ],
   "source": [
    "lr_X_dim1 = torch.load('model_autoencoder/encode_lr_1.pt')\n",
    "lr_X_dim2 = torch.load('model_autoencoder/encode_lr_2.pt')\n",
    "hr_X_dim1 = torch.load('model_autoencoder/encode_hr_1.pt')\n",
    "hr_X_dim2 = torch.load('model_autoencoder/encode_hr_2.pt')\n",
    "\n",
    "\n",
    "lr_X_all = torch.empty((167, 320, 32))\n",
    "for i in range(len(lr_X_dim1)):\n",
    "    a, b = lr_X_dim1[i], lr_X_dim2[i]\n",
    "    lr_X_all[i] = torch.cat([a, b], dim=-1).view(-1, a.shape[-1])\n",
    "\n",
    "hr_X_all = torch.empty((167, 536, 32))\n",
    "for i in range(len(hr_X_dim1)):\n",
    "    a, b = hr_X_dim1[i], hr_X_dim2[i]\n",
    "    hr_X_all[i] = torch.cat([a, b], dim=-1).view(-1, a.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2389928"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainloader = DataLoader(list(zip(lr_X_all, lr_train, hr_X_all, hr_train)), shuffle=True, batch_size=8)\n",
    "\n",
    "\n",
    "up_changer = AdjacencyChangerUp(d=2,f_in=32).to(DEVICE)\n",
    "down_changer = AdjacencyChangerDown(d=2,f_in=32).to(DEVICE)\n",
    "\n",
    "up_optimizer = torch.optim.AdamW(up_changer.parameters(), lr=0.001, betas=(0.5, 0.999))\n",
    "down_optimizer = torch.optim.AdamW(down_changer.parameters(), lr=0.001, betas=(0.5, 0.999))\n",
    "\n",
    "sum(p.numel() for model in [up_changer, down_changer] for p in model.parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs, up_changer, down_changer, trainloader, up_optimizer, down_optimizer):\n",
    "\n",
    "    up_changer.train()\n",
    "    down_changer.train()\n",
    "    with torch.autograd.set_detect_anomaly(True):\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            up_losses = []\n",
    "            down_losses = []\n",
    "\n",
    "            for X_lr, adj_lr, X_hr, adj_hr in tqdm(trainloader):\n",
    "\n",
    "                freeze_model(up_changer)\n",
    "                unfreeze_model(down_changer)\n",
    "            \n",
    "                down_optimizer.zero_grad()\n",
    "                up_optimizer.zero_grad()\n",
    "\n",
    "                down_batch_loss = []\n",
    "\n",
    "                for i in range(len(X_lr)):\n",
    "\n",
    "                    up_adj_ls = up_changer(X_lr[i].to(DEVICE), adj_lr[i].to(DEVICE))\n",
    "                    torch.cuda.empty_cache()\n",
    "                    down_adj_ls = down_changer(X_hr[i].to(DEVICE), adj_hr[i].to(DEVICE))\n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "                    down_batch_loss.append(loss_calc(down_adj_ls, up_adj_ls))\n",
    "\n",
    "                down_loss = torch.mean(torch.stack(down_batch_loss))\n",
    "                down_loss.backward()\n",
    "                down_optimizer.step()\n",
    "\n",
    "                down_losses.append(down_loss.detach().item())\n",
    "                del down_loss\n",
    "                del down_batch_loss\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "                unfreeze_model(up_changer)\n",
    "                freeze_model(down_changer)\n",
    "            \n",
    "                down_optimizer.zero_grad()\n",
    "                up_optimizer.zero_grad()\n",
    "\n",
    "                up_batch_loss = []\n",
    "\n",
    "\n",
    "                for i in range(len(X_lr)):\n",
    "\n",
    "                    up_adj_ls = up_changer(X_lr[i].to(DEVICE), adj_lr[i].to(DEVICE))\n",
    "                    torch.cuda.empty_cache()\n",
    "                    down_adj_ls = down_changer(X_hr[i].to(DEVICE), adj_hr[i].to(DEVICE))\n",
    "                    torch.cuda.empty_cache()\n",
    "                \n",
    "                    up_batch_loss.append(loss_calc(up_adj_ls, down_adj_ls))\n",
    "\n",
    "                up_loss = torch.mean(torch.stack(up_batch_loss))\n",
    "                up_loss.backward()\n",
    "                up_optimizer.step()\n",
    "\n",
    "                up_losses.append(up_loss.detach().item())\n",
    "                del up_loss\n",
    "                del up_batch_loss\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "\n",
    "            epoch_up_loss = np.mean(up_losses)\n",
    "            epoch_down_loss = np.mean(down_losses)\n",
    "\n",
    "            print(f'epoch {epoch}: down loss = {epoch_down_loss}, up loss = {epoch_up_loss}')\n",
    "\n",
    "        return up_changer, down_changer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 7/21 [05:51<11:35, 49.71s/it]"
     ]
    }
   ],
   "source": [
    "up_changer, down_changer = train(20, up_changer, down_changer, trainloader, up_optimizer, down_optimizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
