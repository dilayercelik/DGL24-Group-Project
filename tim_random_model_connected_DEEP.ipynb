{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Sequential, Linear, ReLU, Sigmoid, Tanh, Dropout, Upsample\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GENConv, GATv2Conv\n",
    "import numpy as np\n",
    "from torch_geometric.data import Data\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torch_geometric.utils import dense_to_sparse\n",
    "import torch_geometric.utils\n",
    "\n",
    "from torch.distributions import normal, kl\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd\n",
    "from MatrixVectorizer import MatrixVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set global variables\n",
    "N_SUBJECTS = 167\n",
    "\n",
    "N_LR_NODES = 160\n",
    "\n",
    "N_HR_NODES = 268\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "N_LR_NODES_F = int(N_LR_NODES * (N_LR_NODES-1) / 2)\n",
    "N_HR_NODES_F = int(N_HR_NODES * (N_HR_NODES-1) / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_preparation import load_data_tensor\n",
    "\n",
    "lr_train, lr_test, hr_train = load_data_tensor(\"dgl-icl\")\n",
    "\n",
    "lr_X_dim1 = torch.load('model_autoencoder/final_embeddings/encode_lr.pt')\n",
    "lr_X_dim3 = torch.load('model_autoencoder/final_embeddings/encode_lr_3.pt')\n",
    "hr_X_dim1 = torch.load('model_autoencoder/final_embeddings/encode_hr.pt')\n",
    "hr_X_dim3 = torch.load('model_autoencoder/final_embeddings/encode_hr_3.pt')\n",
    "lr_X_dim1_test = torch.load('model_autoencoder/final_embeddings/encode_lr_test.pt')\n",
    "hr_X_dim3_test = torch.load('model_autoencoder/final_embeddings/encode_lr_test_3.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_steps(num_steps, low=N_LR_NODES, high=N_HR_NODES):\n",
    "    step_size = (high - low) / (num_steps - 1)\n",
    "    steps_list = [round(low + step_size * i) for i in range(num_steps)]\n",
    "    return steps_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = lr_X_dim1[0].to(DEVICE)\n",
    "a = lr_train[0].to(DEVICE)\n",
    "num_steps = 10\n",
    "\n",
    "\n",
    "dim_steps= generate_steps(num_steps)\n",
    "up_sampler = AdjacencyDimChanger(dim_steps=dim_steps, f=32).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.7406e-01, -3.2386e-01],\n",
       "         [ 5.6132e-02, -3.5660e-02]],\n",
       "\n",
       "        [[-3.9412e-01,  3.2988e-01],\n",
       "         [ 8.4503e-04, -1.6906e-02]],\n",
       "\n",
       "        [[ 9.5981e-01, -3.3740e-01],\n",
       "         [ 3.7067e-03,  7.7308e-02]],\n",
       "\n",
       "        [[-1.7738e-01,  8.5273e-01],\n",
       "         [-6.2215e-02,  6.0100e-02]],\n",
       "\n",
       "        [[ 8.6247e-01,  6.7147e-01],\n",
       "         [ 9.8556e-03, -7.8895e-02]]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn((5, 2, 2))\n",
    "f = torch.randn(2)\n",
    "f[:, None] * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400128"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "up_sampler(x, x, a)\n",
    "sum(p.numel() for p in up_sampler.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class AdjacencyStep(nn.Module):\n",
    "    def __init__(self, old_dim, new_dim, channels, dt=1., alpha=1., gamma=1., dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.dt = dt\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        # self.gnn = GENConv(channels, channels, aggr='powermean', learn_p=True)\n",
    "        self.gnn = GATv2Conv(channels, channels, edge_dim=1).to(DEVICE)\n",
    "        self.dropout = dropout\n",
    "        self.dim_changer1 = nn.Parameter(torch.randn((new_dim, 1), device=DEVICE))\n",
    "        self.dim_changer2 = nn.Parameter(torch.randn((1, old_dim), device=DEVICE))\n",
    "        self.A_dim_changer1 = nn.Parameter(torch.randn((new_dim, 1), device=DEVICE))   \n",
    "        self.A_dim_changer2 = nn.Parameter(torch.randn((1, old_dim), device=DEVICE))\n",
    "        self.Z_dim_changer1 = nn.Parameter(torch.randn((channels, 1), device=DEVICE))   \n",
    "        self.Z_dim_changer2 = nn.Parameter(torch.randn((1, new_dim), device=DEVICE))\n",
    "\n",
    "        self.forget_gate = nn.Parameter(torch.randn(new_dim, device=DEVICE))\n",
    "        self.input_gate = nn.Parameter(torch.randn(new_dim, device=DEVICE))\n",
    "\n",
    "\n",
    "    def forward(self, X, Y, A):\n",
    "        # solve ODEs using simple IMEX scheme\n",
    "        dim_changer = self.dim_changer1 @ self.dim_changer2 \n",
    "        A_dim_changer = self.A_dim_changer1 @ self.A_dim_changer2\n",
    "        Z_dim_changer = self.Z_dim_changer1 @ self.Z_dim_changer2\n",
    "\n",
    "        # forget gate from previous adjacency\n",
    "        f = F.sigmoid(self.forget_gate)\n",
    "        i = F.sigmoid(self.input_gate)\n",
    "        forget_A = f[:, None] * F.relu(A_dim_changer @ A @ A_dim_changer.T)\n",
    "    \n",
    "        # update node features with gcn\n",
    "        # edge_index, edge_weights = dense_to_sparse(A)\n",
    "        data_list = []\n",
    "        for x, adj in zip(X, A):\n",
    "            edge_index = adj.nonzero().t()\n",
    "            edge_weights = adj[edge_index[0], edge_index[1]]\n",
    "            data = Data(x=x, edge_index=edge_index, edge_attr=edge_weights.view(-1, 1))\n",
    "            data_list.append(data)\n",
    "        graph_batch = torch_geometric.data.Batch().from_data_list(data_list)\n",
    "        Z = self.gnn(graph_batch.x, graph_batch.edge_index, graph_batch.edge_attr).reshape(X.shape)\n",
    "        input_Z = i[:, None] * F.relu(dim_changer @ Z @ Z_dim_changer)\n",
    "\n",
    "        # get new adjacency matrix\n",
    "        new_A = forget_A + input_Z\n",
    "        new_A = (new_A + torch.transpose(new_A, -1, -2)) / 2\n",
    "        new_A = F.tanh(F.relu(new_A))\n",
    "        # new_A = new_A + torch.diag_embed(torch.diagonal(new_A, 0)).to(DEVICE) - torch.eye(new_A.shape[0]).to(DEVICE)  # remove self connections\n",
    "\n",
    "\n",
    "        # update feature embeiddings\n",
    "        Y_temp = Y\n",
    "        Y = dim_changer @ (Y + self.dt * (Z - self.alpha * Y - self.gamma * X))\n",
    "        X = dim_changer @ (X + self.dt * Y_temp)        \n",
    "\n",
    "        if (self.dropout is not None):\n",
    "            Y = F.dropout(Y, self.dropout, training=self.training)\n",
    "            X = F.dropout(X, self.dropout, training=self.training)\n",
    "\n",
    "        return X, Y, new_A\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdjacencyDimChanger(nn.Module):\n",
    "\n",
    "    def __init__(self, dim_steps, f):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.layers = nn.ModuleList([AdjacencyStep(dim_steps[i], dim_steps[i+1], f) for i in range(len(dim_steps)-1)])\n",
    "        \n",
    "    def forward(self, X, Y, A):\n",
    "        adj_ls = [A]\n",
    "        x, y, adj = X, Y, A\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            x, y, adj = layer(x, y, adj)\n",
    "            adj_ls.append(adj)\n",
    "\n",
    "\n",
    "        return adj_ls\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_model(model):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "def unfreeze_model(model):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "def eigen_centrality(data):\n",
    "    # ROI is the number of brain regions (i.e.,35 in our case)\n",
    "    ROI = 160\n",
    "\n",
    "    topology_eigen = []\n",
    "\n",
    "    G = nx.from_numpy_array(np.absolute(data))\n",
    "    U = G.to_undirected()\n",
    "\n",
    "    # A = to_2d(data)\n",
    "    np.fill_diagonal(data, 0)\n",
    "\n",
    "    # create a graph frL2\n",
    "    # # compute egeinvector centrality and transform the output to vector\n",
    "    ec = nx.eigenvector_centrality_numpy(U)\n",
    "    \n",
    "    eigenvector_centrality = np.array([ec[g] for g in U])\n",
    "\n",
    "\n",
    "\n",
    "    topology_eigen.append(eigenvector_centrality)  # 2\n",
    "\n",
    "    return topology_eigen\n",
    "\n",
    "def pearson_coor(input, target, epsilon=1e-7):\n",
    "    vx = input - torch.mean(input, dim=(1, 2))[:, None, None]\n",
    "    vy = target - torch.mean(target, dim=(1, 2))[:, None, None]\n",
    "    cost = torch.sum(vx * vy) / (torch.sqrt(torch.sum(vx ** 2)+epsilon) * torch.sqrt(torch.sum(vy ** 2)+epsilon)+epsilon)\n",
    "    return cost\n",
    "\n",
    "def GT_loss(target, predicted):\n",
    "\n",
    "    # l1_loss\n",
    "    l1_loss = torch.nn.L1Loss()\n",
    "    # loss_pix2pix = l1_loss(target, predicted)\n",
    "\n",
    "    # topological_loss\n",
    "    target_n = target.detach().cpu().clone().numpy()\n",
    "    predicted_n = predicted.detach().cpu().clone().numpy()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    topo_loss = []\n",
    "    \n",
    "\n",
    "    for i in range(len(target_n)):\n",
    "\n",
    "        cur_target = target_n[i]\n",
    "        cur_predicted = predicted_n[i]\n",
    "\n",
    "        target_t = eigen_centrality(cur_target)\n",
    "        real_topology = torch.tensor(target_t[0])\n",
    "        predicted_t = eigen_centrality(cur_predicted)\n",
    "        fake_topology = torch.tensor(predicted_t[0])\n",
    "        topo_loss.append(l1_loss(real_topology, fake_topology))\n",
    "\n",
    "    topo_loss = torch.sum(torch.stack(topo_loss))\n",
    "\n",
    "    pc_loss = pearson_coor(target, predicted).to(DEVICE)\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # G_loss = loss_pix2pix + (1 - pc_loss) + topo_loss\n",
    "    G_loss = (1 - pc_loss) + topo_loss\n",
    "\n",
    "\n",
    "    return G_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_calc(adj_ls, opp_adj_ls):\n",
    "    total_loss = torch.Tensor([0]).to(DEVICE)\n",
    "    mse_loss_fn = torch.nn.MSELoss()\n",
    "    n = len(adj_ls)\n",
    "\n",
    "    for i, (adj, opp_adj) in enumerate(zip(adj_ls, opp_adj_ls[::-1])):\n",
    "\n",
    "        ### NOTE TEMPORARY MEASURE BECAUSE THEY TAKE IN (BATCHSIZE, xx, xx) shape ####\n",
    "        # temp_adj = adj.reshape(1, *adj.shape)\n",
    "        # temp_opp_adj = opp_adj.reshape(1, *opp_adj.shape)\n",
    "        ##########################################################\n",
    "        gt_loss = GT_loss(adj, opp_adj)\n",
    "        \n",
    "        mse_loss = mse_loss_fn(adj, opp_adj)\n",
    "        total_loss = total_loss + (gt_loss + mse_loss) * n / (i + 1)\n",
    "\n",
    "    # gt_loss = torch.Tensor([0]).to(DEVICE)\n",
    "    # for i, (adj, opp_adj) in enumerate(zip(adj_ls, opp_adj_ls[::-1])):\n",
    "\n",
    "    #     ### NOTE TEMPORARY MEASURE BECAUSE THEY TAKE IN (BATCHSIZE, xx, xx) shape ####\n",
    "    #     temp_adj = adj.reshape(1, *adj.shape)\n",
    "    #     temp_opp_adj = opp_adj.reshape(1, *opp_adj.shape)\n",
    "    #     ##########################################################\n",
    "    #     gt_loss = gt_loss + GT_loss(temp_adj, temp_opp_adj)\n",
    "\n",
    "    # gt_loss = gt_loss / n\n",
    "        \n",
    "    return total_loss\n",
    "\n",
    "\n",
    "def end_adj_loss_calc(adj, opp_adj):\n",
    "    mae_loss_fn = torch.nn.L1Loss()\n",
    "    mae_loss = mae_loss_fn(adj, opp_adj).detach()\n",
    "    temp_adj = adj.reshape(1, *adj.shape)\n",
    "    temp_opp_adj = opp_adj.reshape(1, *opp_adj.shape)\n",
    "    gt_loss = GT_loss(temp_adj, temp_opp_adj)\n",
    "    return mae_loss.detach().item(), gt_loss.detach().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67284"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainloader = DataLoader(list(zip(lr_X_dim1, lr_X_dim3, lr_train, hr_X_dim1, hr_X_dim3, hr_train)), shuffle=True, batch_size=32)\n",
    "\n",
    "dim_steps = generate_steps(num_steps=10)\n",
    "\n",
    "up_changer = AdjacencyDimChanger(dim_steps, f=32).to(DEVICE)\n",
    "down_changer = AdjacencyDimChanger(dim_steps[::-1],f=32).to(DEVICE)\n",
    "\n",
    "up_optimizer = torch.optim.AdamW(up_changer.parameters(), lr=0.001, betas=(0.5, 0.999))\n",
    "down_optimizer = torch.optim.AdamW(down_changer.parameters(), lr=0.001, betas=(0.5, 0.999))\n",
    "\n",
    "sum(p.numel() for model in [up_changer, down_changer] for p in model.parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs, up_changer, down_changer, trainloader, up_optimizer, down_optimizer):\n",
    "\n",
    "    up_changer.train()\n",
    "    down_changer.train()\n",
    "    with torch.autograd.set_detect_anomaly(True):\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            up_losses = []\n",
    "            down_losses = []\n",
    "\n",
    "            for X_lr, Y_lr, adj_lr, X_hr, Y_hr, adj_hr in tqdm(trainloader):\n",
    "\n",
    "                freeze_model(up_changer)\n",
    "                unfreeze_model(down_changer)\n",
    "            \n",
    "                down_optimizer.zero_grad()\n",
    "                up_optimizer.zero_grad()\n",
    "\n",
    "                down_batch_loss = []\n",
    "                \n",
    "                down_end_adj_mse_loss = []\n",
    "                down_end_adj_gt_loss = []\n",
    "\n",
    "                    \n",
    "\n",
    "                up_adj_ls = up_changer(X_lr.to(DEVICE), Y_lr.to(DEVICE), adj_lr.to(DEVICE))\n",
    "                torch.cuda.empty_cache()\n",
    "                down_adj_ls = down_changer(X_hr.to(DEVICE), Y_hr.to(DEVICE), adj_hr.to(DEVICE))\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "                down_batch_loss.append(loss_calc(down_adj_ls, up_adj_ls))\n",
    "            \n",
    "                # for printing loss only\n",
    "                down_end_adj_mse_loss.append(end_adj_loss_calc(down_adj_ls[-1].detach(), up_adj_ls[0].detach())[0])\n",
    "                down_end_adj_gt_loss.append(end_adj_loss_calc(down_adj_ls[-1].detach(), up_adj_ls[0].detach())[1])\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "                # for i in range(len(X_lr)):\n",
    "                \n",
    "\n",
    "                #     up_adj_ls = up_changer(X_lr[i].to(DEVICE), Y_lr[i].to(DEVICE), adj_lr[i].to(DEVICE))\n",
    "                #     torch.cuda.empty_cache()\n",
    "                #     down_adj_ls = down_changer(X_hr[i].to(DEVICE), Y_hr[i].to(DEVICE), adj_hr[i].to(DEVICE))\n",
    "                #     torch.cuda.empty_cache()\n",
    "\n",
    "                #     down_batch_loss.append(loss_calc(down_adj_ls, up_adj_ls))\n",
    "                \n",
    "                #     # for printing loss only\n",
    "                #     down_end_adj_mse_loss.append(end_adj_loss_calc(down_adj_ls[-1].detach(), up_adj_ls[0].detach())[0])\n",
    "                #     down_end_adj_gt_loss.append(end_adj_loss_calc(down_adj_ls[-1].detach(), up_adj_ls[0].detach())[1])\n",
    "                #     torch.cuda.empty_cache()\n",
    "\n",
    "                \n",
    "                print(f'Down end adj mse {np.mean(down_end_adj_mse_loss)}, gt loss {np.mean(down_end_adj_gt_loss)}')\n",
    "                del down_end_adj_mse_loss\n",
    "                del down_end_adj_gt_loss\n",
    "                down_loss = torch.mean(torch.stack(down_batch_loss))\n",
    "                down_loss.backward()\n",
    "                down_optimizer.step()\n",
    "\n",
    "                down_losses.append(down_loss.detach().item())\n",
    "                del down_loss\n",
    "                del down_batch_loss\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "                unfreeze_model(up_changer)\n",
    "                freeze_model(down_changer)\n",
    "            \n",
    "                down_optimizer.zero_grad()\n",
    "                up_optimizer.zero_grad()\n",
    "\n",
    "                up_batch_loss = []\n",
    "                    \n",
    "                up_end_adj_mse_loss = []\n",
    "                up_end_adj_gt_loss = []\n",
    "\n",
    "\n",
    "                for i in range(len(X_lr)):\n",
    "\n",
    "                    up_adj_ls = up_changer(X_lr[i].to(DEVICE), Y_lr[i].to(DEVICE), adj_lr[i].to(DEVICE))\n",
    "                    torch.cuda.empty_cache()\n",
    "                    down_adj_ls = down_changer(X_hr[i].to(DEVICE), Y_hr[i].to(DEVICE), adj_hr[i].to(DEVICE))\n",
    "                    torch.cuda.empty_cache()\n",
    "                \n",
    "                    up_batch_loss.append(loss_calc(up_adj_ls, down_adj_ls))\n",
    "                    \n",
    "                    # for printing loss only\n",
    "                    up_end_adj_mse_loss.append(end_adj_loss_calc(up_adj_ls[-1].detach(), down_adj_ls[0].detach())[0])\n",
    "                    up_end_adj_gt_loss.append(end_adj_loss_calc(up_adj_ls[-1].detach(), down_adj_ls[0].detach())[1])\n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "                \n",
    "                print(f'Up end adj mse {np.mean(up_end_adj_mse_loss)}, gt loss {np.mean(up_end_adj_gt_loss)}')\n",
    "                del up_end_adj_mse_loss\n",
    "                del up_end_adj_gt_loss\n",
    "\n",
    "                up_loss = torch.mean(torch.stack(up_batch_loss))\n",
    "                up_loss.backward()\n",
    "                up_optimizer.step()\n",
    "\n",
    "                up_losses.append(up_loss.detach().item())\n",
    "                del up_loss\n",
    "                del up_batch_loss\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "\n",
    "            epoch_up_loss = np.mean(up_losses)\n",
    "            epoch_down_loss = np.mean(down_losses)\n",
    "\n",
    "            print(f'epoch {epoch}: down loss = {epoch_down_loss}, up loss = {epoch_up_loss}')\n",
    "\n",
    "        return up_changer, down_changer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "up_changer, down_changer = train(10, up_changer, down_changer, trainloader, up_optimizer, down_optimizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
