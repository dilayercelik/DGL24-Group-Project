{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Sequential, Linear, ReLU, Sigmoid, Tanh, Dropout, Upsample\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import BatchNorm, GCNConv\n",
    "import numpy as np\n",
    "from torch_geometric.data import Data\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torch.distributions import normal, kl\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd\n",
    "from MatrixVectorizer import MatrixVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set global variables\n",
    "N_SUBJECTS = 167\n",
    "\n",
    "N_LR_NODES = 160\n",
    "\n",
    "N_HR_NODES = 268\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "N_LR_NODES_F = int(N_LR_NODES * (N_LR_NODES-1) / 2)\n",
    "N_HR_NODES_F = int(N_HR_NODES * (N_HR_NODES-1) / 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class SheafConvLayer(nn.Module):\n",
    "#     def __init__(self, n_nodes, d, f_in, f_out=None):\n",
    "#         super().__init__()\n",
    "#         self.d = d\n",
    "#         self.n_nodes = n_nodes\n",
    "#         self.f_in = f_in\n",
    "#         self.f_out = f_out\n",
    "#         # random init weight matrices\n",
    "#         if f_out is None:\n",
    "#             f_out = f_in \n",
    "#         self.weight1 = nn.Parameter(torch.randn((d, d), device=DEVICE))\n",
    "#         self.weight2 = nn.Parameter(torch.randn((f_in, f_out), device=DEVICE))\n",
    "#         self.edge_weights = nn.Parameter(torch.randn((n_nodes, n_nodes, d, 2*d), device=DEVICE))\n",
    "\n",
    "\n",
    "#     def forward(self, X, adj):\n",
    "#         kron_prod = torch.kron(torch.eye(self.n_nodes).to(DEVICE), self.weight1)\n",
    "#         L = self.sheaf_laplacian(X, adj)\n",
    "#         if self.f_out is None:\n",
    "#             return X - F.elu(L @ kron_prod @ X @ self.weight2), L\n",
    "#         else:\n",
    "#             return F.elu(L @ kron_prod @ X @ self.weight2), L\n",
    "\n",
    "\n",
    "#     def sheaf_laplacian(self, X, adj, epsilon=1e-6):\n",
    "#         X_reshaped = X.reshape(self.n_nodes, self.d, -1)\n",
    "#         idx_pairs = torch.cartesian_prod(torch.arange(self.n_nodes), torch.arange(self.n_nodes))\n",
    "#         all_stacked_features = X_reshaped[idx_pairs].reshape(self.n_nodes, self.n_nodes, 2*self.d, -1).to(DEVICE)\n",
    "#         lin_trans = F.elu(torch.matmul(self.edge_weights, all_stacked_features))\n",
    "#         inner_transpose = torch.transpose(lin_trans, -1, -2)\n",
    "#         L_v = -1 * torch.matmul(lin_trans, torch.transpose(inner_transpose, 0, 1))\n",
    "#         # row_cond = torch.isclose(torch.sum(adj, dim=1), torch.zeros_like(torch.sum(adj, dim=1)))\n",
    "#         # col_cond = torch.isclose(torch.sum(adj, dim=0), torch.zeros_like(torch.sum(adj, dim=0)))\n",
    "#         adj_row_weights = adj / (torch.sum(adj, dim=1)[:, None] + epsilon)\n",
    "#         adj_col_weights = adj / (torch.sum(adj, dim=0)[:, None] + epsilon)\n",
    "#         # adj_col_weights = torch.where(col_cond[None, :], 0., adj / torch.sum(adj, dim=0)[None, :])\n",
    "#         adj_weights = torch.maximum(adj_row_weights * adj_col_weights, torch.zeros_like(adj_row_weights))\n",
    "\n",
    "#         adj_diag_weights = adj_row_weights ** 2\n",
    "#         diag_blocks = torch.sum(adj_diag_weights[:, :, None, None] * torch.matmul(lin_trans, inner_transpose), dim=1)\n",
    "#         L_v[range(self.n_nodes), range(self.n_nodes)] = diag_blocks\n",
    "#         return L_v.reshape(-1, self.n_nodes * self.d)\n",
    "#         ### NOTE IGNORE MATRIX NORMALISATION FOR NOW #####\n",
    "#         # inv_root_diag_blocks = torch.pow(diag_blocks+epsilon, -1/2)\n",
    "#         # normalise_mat = torch.block_diag(*inv_root_diag_blocks)\n",
    "\n",
    "#         # return normalise_mat @ L_v.view(-1, self.n_nodes * self.d) @ normalise_mat\n",
    "#         ################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdjacencyDimChanger(nn.Module):\n",
    "    def __init__(self, new_n, old_n, old_f, d):\n",
    "        super().__init__()\n",
    "        self.new_n = new_n\n",
    "        self.old_n = old_n\n",
    "        self.d = d\n",
    "        #self.sheafconv = SheafConvLayer(old_n, d, old_f, new_n)  # Using Sheaf conv\n",
    "        # TODO: ADD ANOTHER LAYER TYPE FROM TORCH_GEOMETRIC INSTEAD OF SHEAFCONV\n",
    "        self.gcnconv = GCNConv(old_f, d)  # GCN\n",
    "        self.layernorm = nn.LayerNorm([d, old_n]).to(DEVICE)\n",
    "\n",
    "    def forward(self, X, adj):\n",
    "\n",
    "        adj = adj - torch.diag_embed(torch.diagonal(adj, 0)).to(DEVICE) + torch.eye(adj.shape[0]).to(DEVICE)  # add self connections\n",
    "        #x, L = self.sheafconv(X, adj)  # Using Sheaf conv\n",
    "        # TODO: USE THE OTHER LAYER TYPE\n",
    "        print(f'X: {X.shape}, adj: {adj.shape}')\n",
    "        x = self.gcnconv(X, adj)  # Using GCNConv\n",
    "        print(f'x: {x.shape}')\n",
    "\n",
    "        x = x.reshape(self.old_n, self.d, self.new_n)\n",
    "        x = torch.transpose(x, 0, -1)\n",
    "        x = self.layernorm(x)\n",
    "        \n",
    "        x_mean = x.mean(dim=-1)\n",
    "\n",
    "        #L_mean = L.reshape(self.old_n, self.old_n, self.d, self.d).max(dim=0)[0].mean(dim=0) # aggregate by eigenvalues of each n by n mat? # Using Sheaf conv\n",
    "        # TODO: for the reshaping above, might be better to hard-code it with some values instead?\n",
    "        # Using GCNConv: calculate L_mean based on the adjacency matrix adj\n",
    "        L_mean = adj.sum(dim=1, keepdim=True)  # Sum of each row\n",
    "        L_mean = L_mean.repeat(1, self.d)  # Repeat for each feature dimension\n",
    "        L_mean = L_mean.unsqueeze(2)  # Add dimension for element-wise multiplication\n",
    "        L_mean = L_mean * torch.eye(self.old_n).to(DEVICE)  # Keep only diagonal elements\n",
    "        L_mean = L_mean.transpose(0, 1)  # Transpose to match the dimensions\n",
    "        print(f'L_mean: {L_mean.shape}, self.old_n: {self.old_n},  self.d:{ self.d}')\n",
    "        \n",
    "        \n",
    "        adj_new = torch.matmul(x_mean, L_mean)\n",
    "        adj_new = torch.matmul(adj_new, x_mean.T)\n",
    "        adj_new_T = torch.t(adj_new)\n",
    "        adj_new = F.tanh(F.relu(((adj_new + adj_new_T) / 2))) # becomes a new f by new f adj1\n",
    "\n",
    "\n",
    "        return x.reshape(self.new_n*self.d, -1), adj_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdjacencyChangerUp(nn.Module):\n",
    "\n",
    "    def __init__(self, d, f_in):\n",
    "        super().__init__()\n",
    "        self.d = d\n",
    "\n",
    "        self.adjdim_changer1 = AdjacencyDimChanger(200, N_LR_NODES, f_in, d) # from 160 (initial size) to 200\n",
    "        self.adjdim_changer2 = AdjacencyDimChanger(220, 200, N_LR_NODES, d) # from 200 to 220\n",
    "        self.adjdim_changer3 = AdjacencyDimChanger(N_HR_NODES, 220, 200, d) # from 220 to 268 (final size) \n",
    "\n",
    "        \n",
    "    def forward(self, X, adj):\n",
    "        x1, adj1 = self.adjdim_changer1(X, adj)\n",
    "        x2, adj2 = self.adjdim_changer2(x1, adj1)\n",
    "        x3, adj3 = self.adjdim_changer3(x2, adj2)\n",
    "        return [adj, adj1, adj2, adj3]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdjacencyChangerDown(nn.Module):\n",
    "\n",
    "    def __init__(self, d, f_in):\n",
    "        super().__init__()\n",
    "        self.d = d\n",
    "\n",
    "        self.adjdim_changer1 = AdjacencyDimChanger(220, N_HR_NODES, f_in, d).to(DEVICE) # from 268 (final size) to 220\n",
    "        self.adjdim_changer2  = AdjacencyDimChanger(200, 220, N_HR_NODES, d).to(DEVICE) # from 220 to 200\n",
    "        self.adjdim_changer3 = AdjacencyDimChanger(N_LR_NODES, 200, 220, d).to(DEVICE) # from 200 to 168\n",
    "\n",
    "        \n",
    "    def forward(self, X, adj):\n",
    "        x1, adj1 = self.adjdim_changer1(X, adj)\n",
    "        x2, adj2 = self.adjdim_changer2(x1, adj1)\n",
    "        x3, adj3 = self.adjdim_changer3(x2, adj2)\n",
    "        return [adj, adj1, adj2, adj3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_model(model):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "def unfreeze_model(model):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "def eigen_centrality(data):\n",
    "    # ROI is the number of brain regions (i.e.,35 in our case)\n",
    "    ROI = 160\n",
    "\n",
    "    topology_eigen = []\n",
    "\n",
    "    G = nx.from_numpy_array(np.absolute(data))\n",
    "    U = G.to_undirected()\n",
    "\n",
    "    # A = to_2d(data)\n",
    "    np.fill_diagonal(data, 0)\n",
    "\n",
    "    # create a graph frL2\n",
    "    # # compute egeinvector centrality and transform the output to vector\n",
    "    ec = nx.eigenvector_centrality_numpy(U)\n",
    "    \n",
    "    eigenvector_centrality = np.array([ec[g] for g in U])\n",
    "\n",
    "\n",
    "\n",
    "    topology_eigen.append(eigenvector_centrality)  # 2\n",
    "\n",
    "    return topology_eigen\n",
    "\n",
    "def pearson_coor(input, target, epsilon=1e-7):\n",
    "    vx = input - torch.mean(input, dim=(1, 2))[:, None, None]\n",
    "    vy = target - torch.mean(target, dim=(1, 2))[:, None, None]\n",
    "    cost = torch.sum(vx * vy) / (torch.sqrt(torch.sum(vx ** 2)+epsilon) * torch.sqrt(torch.sum(vy ** 2)+epsilon)+epsilon)\n",
    "    return cost\n",
    "\n",
    "def GT_loss(target, predicted):\n",
    "\n",
    "    # l1_loss\n",
    "    l1_loss = torch.nn.L1Loss()\n",
    "    # loss_pix2pix = l1_loss(target, predicted)\n",
    "\n",
    "    # topological_loss\n",
    "    target_n = target.detach().cpu().clone().numpy()\n",
    "    predicted_n = predicted.detach().cpu().clone().numpy()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    topo_loss = []\n",
    "    \n",
    "\n",
    "    for i in range(len(target_n)):\n",
    "\n",
    "        cur_target = target_n[i]\n",
    "        cur_predicted = predicted_n[i]\n",
    "\n",
    "        target_t = eigen_centrality(cur_target)\n",
    "        real_topology = torch.tensor(target_t[0])\n",
    "        predicted_t = eigen_centrality(cur_predicted)\n",
    "        fake_topology = torch.tensor(predicted_t[0])\n",
    "        topo_loss.append(l1_loss(real_topology, fake_topology))\n",
    "\n",
    "    topo_loss = torch.sum(torch.stack(topo_loss))\n",
    "\n",
    "    pc_loss = pearson_coor(target, predicted).to(DEVICE)\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # G_loss = loss_pix2pix + (1 - pc_loss) + topo_loss\n",
    "    G_loss = (1 - pc_loss) + topo_loss\n",
    "\n",
    "\n",
    "    return G_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_calc(adj_ls, opp_adj_ls):\n",
    "    total_loss = torch.Tensor([0]).to(DEVICE)\n",
    "    mse_loss_fn = torch.nn.MSELoss()\n",
    "    for i, (adj, opp_adj) in enumerate(zip(adj_ls[::-1], opp_adj_ls)):\n",
    "\n",
    "        ### NOTE TEMPORARY MEASURE BECAUSE THEY TAKE IN (BATCHSIZE, xx, xx) shape ####\n",
    "        temp_adj = adj.reshape(1, *adj.shape)\n",
    "        temp_opp_adj = opp_adj.reshape(1, *opp_adj.shape)\n",
    "        ##########################################################\n",
    "        gt_loss = GT_loss(temp_adj, temp_opp_adj) / len(adj_ls)\n",
    "        mse_loss = torch.pow(mse_loss_fn(adj, opp_adj), 1/(i+1)) \n",
    "        total_loss = total_loss + mse_loss + gt_loss.to(DEVICE)\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_preparation import load_data_tensor\n",
    "\n",
    "lr_train, lr_test, hr_train = load_data_tensor('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_X_dim1 = torch.load('model_autoencoder/encode_lr_1.pt')\n",
    "lr_X_dim2 = torch.load('model_autoencoder/encode_lr_2.pt')\n",
    "hr_X_dim1 = torch.load('model_autoencoder/encode_hr_1.pt')\n",
    "hr_X_dim2 = torch.load('model_autoencoder/encode_hr_2.pt')\n",
    "\n",
    "\n",
    "lr_X_all = torch.empty((167, 320, 32))\n",
    "for i in range(len(lr_X_dim1)):\n",
    "    a, b = lr_X_dim1[i], lr_X_dim2[i]\n",
    "    lr_X_all[i] = torch.cat([a, b], dim=-1).view(-1, a.shape[-1])\n",
    "\n",
    "hr_X_all = torch.empty((167, 536, 32))\n",
    "for i in range(len(hr_X_dim1)):\n",
    "    a, b = hr_X_dim1[i], hr_X_dim2[i]\n",
    "    hr_X_all[i] = torch.cat([a, b], dim=-1).view(-1, a.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6908"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainloader = DataLoader(list(zip(lr_X_all, lr_train, hr_X_all, hr_train)), shuffle=True, batch_size=8)\n",
    "\n",
    "\n",
    "up_changer = AdjacencyChangerUp(d=2,f_in=32).to(DEVICE)\n",
    "down_changer = AdjacencyChangerDown(d=2,f_in=32).to(DEVICE)\n",
    "\n",
    "up_optimizer = torch.optim.AdamW(up_changer.parameters(), lr=0.001, betas=(0.5, 0.999))\n",
    "down_optimizer = torch.optim.AdamW(down_changer.parameters(), lr=0.001, betas=(0.5, 0.999))\n",
    "\n",
    "sum(p.numel() for model in [up_changer, down_changer] for p in model.parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs, up_changer, down_changer, trainloader, up_optimizer, down_optimizer):\n",
    "\n",
    "    up_changer.train()\n",
    "    down_changer.train()\n",
    "    with torch.autograd.set_detect_anomaly(True):\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            up_losses = []\n",
    "            down_losses = []\n",
    "\n",
    "            for X_lr, adj_lr, X_hr, adj_hr in tqdm(trainloader):\n",
    "\n",
    "                freeze_model(up_changer)\n",
    "                unfreeze_model(down_changer)\n",
    "            \n",
    "                down_optimizer.zero_grad()\n",
    "                up_optimizer.zero_grad()\n",
    "\n",
    "                down_batch_loss = []\n",
    "\n",
    "                for i in range(len(X_lr)):\n",
    "\n",
    "                    up_adj_ls = up_changer(X_lr[i].to(DEVICE), adj_lr[i].to(DEVICE))\n",
    "                    torch.cuda.empty_cache()\n",
    "                    down_adj_ls = down_changer(X_hr[i].to(DEVICE), adj_hr[i].to(DEVICE))\n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "                    down_batch_loss.append(loss_calc(down_adj_ls, up_adj_ls))\n",
    "\n",
    "                down_loss = torch.mean(torch.stack(down_batch_loss))\n",
    "                down_loss.backward()\n",
    "                down_optimizer.step()\n",
    "\n",
    "                down_losses.append(down_loss.detach().item())\n",
    "                del down_loss\n",
    "                del down_batch_loss\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "                unfreeze_model(up_changer)\n",
    "                freeze_model(down_changer)\n",
    "            \n",
    "                down_optimizer.zero_grad()\n",
    "                up_optimizer.zero_grad()\n",
    "\n",
    "                up_batch_loss = []\n",
    "\n",
    "\n",
    "                for i in range(len(X_lr)):\n",
    "\n",
    "                    up_adj_ls = up_changer(X_lr[i].to(DEVICE), adj_lr[i].to(DEVICE))\n",
    "                    torch.cuda.empty_cache()\n",
    "                    down_adj_ls = down_changer(X_hr[i].to(DEVICE), adj_hr[i].to(DEVICE))\n",
    "                    torch.cuda.empty_cache()\n",
    "                \n",
    "                    up_batch_loss.append(loss_calc(up_adj_ls, down_adj_ls))\n",
    "\n",
    "                up_loss = torch.mean(torch.stack(up_batch_loss))\n",
    "                up_loss.backward()\n",
    "                up_optimizer.step()\n",
    "\n",
    "                up_losses.append(up_loss.detach().item())\n",
    "                del up_loss\n",
    "                del up_batch_loss\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "\n",
    "            epoch_up_loss = np.mean(up_losses)\n",
    "            epoch_down_loss = np.mean(down_losses)\n",
    "\n",
    "            print(f'epoch {epoch}: down loss = {epoch_down_loss}, up loss = {epoch_up_loss}')\n",
    "\n",
    "        return up_changer, down_changer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/21 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: torch.Size([320, 32]), adj: torch.Size([160, 160])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 1. Expected size 160 but got size 2 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m up_changer, down_changer \u001b[39m=\u001b[39m train(\u001b[39m20\u001b[39;49m, up_changer, down_changer, trainloader, up_optimizer, down_optimizer)\n",
      "Cell \u001b[0;32mIn[13], line 23\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(epochs, up_changer, down_changer, trainloader, up_optimizer, down_optimizer)\u001b[0m\n\u001b[1;32m     19\u001b[0m down_batch_loss \u001b[39m=\u001b[39m []\n\u001b[1;32m     21\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(X_lr)):\n\u001b[0;32m---> 23\u001b[0m     up_adj_ls \u001b[39m=\u001b[39m up_changer(X_lr[i]\u001b[39m.\u001b[39;49mto(DEVICE), adj_lr[i]\u001b[39m.\u001b[39;49mto(DEVICE))\n\u001b[1;32m     24\u001b[0m     torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mempty_cache()\n\u001b[1;32m     25\u001b[0m     down_adj_ls \u001b[39m=\u001b[39m down_changer(X_hr[i]\u001b[39m.\u001b[39mto(DEVICE), adj_hr[i]\u001b[39m.\u001b[39mto(DEVICE))\n",
      "File \u001b[0;32m~/Documents/Imperial/deep_graph_learning/group_project/DGL24-Group-Project/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[5], line 13\u001b[0m, in \u001b[0;36mAdjacencyChangerUp.forward\u001b[0;34m(self, X, adj)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, X, adj):\n\u001b[0;32m---> 13\u001b[0m     x1, adj1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madjdim_changer1(X, adj)\n\u001b[1;32m     14\u001b[0m     x2, adj2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madjdim_changer2(x1, adj1)\n\u001b[1;32m     15\u001b[0m     x3, adj3 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madjdim_changer3(x2, adj2)\n",
      "File \u001b[0;32m~/Documents/Imperial/deep_graph_learning/group_project/DGL24-Group-Project/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[4], line 18\u001b[0m, in \u001b[0;36mAdjacencyDimChanger.forward\u001b[0;34m(self, X, adj)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39m#x, L = self.sheafconv(X, adj)  # Using Sheaf conv\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[39m# TODO: USE THE OTHER LAYER TYPE\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mX: \u001b[39m\u001b[39m{\u001b[39;00mX\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m, adj: \u001b[39m\u001b[39m{\u001b[39;00madj\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 18\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgcnconv(X, adj)  \u001b[39m# Using GCNConv\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mx: \u001b[39m\u001b[39m{\u001b[39;00mx\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     21\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mreshape(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mold_n, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39md, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnew_n)\n",
      "File \u001b[0;32m~/Documents/Imperial/deep_graph_learning/group_project/DGL24-Group-Project/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/Imperial/deep_graph_learning/group_project/DGL24-Group-Project/.venv/lib/python3.10/site-packages/torch_geometric/nn/conv/gcn_conv.py:241\u001b[0m, in \u001b[0;36mGCNConv.forward\u001b[0;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[1;32m    239\u001b[0m cache \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cached_edge_index\n\u001b[1;32m    240\u001b[0m \u001b[39mif\u001b[39;00m cache \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 241\u001b[0m     edge_index, edge_weight \u001b[39m=\u001b[39m gcn_norm(  \u001b[39m# yapf: disable\u001b[39;49;00m\n\u001b[1;32m    242\u001b[0m         edge_index, edge_weight, x\u001b[39m.\u001b[39;49msize(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnode_dim),\n\u001b[1;32m    243\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mimproved, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd_self_loops, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mflow, x\u001b[39m.\u001b[39;49mdtype)\n\u001b[1;32m    244\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcached:\n\u001b[1;32m    245\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cached_edge_index \u001b[39m=\u001b[39m (edge_index, edge_weight)\n",
      "File \u001b[0;32m~/Documents/Imperial/deep_graph_learning/group_project/DGL24-Group-Project/.venv/lib/python3.10/site-packages/torch_geometric/nn/conv/gcn_conv.py:99\u001b[0m, in \u001b[0;36mgcn_norm\u001b[0;34m(edge_index, edge_weight, num_nodes, improved, add_self_loops, flow, dtype)\u001b[0m\n\u001b[1;32m     96\u001b[0m num_nodes \u001b[39m=\u001b[39m maybe_num_nodes(edge_index, num_nodes)\n\u001b[1;32m     98\u001b[0m \u001b[39mif\u001b[39;00m add_self_loops:\n\u001b[0;32m---> 99\u001b[0m     edge_index, edge_weight \u001b[39m=\u001b[39m add_remaining_self_loops(\n\u001b[1;32m    100\u001b[0m         edge_index, edge_weight, fill_value, num_nodes)\n\u001b[1;32m    102\u001b[0m \u001b[39mif\u001b[39;00m edge_weight \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    103\u001b[0m     edge_weight \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mones((edge_index\u001b[39m.\u001b[39msize(\u001b[39m1\u001b[39m), ), dtype\u001b[39m=\u001b[39mdtype,\n\u001b[1;32m    104\u001b[0m                              device\u001b[39m=\u001b[39medge_index\u001b[39m.\u001b[39mdevice)\n",
      "File \u001b[0;32m~/Documents/Imperial/deep_graph_learning/group_project/DGL24-Group-Project/.venv/lib/python3.10/site-packages/torch_geometric/utils/loop.py:654\u001b[0m, in \u001b[0;36madd_remaining_self_loops\u001b[0;34m(edge_index, edge_attr, fill_value, num_nodes)\u001b[0m\n\u001b[1;32m    651\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mis_scripting() \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(edge_index, EdgeIndex):\n\u001b[1;32m    652\u001b[0m     edge_index\u001b[39m.\u001b[39m_is_undirected \u001b[39m=\u001b[39m is_undirected\n\u001b[0;32m--> 654\u001b[0m edge_index \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mcat([edge_index, loop_index], dim\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m    656\u001b[0m \u001b[39mreturn\u001b[39;00m edge_index, edge_attr\n",
      "File \u001b[0;32m~/Documents/Imperial/deep_graph_learning/group_project/DGL24-Group-Project/.venv/lib/python3.10/site-packages/torch_geometric/edge_index.py:1057\u001b[0m, in \u001b[0;36mEdgeIndex.__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m   1038\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__torch_function__\u001b[39m(\n\u001b[1;32m   1039\u001b[0m     \u001b[39mcls\u001b[39m: Type,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1054\u001b[0m     \u001b[39m# To account for this, we hold a number of `HANDLED_FUNCTIONS` that\u001b[39;00m\n\u001b[1;32m   1055\u001b[0m     \u001b[39m# implement specific functions for valid `EdgeIndex` routines.\u001b[39;00m\n\u001b[1;32m   1056\u001b[0m     \u001b[39mif\u001b[39;00m func \u001b[39min\u001b[39;00m HANDLED_FUNCTIONS:\n\u001b[0;32m-> 1057\u001b[0m         \u001b[39mreturn\u001b[39;00m HANDLED_FUNCTIONS[func](\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m(kwargs \u001b[39mor\u001b[39;49;00m {}))\n\u001b[1;32m   1059\u001b[0m     \u001b[39m# For all other PyTorch functions, we return a vanilla PyTorch tensor.\u001b[39;00m\n\u001b[1;32m   1060\u001b[0m     _types \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(Tensor \u001b[39mif\u001b[39;00m \u001b[39missubclass\u001b[39m(t, \u001b[39mcls\u001b[39m) \u001b[39melse\u001b[39;00m t \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m types)\n",
      "File \u001b[0;32m~/Documents/Imperial/deep_graph_learning/group_project/DGL24-Group-Project/.venv/lib/python3.10/site-packages/torch_geometric/edge_index.py:1204\u001b[0m, in \u001b[0;36mcat\u001b[0;34m(tensors, dim, out)\u001b[0m\n\u001b[1;32m   1201\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(tensors) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1202\u001b[0m     \u001b[39mreturn\u001b[39;00m tensors[\u001b[39m0\u001b[39m]\n\u001b[0;32m-> 1204\u001b[0m output \u001b[39m=\u001b[39m Tensor\u001b[39m.\u001b[39;49m__torch_function__(torch\u001b[39m.\u001b[39;49mcat, (Tensor, ), (tensors, dim),\n\u001b[1;32m   1205\u001b[0m                                    \u001b[39mdict\u001b[39;49m(out\u001b[39m=\u001b[39;49mout))\n\u001b[1;32m   1207\u001b[0m \u001b[39mif\u001b[39;00m dim \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m dim \u001b[39m!=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:  \u001b[39m# No valid `EdgeIndex` anymore.\u001b[39;00m\n\u001b[1;32m   1208\u001b[0m     \u001b[39mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/Documents/Imperial/deep_graph_learning/group_project/DGL24-Group-Project/.venv/lib/python3.10/site-packages/torch/_tensor.py:1295\u001b[0m, in \u001b[0;36mTensor.__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m   1292\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNotImplemented\u001b[39m\n\u001b[1;32m   1294\u001b[0m \u001b[39mwith\u001b[39;00m _C\u001b[39m.\u001b[39mDisableTorchFunctionSubclass():\n\u001b[0;32m-> 1295\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1296\u001b[0m     \u001b[39mif\u001b[39;00m func \u001b[39min\u001b[39;00m get_default_nowrap_functions():\n\u001b[1;32m   1297\u001b[0m         \u001b[39mreturn\u001b[39;00m ret\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 1. Expected size 160 but got size 2 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "up_changer, down_changer = train(20, up_changer, down_changer, trainloader, up_optimizer, down_optimizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
